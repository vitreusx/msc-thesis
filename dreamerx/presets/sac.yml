sac:
  base:
    $extends: [no_model]
    compute_dtype: float32
    rl:
      type: sac
      sac:
        num_qf: 2
        gamma: 0.99
        gae_lambda: 0.95
        rew_fn: sign
        clip_grad: ~
        alpha:
          adaptive: true
          value: 1.0
          opt:
            type: adam
            lr: ${qf.opt.lr}
            eps: 1e-4
        actor:
          opt:
            type: adam
            eps: 1e-5
        qf:
          opt:
            type: adam
            eps: 1e-5
    profile.functions: [do_rl_opt_step]
  mujoco:
    $extends: [base]
    env:
      type: gym
      gym:
        env_id: HalfCheetah-v4
    data:
      capacity: 1e6
      loaders.real_rl:
        batch_size: 256
        slice_len: 2
    rl.sac:
      alpha:
        target: ${-1/math.log(2)}
        mode: rel
      actor:
        encoder:
          type: box
          box:
            hidden: 256
            layers: 2
            act: relu
        dist:
          type: trunc_normal
          trunc_normal:
            init: cleanrl_sac
        opt.lr: 3e-4
      qf:
        polyak:
          every: 1
          tau: 0.995
        encoder:
          type: box
          box:
            hidden: 256
            layers: 2
            act: relu
        opt.lr: 1e-3
    stages:
      - prefill:
          until: { n: 5e3, of: agent_step }
      - train_loop:
          until: { n: 1e6, of: agent_step }
          tasks:
            - do_rl_opt_step
            - do_env_step
  atari:
    $extends: [base]
    env:
      type: atari
      atari:
        env_id: Breakout
        screen_size: 84
        stack_num: 4
        term_on_life_loss: true
    data:
      capacity: 1e6
      loaders.real_rl:
        batch_size: 64
        slice_len: 2
    rl.sac:
      alpha:
        target: 0.89
        mode: rel
      actor:
        encoder:
          type: sac_image
        dist:
          type: cat
          cat:
            init: cleanrl_sac
        opt:
          lr: 3e-4
          eps: 1e-4
      qf:
        polyak:
          every: 2000
          tau: 0.0
        encoder:
          type: sac_image
        opt:
          lr: 3e-4
          eps: 1e-4
    stages:
      - prefill:
          until: { n: 20e3, of: agent_step }
      - train_loop:
          until: { n: 5e6, of: agent_step }
          tasks:
            - do_rl_opt_step: ~
              every: { n: 4, of: agent_step }
            - do_env_step
