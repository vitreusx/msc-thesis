% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/apasortcite//global/global}
    \entry{agarwalDeepReinforcementLearning2022}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=a3ce7bf5b3d6fcc96d09f5142950dd8d}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Rishabh},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd36c2abe3c5c9ea4b21e5258e5f3a37}{%
           family={Castro},
           familyi={C\bibinitperiod},
           given={Pablo\bibnamedelima Samuel},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b65e3dca892310aab631e0e18d6dcf30}
      \strng{fullhash}{eca631d7bf56942c4e599af3cdd85af6}
      \strng{bibnamehash}{eca631d7bf56942c4e599af3cdd85af6}
      \strng{authorbibnamehash}{eca631d7bf56942c4e599af3cdd85af6}
      \strng{authornamehash}{b65e3dca892310aab631e0e18d6dcf30}
      \strng{authorfullhash}{eca631d7bf56942c4e599af3cdd85af6}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep reinforcement learning (RL) algorithms are predominantly evaluated by comparing their relative performance on a large suite of tasks. Most published results on deep RL benchmarks compare point estimates of aggregate performance such as mean and median scores across tasks, ignoring the statistical uncertainty implied by the use of a finite number of training runs. Beginning with the Arcade Learning Environment (ALE), the shift towards computationally-demanding benchmarks has led to the practice of evaluating only a small number of runs per task, exacerbating the statistical uncertainty in point estimates. In this paper, we argue that reliable evaluation in the few run deep RL regime cannot ignore the uncertainty in results without running the risk of slowing down progress in the field. We illustrate this point using a case study on the Atari 100k benchmark, where we find substantial discrepancies between conclusions drawn from point estimates alone versus a more thorough statistical analysis. With the aim of increasing the field's confidence in reported results with a handful of runs, we advocate for reporting interval estimates of aggregate performance and propose performance profiles to account for the variability in results, as well as present more robust and efficient aggregate metrics, such as interquartile mean scores, to achieve small uncertainty in results. Using such statistical tools, we scrutinize performance evaluations of existing algorithms on other widely used RL benchmarks including the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies in prior comparisons. Our findings call for a change in how we evaluate performance in deep RL, for which we present a more rigorous evaluation methodology, accompanied with an open-source library rliable, to prevent unreliable results from stagnating the field.}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:2108.13264}
      \field{title}{Deep {{Reinforcement Learning}} at the {{Edge}} of the {{Statistical Precipice}}}
      \field{urlday}{28}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2108.13264
      \endverb
      \verb{eprint}
      \verb 2108.13264
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/XXICT83J/Agarwal et al. - 2022 - Deep Reinforcement Learning at the Edge of the Statistical Precipice.pdf;/home/james/Zotero/storage/ZT6G3NAW/2108.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology}
    \endentry
    \entry{aitchisonAtari5DistillingArcade2022}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=8539a0fc12c334a7cc7e81be93a5f273}{%
           family={Aitchison},
           familyi={A\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3d8ae89787e94a865d889d84d0324751}{%
           family={Sweetser},
           familyi={S\bibinitperiod},
           given={Penny},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=da595386b0c32905953fa716d906652a}{%
           family={Hutter},
           familyi={H\bibinitperiod},
           given={Marcus},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{502e938acf2fdc366dce81a8d0feb085}
      \strng{fullhash}{52a70e4533337ea187b59f4ea7f48d8b}
      \strng{bibnamehash}{52a70e4533337ea187b59f4ea7f48d8b}
      \strng{authorbibnamehash}{52a70e4533337ea187b59f4ea7f48d8b}
      \strng{authornamehash}{502e938acf2fdc366dce81a8d0feb085}
      \strng{authorfullhash}{52a70e4533337ea187b59f4ea7f48d8b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The Arcade Learning Environment (ALE) has become an essential benchmark for assessing the performance of reinforcement learning algorithms. However, the computational cost of generating results on the entire 57-game dataset limits ALE's use and makes the reproducibility of many results infeasible. We propose a novel solution to this problem in the form of a principled methodology for selecting small but representative subsets of environments within a benchmark suite. We applied our method to identify a subset of five ALE games, called Atari-5, which produces 57-game median score estimates within 10\% of their true values. Extending the subset to 10-games recovers 80\% of the variance for log-scores for all games within the 57-game set. We show this level of compression is possible due to a high degree of correlation between many of the games in ALE.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:2210.02019}
      \field{shorttitle}{Atari-5}
      \field{title}{Atari-5: {{Distilling}} the {{Arcade Learning Environment}} down to {{Five Games}}}
      \field{urlday}{17}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2210.02019
      \endverb
      \verb{eprint}
      \verb 2210.02019
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/3ZTJGMVB/Aitchison et al. - 2022 - Atari-5 Distilling the Arcade Learning Environmen.pdf;/home/james/Zotero/storage/R2847YWA/2210.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{bellemareArcadeLearningEnvironment2013}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07c80c48e7c42d8390ac0ad0513cbed3}{%
           family={Naddaf},
           familyi={N\bibinitperiod},
           given={Yavar},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1cbd91f7404b2298b46bb46c47c08251}{%
           family={Veness},
           familyi={V\bibinitperiod},
           given={Joel},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3318cb7968ff83b0f4b5a04d8f9ec318}{%
           family={Bowling},
           familyi={B\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{fullhash}{49395aa0bfa961c14ab74a906578e3ee}
      \strng{bibnamehash}{49395aa0bfa961c14ab74a906578e3ee}
      \strng{authorbibnamehash}{49395aa0bfa961c14ab74a906578e3ee}
      \strng{authornamehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{authorfullhash}{49395aa0bfa961c14ab74a906578e3ee}
      \field{extraname}{1}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1207.4708}
      \field{shorttitle}{The {{Arcade Learning Environment}}}
      \field{title}{The {{Arcade Learning Environment}}: {{An Evaluation Platform}} for {{General Agents}}}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1207.4708
      \endverb
      \verb{eprint}
      \verb 1207.4708
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/LSTXSQPY/Bellemare et al. - 2013 - The Arcade Learning Environment An Evaluation Platform for General Agents.pdf;/home/james/Zotero/storage/ZUSAMYHY/1207.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence}
    \endentry
    \entry{bellemareDistributionalPerspectiveReinforcement2017}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5a44cbf0d05e4c50b512bb0c1368d2f}{%
           family={Dabney},
           familyi={D\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d8fa91764a27bf97b87fdcac885745d}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={RÃ©mi},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{fullhash}{388111794c9bc8299b60e3b15be023db}
      \strng{bibnamehash}{388111794c9bc8299b60e3b15be023db}
      \strng{authorbibnamehash}{388111794c9bc8299b60e3b15be023db}
      \strng{authornamehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{authorfullhash}{388111794c9bc8299b60e3b15be023db}
      \field{extraname}{2}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we argue for the fundamental importance of the value distribution: the distribution of the random return received by a reinforcement learning agent. This is in contrast to the common approach to reinforcement learning which models the expectation of this return, or value. Although there is an established body of literature studying the value distribution, thus far it has always been used for a specific purpose such as implementing risk-aware behaviour. We begin with theoretical results in both the policy evaluation and control settings, exposing a significant distributional instability in the latter. We then use the distributional perspective to design a new algorithm which applies Bellman's equation to the learning of approximate value distributions. We evaluate our algorithm using the suite of games from the Arcade Learning Environment. We obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning. Finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1707.06887}
      \field{title}{A {{Distributional Perspective}} on {{Reinforcement Learning}}}
      \field{urlday}{23}
      \field{urlmonth}{7}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 1707.06887
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Bellemare et al_2017_A Distributional Perspective on Reinforcement Learning.pdf;/home/james/Zotero/storage/GS93URP8/1707.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{jax2018github}{software}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=b75383e6b48c8360c7a60031424c85cf}{%
           family={Bradbury},
           familyi={B\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29563c986154ca2b45d286b4dd5ef92a}{%
           family={Frostig},
           familyi={F\bibinitperiod},
           given={Roy},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ab2d7e7f2bfceec36e42ad1962fde11}{%
           family={Hawkins},
           familyi={H\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e4d515e534ba184f553d5a2a926e0ea7}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Matthew\bibnamedelima James},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0101ae5b219809cf901e7645ca40b9ae}{%
           family={Leary},
           familyi={L\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07e607fb522f06610feb023ecfa712e2}{%
           family={Maclaurin},
           familyi={M\bibinitperiod},
           given={Dougal},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bca7d753be3217d63404d860acb6e5f5}{%
           family={Necula},
           familyi={N\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=56bf0b340039cf8594436a624ff548a9}{%
           family={Paszke},
           familyi={P\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0fd9a0e34f1b2adda41357c948d14986}{%
           family={Vander{P}las},
           familyi={V\bibinitperiod},
           given={Jake},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=02f809ed2547f721c304772c06378c2d}{%
           family={Wanderman-{M}ilne},
           familyi={W\bibinithyphendelim M\bibinitperiod},
           given={Skye},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fe167f78433aabd363ac3c06710a1945}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Qiao},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{be9c2f36b976223518e841214253df92}
      \strng{fullhash}{12f83c04441cfb40a3c9b086929c12bf}
      \strng{bibnamehash}{12f83c04441cfb40a3c9b086929c12bf}
      \strng{authorbibnamehash}{12f83c04441cfb40a3c9b086929c12bf}
      \strng{authornamehash}{be9c2f36b976223518e841214253df92}
      \strng{authorfullhash}{12f83c04441cfb40a3c9b086929c12bf}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{JAX}: composable transformations of {P}ython+{N}um{P}y programs}
      \field{version}{0.3.13}
      \field{year}{2018}
      \verb{urlraw}
      \verb http://github.com/jax-ml/jax
      \endverb
      \verb{url}
      \verb http://github.com/jax-ml/jax
      \endverb
    \endentry
    \entry{brohanRT1RoboticsTransformer2023}{misc}{}
      \name{author}{51}{}{%
        {{un=0,uniquepart=base,hash=f85d2cbec6e9b5ca55d3826bbe4368ad}{%
           family={Brohan},
           familyi={B\bibinitperiod},
           given={Anthony},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=08d6dd07d0aece35ec87bdf93614ef8d}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Noah},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b1f99e7aa4aa0467670b08b913dff35}{%
           family={Carbajal},
           familyi={C\bibinitperiod},
           given={Justice},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=76d42bc2454b74c74d031975757c3b6f}{%
           family={Chebotar},
           familyi={C\bibinitperiod},
           given={Yevgen},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b04d48b46cc6c9274a2d66fb08e5add}{%
           family={Dabis},
           familyi={D\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=058e82495825ae376c6a96a12169e6ee}{%
           family={Finn},
           familyi={F\bibinitperiod},
           given={Chelsea},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a3bf81921be7cabf0697b2b427515e43}{%
           family={Gopalakrishnan},
           familyi={G\bibinitperiod},
           given={Keerthana},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=db5fb91bc488e352c6b92899f58c54f2}{%
           family={Hausman},
           familyi={H\bibinitperiod},
           given={Karol},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b1f80957f6b826692a865bccfb5edb5d}{%
           family={Herzog},
           familyi={H\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c83e3ad829beca29ca183c74f742e020}{%
           family={Hsu},
           familyi={H\bibinitperiod},
           given={Jasmine},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03345358e737db6abfc1f5accfc48533}{%
           family={Ibarz},
           familyi={I\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a096e9107f0463212211c4510c6fa470}{%
           family={Ichter},
           familyi={I\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=94a1e4ffdb54841501b129d269ddba1e}{%
           family={Irpan},
           familyi={I\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=da2fb282fbfcefd85a65e276dccd059d}{%
           family={Jackson},
           familyi={J\bibinitperiod},
           given={Tomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dd87df9934b4226160b2585245b008af}{%
           family={Jesmonth},
           familyi={J\bibinitperiod},
           given={Sally},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c5b78e927d8f921c22fa839298a78f9e}{%
           family={Joshi},
           familyi={J\bibinitperiod},
           given={Nikhil\bibnamedelima J.},
           giveni={N\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b04ec5aef0791c6a41951756f2a0bb3}{%
           family={Julian},
           familyi={J\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dd32ba2d0643a1dfa9dba39af24e2948}{%
           family={Kalashnikov},
           familyi={K\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=766c07beb0725c8ea271df0742be4f83}{%
           family={Kuang},
           familyi={K\bibinitperiod},
           given={Yuheng},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=325829a0eb81f78538ba18de089faa1f}{%
           family={Leal},
           familyi={L\bibinitperiod},
           given={Isabel},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=756814c491139f3349afefe329960ae5}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kuang-Huei},
           giveni={K\bibinithyphendelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=412e1388b73ef19ade8c52ca3431f84c}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Yao},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b06397d32f3c4c98e3e4516f8c475ec}{%
           family={Malla},
           familyi={M\bibinitperiod},
           given={Utsav},
           giveni={U\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a68c078d5efd7a18a2906cf09ddd657f}{%
           family={Manjunath},
           familyi={M\bibinitperiod},
           given={Deeksha},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7570e7c3fc2c13d59af4d7cdb9962a4d}{%
           family={Mordatch},
           familyi={M\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3fdbcb94c087d48425327cdfdb5f0827}{%
           family={Nachum},
           familyi={N\bibinitperiod},
           given={Ofir},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7fe2d48ce31c87a150449138bad607f0}{%
           family={Parada},
           familyi={P\bibinitperiod},
           given={Carolina},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2806c0f17dcce991b3e76cc59326f68a}{%
           family={Peralta},
           familyi={P\bibinitperiod},
           given={Jodilyn},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=39824e4aa78149965c2ae5976b4d40fd}{%
           family={Perez},
           familyi={P\bibinitperiod},
           given={Emily},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a31ce25b53500260a67ce7b91c821b6b}{%
           family={Pertsch},
           familyi={P\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33846ea5683179601fc64f8154f39fd5}{%
           family={Quiambao},
           familyi={Q\bibinitperiod},
           given={Jornell},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0bc76ae3489ed701bf62b815b7166ed7}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Kanishka},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3daa95be0b155cfe142bea7643fe022}{%
           family={Ryoo},
           familyi={R\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f1096086ce15f12da081de0f372ff987}{%
           family={Salazar},
           familyi={S\bibinitperiod},
           given={Grecia},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2958a61013cbb0c4eed93a63ad313fa9}{%
           family={Sanketi},
           familyi={S\bibinitperiod},
           given={Pannag},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=451b2df9920d95ad346012159883cfa2}{%
           family={Sayed},
           familyi={S\bibinitperiod},
           given={Kevin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b616dabbd3c472fdb55908119deaf408}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Jaspiar},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03de3c0b4a08fe619740d5bf11f9653e}{%
           family={Sontakke},
           familyi={S\bibinitperiod},
           given={Sumedh},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a3dfa1303288ee802e8bf3ce3abf08a}{%
           family={Stone},
           familyi={S\bibinitperiod},
           given={Austin},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=193380c4c8991077c66dd34b45776e45}{%
           family={Tan},
           familyi={T\bibinitperiod},
           given={Clayton},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=faf79b09b112cd2025ac4b03430780a3}{%
           family={Tran},
           familyi={T\bibinitperiod},
           given={Huong},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8051922e7bd286f884bfbd1023ef62f5}{%
           family={Vanhoucke},
           familyi={V\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=030bf812b3b741bdc09e070d6cbb86e2}{%
           family={Vega},
           familyi={V\bibinitperiod},
           given={Steve},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=644737d9c237bfc5db1369d2ca8f7688}{%
           family={Vuong},
           familyi={V\bibinitperiod},
           given={Quan},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=61e00ed0c44b8bddb9077a74a4ac1167}{%
           family={Xia},
           familyi={X\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=983a85de139e78f8c8e34fa633f08b8c}{%
           family={Xiao},
           familyi={X\bibinitperiod},
           given={Ted},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a9f1e89449a8f9e0a4b65ee24d8f421d}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3c4e72762406de2fb44caf54e7478103}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Sichun},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9deda9161d91175c5ce4efe814e405c7}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Tianhe},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=019a17d953e12f46a852d1314441652e}{%
           family={Zitkovich},
           familyi={Z\bibinitperiod},
           given={Brianna},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{c5d07d4a8918ca9ac03995189e27ade5}
      \strng{fullhash}{f78ae9babdcf9c1a81b98c9ea10ccba5}
      \strng{bibnamehash}{7e821cc9ab174b709c334e7c268601d8}
      \strng{authorbibnamehash}{7e821cc9ab174b709c334e7c268601d8}
      \strng{authornamehash}{c5d07d4a8918ca9ac03995189e27ade5}
      \strng{authorfullhash}{f78ae9babdcf9c1a81b98c9ea10ccba5}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{arXiv:2212.06817}
      \field{shorttitle}{{{RT-1}}}
      \field{title}{{{RT-1}}: {{Robotics Transformer}} for {{Real-World Control}} at {{Scale}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2212.06817
      \endverb
      \verb{eprint}
      \verb 2212.06817
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/PS6RZ8ZS/Brohan et al. - 2023 - RT-1 Robotics Transformer for Real-World Control at Scale.pdf
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{byravanImaginedValueGradients2019}{misc}{}
      \name{author}{9}{}{%
        {{un=0,uniquepart=base,hash=92babce6d69105729d815e93c1bdb54c}{%
           family={Byravan},
           familyi={B\bibinitperiod},
           given={Arunkumar},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d52162d1c5497f647e12128f74d58da4}{%
           family={Springenberg},
           familyi={S\bibinitperiod},
           given={Jost\bibnamedelima Tobias},
           giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=528d31a6b5c1231e01391e2597dd5491}{%
           family={Abdolmaleki},
           familyi={A\bibinitperiod},
           given={Abbas},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fc9873fa16235237944ddb12fc2db97d}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Roland},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=060d57062477e5aa7705774f29f438a2}{%
           family={Neunert},
           familyi={N\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=88b7db69f42e22293022f02f63af62cf}{%
           family={Lampe},
           familyi={L\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4b2968a035ed438b3b9d4f7e3dcb3bff}{%
           family={Siegel},
           familyi={S\bibinitperiod},
           given={Noah},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=231312991eab5915498d6c19c2a8cd4e}{%
           family={Heess},
           familyi={H\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{cf7be3452ad5edfe721b7f3f2f15ae66}
      \strng{fullhash}{967a8b62fadf406697f4d635cca3b7f3}
      \strng{bibnamehash}{967a8b62fadf406697f4d635cca3b7f3}
      \strng{authorbibnamehash}{967a8b62fadf406697f4d635cca3b7f3}
      \strng{authornamehash}{cf7be3452ad5edfe721b7f3f2f15ae66}
      \strng{authorfullhash}{967a8b62fadf406697f4d635cca3b7f3}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Humans are masters at quickly learning many complex tasks, relying on an approximate understanding of the dynamics of their environments. In much the same way, we would like our learning agents to quickly adapt to new tasks. In this paper, we explore how model-based Reinforcement Learning (RL) can facilitate transfer to new tasks. We develop an algorithm that learns an action-conditional, predictive model of expected future observations, rewards and values from which a policy can be derived by following the gradient of the estimated value along imagined trajectories. We show how robust policy optimization can be achieved in robot manipulation tasks even with approximate models that are learned directly from vision and proprioception. We evaluate the efficacy of our approach in a transfer learning scenario, re-using previously learned models on tasks with different reward structures and visual distractors, and show a significant improvement in learning speed compared to strong off-policy baselines. Videos with results can be found at https://sites.google.com/view/ivg-corl19}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1910.04142}
      \field{shorttitle}{Imagined {{Value Gradients}}}
      \field{title}{Imagined {{Value Gradients}}: {{Model-Based Policy Optimization}} with {{Transferable Latent Dynamics Models}}}
      \field{urlday}{26}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1910.04142
      \endverb
      \verb{eprint}
      \verb 1910.04142
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/F8894SKH/Byravan et al. - 2019 - Imagined Value Gradients Model-Based Policy Optimization with Transferable Latent Dynamics Models.pdf;/home/james/Zotero/storage/EIPU6XZ9/1910.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics}
    \endentry
    \entry{castro18dopamine}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=cd36c2abe3c5c9ea4b21e5258e5f3a37}{%
           family={Castro},
           familyi={C\bibinitperiod},
           given={Pablo\bibnamedelima Samuel},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef2e4463869382eb399d48b9f47403ab}{%
           family={Moitra},
           familyi={M\bibinitperiod},
           given={Subhodeep},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=592464775b22487321b185921f1faeb2}{%
           family={Gelada},
           familyi={G\bibinitperiod},
           given={Carles},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3ac9e7dae03c093a86970853c449196}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Saurabh},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ff971ecddde7a07f22ce8cf2802bfd41}
      \strng{fullhash}{57bac6fc4d83645cb17e6ca14f921295}
      \strng{bibnamehash}{57bac6fc4d83645cb17e6ca14f921295}
      \strng{authorbibnamehash}{57bac6fc4d83645cb17e6ca14f921295}
      \strng{authornamehash}{ff971ecddde7a07f22ce8cf2802bfd41}
      \strng{authorfullhash}{57bac6fc4d83645cb17e6ca14f921295}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{title}{Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning}
      \field{year}{2018}
      \verb{urlraw}
      \verb http://arxiv.org/abs/1812.06110
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1812.06110
      \endverb
    \endentry
    \entry{chenExploringSimpleSiamese2020}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=ce10870c303bf2f78994acd2df305b39}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Xinlei},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{fullhash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{bibnamehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{authorbibnamehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{authornamehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{authorfullhash}{61962cb16a5a83c9961a624ef2c87fb9}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Siamese networks have become a common structure in various recent models for unsupervised visual representation learning. These models maximize the similarity between two augmentations of one image, subject to certain conditions for avoiding collapsing solutions. In this paper, we report surprising empirical results that simple Siamese networks can learn meaningful representations even using none of the following: (i) negative sample pairs, (ii) large batches, (iii) momentum encoders. Our experiments show that collapsing solutions do exist for the loss and structure, but a stop-gradient operation plays an essential role in preventing collapsing. We provide a hypothesis on the implication of stop-gradient, and further show proof-of-concept experiments verifying it. Our "SimSiam" method achieves competitive results on ImageNet and downstream tasks. We hope this simple baseline will motivate people to rethink the roles of Siamese architectures for unsupervised representation learning. Code will be made available.}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2011.10566}
      \field{title}{Exploring {{Simple Siamese Representation Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2011.10566
      \endverb
      \verb{eprint}
      \verb 2011.10566
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/9FVXCAVE/Chen and He - 2020 - Exploring Simple Siamese Representation Learning.pdf;/home/james/Zotero/storage/5PPK88RE/2011.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{chopraLearningSimilarityMetric2005}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=5eb35fffcf75e0932c31b19f424238fe}{%
           family={Chopra},
           familyi={C\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ae95119be0d9d86ffdec9f3142af353e}{%
           family={Hadsell},
           familyi={H\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9ae8dc3a930d73e11e1b22a9ef065055}{%
           family={LeCun},
           familyi={L\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b449f514f35191985ab69f9a22beec46}
      \strng{fullhash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \strng{bibnamehash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \strng{authorbibnamehash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \strng{authornamehash}{b449f514f35191985ab69f9a22beec46}
      \strng{authorfullhash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the "semantic" distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves.}
      \field{issn}{1063-6919}
      \field{journaltitle}{2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)}
      \field{month}{6}
      \field{title}{Learning a Similarity Metric Discriminatively, with Application to Face Verification}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{1}
      \field{year}{2005}
      \field{urldateera}{ce}
      \field{pages}{539\bibrangedash 546 vol. 1}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1109/CVPR.2005.202
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/IUFWXFXS/1467314.html
      \endverb
      \keyw{Artificial neural networks,Character generation,Drives,Face recognition,Glass,Robustness,Spatial databases,Support vector machine classification,Support vector machines,System testing}
    \endentry
    \entry{chuaDeepReinforcementLearning2018}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=5a627648d87fbb1650833684cd5d6fa9}{%
           family={Chua},
           familyi={C\bibinitperiod},
           given={Kurtland},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=864584c60b808b517f2a06c664ec116a}{%
           family={Calandra},
           familyi={C\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b4f598eab77331a1e5a5f3c9ce3ed17d}{%
           family={McAllister},
           familyi={M\bibinitperiod},
           given={Rowan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{f1e092bd96dfea65399b02a0fd64242a}
      \strng{fullhash}{56a8bebfe5f201534436e41113469d43}
      \strng{bibnamehash}{56a8bebfe5f201534436e41113469d43}
      \strng{authorbibnamehash}{56a8bebfe5f201534436e41113469d43}
      \strng{authornamehash}{f1e092bd96dfea65399b02a0fd64242a}
      \strng{authorfullhash}{56a8bebfe5f201534436e41113469d43}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:1805.12114}
      \field{title}{Deep {{Reinforcement Learning}} in a {{Handful}} of {{Trials}} Using {{Probabilistic Dynamics Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1805.12114
      \endverb
      \verb{eprint}
      \verb 1805.12114
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Chua et al_2018_Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics.pdf;/home/james/Zotero/storage/G256PNY5/1805.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{deboerTutorialCrossEntropyMethod2005}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=543cc24c01bba57efb3df90f45ed0292}{%
           family={{de Boer}},
           familyi={d\bibinitperiod},
           given={Pieter-Tjerk},
           giveni={P\bibinithyphendelim T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bdeae732a8a2bf629098c06d021dceb5}{%
           family={Kroese},
           familyi={K\bibinitperiod},
           given={Dirk\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cb41e7e037f839138136e53088340de0}{%
           family={Mannor},
           familyi={M\bibinitperiod},
           given={Shie},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74bcd83ba931505aa6a17e6d83add62d}{%
           family={Rubinstein},
           familyi={R\bibinitperiod},
           given={Reuven\bibnamedelima Y.},
           giveni={R\bibinitperiod\bibinitdelim Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b24a48d8f9f915d4abfaae4e4d43fdf8}
      \strng{fullhash}{18c1837b8e3ea7181baf4054fc0958a0}
      \strng{bibnamehash}{18c1837b8e3ea7181baf4054fc0958a0}
      \strng{authorbibnamehash}{18c1837b8e3ea7181baf4054fc0958a0}
      \strng{authornamehash}{b24a48d8f9f915d4abfaae4e4d43fdf8}
      \strng{authorfullhash}{18c1837b8e3ea7181baf4054fc0958a0}
      \field{sortinit}{d}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The cross-entropy (CE) method is a new generic approach to combinatorial and multi-extremal optimization and rare event simulation. The purpose of this tutorial is to give a gentle introduction to the CE method. We present the CE methodology, the basic algorithm and its modifications, and discuss applications in combinatorial optimization and machine learning.}
      \field{issn}{1572-9338}
      \field{journaltitle}{Annals of Operations Research}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{1}
      \field{title}{A {{Tutorial}} on the {{Cross-Entropy Method}}}
      \field{urlday}{28}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{134}
      \field{year}{2005}
      \field{urldateera}{ce}
      \field{pages}{19\bibrangedash 67}
      \range{pages}{49}
      \verb{doi}
      \verb 10.1007/s10479-005-5724-z
      \endverb
      \keyw{cross-entropy method,machine learning,Monte-Carlo simulation,randomized optimization,rare events}
    \endentry
    \entry{devlinBERTPretrainingDeep2019}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=13202969e372bc82318f9629cbdd199b}{%
           family={Devlin},
           familyi={D\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a45784fe7163b45f11d166564f5d24b6}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Ming-Wei},
           giveni={M\bibinithyphendelim W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8dde73b4194f5bc4230c4808f3fc1534}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kenton},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b92aa283415413bb8d2a1548716d0c7d}{%
           family={Toutanova},
           familyi={T\bibinitperiod},
           given={Kristina},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ad8e2e2a80d28ade21e86852b804fc9b}
      \strng{fullhash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{bibnamehash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authorbibnamehash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authornamehash}{ad8e2e2a80d28ade21e86852b804fc9b}
      \strng{authorfullhash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:1810.04805}
      \field{shorttitle}{{{BERT}}}
      \field{title}{{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1810.04805
      \endverb
      \verb{eprint}
      \verb 1810.04805
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Devlin et al_2019_BERT.pdf;/home/james/Zotero/storage/EGGQPIYZ/1810.html
      \endverb
      \keyw{Computer Science - Computation and Language,LMs,Transformers}
    \endentry
    \entry{dorkaDynamicUpdatetoDataRatio2023}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=5a7a8c9907b9dc822d54ed243ca623b7}{%
           family={Dorka},
           familyi={D\bibinitperiod},
           given={Nicolai},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3861b5daf60d03468cc6b9c900fbeb0b}{%
           family={Welschehold},
           familyi={W\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98f4ab1bc2ac191d8f8a0651315ce9c0}{%
           family={Burgard},
           familyi={B\bibinitperiod},
           given={Wolfram},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ec4dc6b46663e18265ce610d3ef30049}
      \strng{fullhash}{10553f199504d62f0f104c83d2bf14f4}
      \strng{bibnamehash}{10553f199504d62f0f104c83d2bf14f4}
      \strng{authorbibnamehash}{10553f199504d62f0f104c83d2bf14f4}
      \strng{authornamehash}{ec4dc6b46663e18265ce610d3ef30049}
      \strng{authorfullhash}{10553f199504d62f0f104c83d2bf14f4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Early stopping based on the validation set performance is a popular approach to find the right balance between under- and overfitting in the context of supervised learning. However, in reinforcement learning, even for supervised sub-problems such as world model learning, early stopping is not applicable as the dataset is continually evolving. As a solution, we propose a new general method that dynamically adjusts the update to data (UTD) ratio during training based on under- and overfitting detection on a small subset of the continuously collected experience not used for training. We apply our method to DreamerV2, a state-of-the-art model-based reinforcement learning algorithm, and evaluate it on the DeepMind Control Suite and the Atari \$100\$k benchmark. The results demonstrate that one can better balance under- and overestimation by adjusting the UTD ratio with our approach compared to the default setting in DreamerV2 and that it is competitive with an extensive hyperparameter search which is not feasible for many applications. Our method eliminates the need to set the UTD hyperparameter by hand and even leads to a higher robustness with regard to other learning-related hyperparameters further reducing the amount of necessary tuning.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2303.10144}
      \field{shorttitle}{Dynamic {{Update-to-Data Ratio}}}
      \field{title}{Dynamic {{Update-to-Data Ratio}}: {{Minimizing World Model Overfitting}}}
      \field{urlday}{28}
      \field{urlmonth}{10}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2303.10144
      \endverb
      \verb{eprint}
      \verb 2303.10144
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/QYEQFJ65/Dorka et al. - 2023 - Dynamic Update-to-Data Ratio Minimizing World Model Overfitting.pdf;/home/james/Zotero/storage/W3H9549Z/2303.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{doroSampleEfficientReinforcementLearning2022}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=e09d377eb804fa206349bcc1d7162ddf}{%
           family={D'Oro},
           familyi={D\bibinitperiod},
           given={Pierluca},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d078365da0923eced35cd9345318ca0}{%
           family={Nikishin},
           familyi={N\bibinitperiod},
           given={Evgenii},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9417eec56d7db4d07719bbb7fe3bcdd}{%
           family={Bacon},
           familyi={B\bibinitperiod},
           given={Pierre-Luc},
           giveni={P\bibinithyphendelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ce2ba9e0396ea93595cefce10a25f9d1}
      \strng{fullhash}{9acc5d19062a330a79f7b970244a0ad9}
      \strng{bibnamehash}{9acc5d19062a330a79f7b970244a0ad9}
      \strng{authorbibnamehash}{9acc5d19062a330a79f7b970244a0ad9}
      \strng{authornamehash}{ce2ba9e0396ea93595cefce10a25f9d1}
      \strng{authorfullhash}{9acc5d19062a330a79f7b970244a0ad9}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Increasing the replay ratio, the number of updates of an agent's parameters per environment interaction, is an appealing strategy for improving the sample efficiency of deep reinforcement learning algorithms. In this work, we show that fully or partially resetting the parameters of deep reinforcement learning agents causes better replay ratio scaling capabilities to emerge. We push the limits of the sample efficiency of carefully-modified algorithms by training them using an order of magnitude more updates than usual, significantly improving their performance in the Atari 100k and DeepMind Control Suite benchmarks. We then provide an analysis of the design choices required for favorable replay ratio scaling to be possible and discuss inherent limits and tradeoffs.}
      \field{journaltitle}{The {{Eleventh International Conference}} on {{Learning Representations}}}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Sample-{{Efficient Reinforcement Learning}} by {{Breaking}} the {{Replay Ratio Barrier}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/56KZMTMH/D'Oro et al. - 2022 - Sample-Efficient Reinforcement Learning by Breakin.pdf
      \endverb
    \endentry
    \entry{farquharTreeQNATreeCDifferentiable2018}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=de7fc27bb6e6105440cd3039a5c9b684}{%
           family={Farquhar},
           familyi={F\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b3ff4029884ead9928954ea33714192c}{%
           family={RocktÃ¤schel},
           familyi={R\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a16299a48b44fa1c82d5c13151401004}{%
           family={Igl},
           familyi={I\bibinitperiod},
           given={Maximilian},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d05819cf2b4fe22ba972c9b2b5d8c9d}{%
           family={Whiteson},
           familyi={W\bibinitperiod},
           given={Shimon},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a674e854056b940bb7a84a7b613b17a0}
      \strng{fullhash}{d82f83d049512ecb33743027292cf97a}
      \strng{bibnamehash}{d82f83d049512ecb33743027292cf97a}
      \strng{authorbibnamehash}{d82f83d049512ecb33743027292cf97a}
      \strng{authornamehash}{a674e854056b940bb7a84a7b613b17a0}
      \strng{authorfullhash}{d82f83d049512ecb33743027292cf97a}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Combining deep model-free reinforcement learning with on-line planning is a promising approach to building on the successes of deep RL. On-line planning with look-ahead trees has proven successful in environments where transition models are known a priori. However, in complex environments where transition models need to be learned from data, the deficiencies of learned models have limited their utility for planning. To address these challenges, we propose TreeQN, a differentiable, recursive, tree-structured model that serves as a drop-in replacement for any value function network in deep RL with discrete actions. TreeQN dynamically constructs a tree by recursively applying a transition model in a learned abstract state space and then aggregating predicted rewards and state-values using a tree backup to estimate Q-values. We also propose ATreeC, an actor-critic variant that augments TreeQN with a softmax layer to form a stochastic policy network. Both approaches are trained end-to-end, such that the learned model is optimised for its actual use in the tree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a box-pushing task, as well as n-step DQN and value prediction networks (Oh et al. 2017) on multiple Atari games. Furthermore, we present ablation studies that demonstrate the effect of different auxiliary losses on learning transition models.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1710.11417}
      \field{shorttitle}{{{TreeQN}} and {{ATreeC}}}
      \field{title}{{{TreeQN}} and {{ATreeC}}: {{Differentiable Tree-Structured Models}} for {{Deep Reinforcement Learning}}}
      \field{urlday}{2}
      \field{urlmonth}{4}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1710.11417
      \endverb
      \verb{eprint}
      \verb 1710.11417
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Farquhar et al_2018_TreeQN and ATreeC.pdf;/home/james/Zotero/storage/4JU2SQAH/1710.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning}
    \endentry
    \entry{fortunatoNoisyNetworksExploration2019}{misc}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=dfc7f8069848dbc66435c3acc3172871}{%
           family={Fortunato},
           familyi={F\bibinitperiod},
           given={Meire},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c08c463bfe294c33c09d1f2c5a3b1e24}{%
           family={Azar},
           familyi={A\bibinitperiod},
           given={Mohammad\bibnamedelima Gheshlaghi},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f31963abd2aa43dd3aafc40aa1252a05}{%
           family={Piot},
           familyi={P\bibinitperiod},
           given={Bilal},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d3255f46b9e59e322e3fba6ce3daa11}{%
           family={Menick},
           familyi={M\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d78832306745d08c2a95154ee3e0a1b7}{%
           family={Osband},
           familyi={O\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fef11d6229576d005bc4434cdcf7091e}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Vlad},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ce2c8d8bf1e96e9845a930fb6264204f}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={Remi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fa8a4817aef70fffae62a48b98481ef7}{%
           family={Pietquin},
           familyi={P\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24fe1af011227491e54e299ba4cb24b5}{%
           family={Blundell},
           familyi={B\bibinitperiod},
           given={Charles},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=afdf5ed50a24cdca0f42433e4f4848d5}{%
           family={Legg},
           familyi={L\bibinitperiod},
           given={Shane},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8d92fb6b77c2a76599fe0b1aeffffa08}
      \strng{fullhash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \strng{bibnamehash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \strng{authorbibnamehash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \strng{authornamehash}{8d92fb6b77c2a76599fe0b1aeffffa08}
      \strng{authorfullhash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce NoisyNet, a deep reinforcement learning agent with parametric noise added to its weights, and show that the induced stochasticity of the agent's policy can be used to aid efficient exploration. The parameters of the noise are learned with gradient descent along with the remaining network weights. NoisyNet is straightforward to implement and adds little computational overhead. We find that replacing the conventional exploration heuristics for A3C, DQN and dueling agents (entropy reward and \${\textbackslash}epsilon\$-greedy respectively) with NoisyNet yields substantially higher scores for a wide range of Atari games, in some cases advancing the agent from sub to super-human performance.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1706.10295}
      \field{title}{Noisy {{Networks}} for {{Exploration}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1706.10295
      \endverb
      \verb{eprint}
      \verb 1706.10295
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/QK3I2G27/Fortunato et al. - 2019 - Noisy Networks for Exploration.pdf;/home/james/Zotero/storage/VYV9II9Y/1706.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{francois-lavetHowDiscountDeep2016}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=ef083153331d849d68dca175e0afd86d}{%
           family={{FranÃ§ois-Lavet}},
           familyi={F\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3c261c6c8f7ce19f21763516b0af342}{%
           family={Fonteneau},
           familyi={F\bibinitperiod},
           given={Raphael},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6fbe33fd3b6a25f54629f311cb113551}{%
           family={Ernst},
           familyi={E\bibinitperiod},
           given={Damien},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a60ab02792ecd3844cbf1a41d97ebc40}
      \strng{fullhash}{4728e62162f069458d32b659d9c2ec07}
      \strng{bibnamehash}{4728e62162f069458d32b659d9c2ec07}
      \strng{authorbibnamehash}{4728e62162f069458d32b659d9c2ec07}
      \strng{authornamehash}{a60ab02792ecd3844cbf1a41d97ebc40}
      \strng{authorfullhash}{4728e62162f069458d32b659d9c2ec07}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real-world complexity. Using these results as a benchmark, we discuss the role that the discount factor may play in the quality of the learning process of a deep Q-network (DQN). When the discount factor progressively increases up to its final value, we empirically show that it is possible to significantly reduce the number of learning steps. When used in conjunction with a varying learning rate, we empirically show that it outperforms original DQN on several experiments. We relate this phenomenon with the instabilities of neural networks when they are used in an approximate Dynamic Programming setting. We also describe the possibility to fall within a local optimum during the learning process, thus connecting our discussion with the exploration/exploitation dilemma.}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:1512.02011}
      \field{shorttitle}{How to {{Discount Deep Reinforcement Learning}}}
      \field{title}{How to {{Discount Deep Reinforcement Learning}}: {{Towards New Dynamic Strategies}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1512.02011
      \endverb
      \verb{eprint}
      \verb 1512.02011
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/TWXWRW7G/FranÃ§ois-Lavet et al. - 2016 - How to Discount Deep Reinforcement Learning Towards New Dynamic Strategies.pdf;/home/james/Zotero/storage/QP5YHIDA/1512.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{gidarisUnsupervisedRepresentationLearning2018}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=46e96c4d02697413846440921900e9ce}{%
           family={Gidaris},
           familyi={G\bibinitperiod},
           given={Spyros},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f12bafa3883b5e94ed5bbcab458128c4}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Praveer},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b19df6325edc9e76749ac30a9d962c7}{%
           family={Komodakis},
           familyi={K\bibinitperiod},
           given={Nikos},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{91463ca4ff04b91c7362bf8123b8141a}
      \strng{fullhash}{6803481e0cd09c5bddcfc136edc99d2b}
      \strng{bibnamehash}{6803481e0cd09c5bddcfc136edc99d2b}
      \strng{authorbibnamehash}{6803481e0cd09c5bddcfc136edc99d2b}
      \strng{authornamehash}{91463ca4ff04b91c7362bf8123b8141a}
      \strng{authorfullhash}{6803481e0cd09c5bddcfc136edc99d2b}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4\% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: https://github.com/gidariss/FeatureLearningRotNet .}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1803.07728}
      \field{title}{Unsupervised {{Representation Learning}} by {{Predicting Image Rotations}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1803.07728
      \endverb
      \verb{eprint}
      \verb 1803.07728
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/J5T2P75U/Gidaris et al. - 2018 - Unsupervised Representation Learning by Predicting Image Rotations.pdf;/home/james/Zotero/storage/M5YVEZ3L/1803.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{grillBootstrapYourOwn2020}{misc}{}
      \name{author}{14}{}{%
        {{un=0,uniquepart=base,hash=152351efb2aa1ec8470b935d63d68a21}{%
           family={Grill},
           familyi={G\bibinitperiod},
           given={Jean-Bastien},
           giveni={J\bibinithyphendelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3af936a4e6dd4b0086458a45dfac6da}{%
           family={Strub},
           familyi={S\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba254bce2809834e8b51cd526e20c1c2}{%
           family={AltchÃ©},
           familyi={A\bibinitperiod},
           given={Florent},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=53e127de75e9241aa5b25e378a90fea1}{%
           family={Tallec},
           familyi={T\bibinitperiod},
           given={Corentin},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bb66a15fe0e5fcdb7d3ba216e5cf9974}{%
           family={Richemond},
           familyi={R\bibinitperiod},
           given={Pierre\bibnamedelima H.},
           giveni={P\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eee8c4b85d5c4e1f4bc70218d34ba69d}{%
           family={Buchatskaya},
           familyi={B\bibinitperiod},
           given={Elena},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=96b67cea31d7dd5c10af974faba91947}{%
           family={Doersch},
           familyi={D\bibinitperiod},
           given={Carl},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8ff346cbfa06024a8dd0afe01bd765a}{%
           family={Pires},
           familyi={P\bibinitperiod},
           given={Bernardo\bibnamedelima Avila},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=610da8bda1894dde64553a72f1a275ea}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Zhaohan\bibnamedelima Daniel},
           giveni={Z\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c08c463bfe294c33c09d1f2c5a3b1e24}{%
           family={Azar},
           familyi={A\bibinitperiod},
           given={Mohammad\bibnamedelima Gheshlaghi},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f31963abd2aa43dd3aafc40aa1252a05}{%
           family={Piot},
           familyi={P\bibinitperiod},
           given={Bilal},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d8fa91764a27bf97b87fdcac885745d}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={RÃ©mi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e25b9b55e0d33d8e554fb428b0122ba9}{%
           family={Valko},
           familyi={V\bibinitperiod},
           given={Michal},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{37900d0162e64eae8ddfb8300b650795}
      \strng{fullhash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \strng{bibnamehash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \strng{authorbibnamehash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \strng{authornamehash}{37900d0162e64eae8ddfb8300b650795}
      \strng{authorfullhash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches \$74.3{\textbackslash}\%\$ top-1 classification accuracy on ImageNet using a linear evaluation with a ResNet-50 architecture and \$79.6{\textbackslash}\%\$ with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks. Our implementation and pretrained models are given on GitHub.}
      \field{eprinttype}{arXiv}
      \field{month}{9}
      \field{number}{arXiv:2006.07733}
      \field{shorttitle}{Bootstrap Your Own Latent}
      \field{title}{Bootstrap Your Own Latent: {{A}} New Approach to Self-Supervised {{Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2006.07733
      \endverb
      \verb{eprint}
      \verb 2006.07733
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/BR83I5BP/Grill et al. - 2020 - Bootstrap your own latent A new approach to self-supervised Learning.pdf;/home/james/Zotero/storage/EF8GD23Y/2006.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{haRecurrentWorldModels2018}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=4467056eb9d0a44c1ec21bbb4d6152c5}{%
           family={Ha},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=288bdbcfe1b91ad7484d7a24f74f99ed}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={JÃ¼rgen},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{fullhash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{bibnamehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{authorbibnamehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{authornamehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{authorfullhash}{ac33097a207e3840f68fa6e4bd34710c}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A generative recurrent neural network is quickly trained in an unsupervised manner to model popular reinforcement learning environments through compressed spatio-temporal representations. The world model's extracted features are fed into compact and simple policies trained by evolution, achieving state of the art results in various environments. We also train our agent entirely inside of an environment generated by its own internal world model, and transfer this policy back into the actual environment. Interactive version of this paper is available at https://worldmodels.github.io}
      \field{journaltitle}{Advances in {{Neural Information Processing Systems}}}
      \field{title}{Recurrent {{World Models Facilitate Policy Evolution}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{31}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/9YXWGU7I/Ha and Schmidhuber - 2018 - Recurrent World Models Facilitate Policy Evolution.pdf
      \endverb
    \endentry
    \entry{haarnojaSoftActorCriticOffPolicy2018}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=45b14f55dd7ae28cb6cb2e23e4a168b9}{%
           family={Haarnoja},
           familyi={H\bibinitperiod},
           given={Tuomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=519033a7338e5ef684c77d4d04748a4a}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Aurick},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{fullhash}{951e86110020d3107317b3e819f3d92d}
      \strng{bibnamehash}{951e86110020d3107317b3e819f3d92d}
      \strng{authorbibnamehash}{951e86110020d3107317b3e819f3d92d}
      \strng{authornamehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{authorfullhash}{951e86110020d3107317b3e819f3d92d}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{number}{arXiv:1801.01290}
      \field{shorttitle}{Soft {{Actor-Critic}}}
      \field{title}{Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}}
      \field{urlday}{14}
      \field{urlmonth}{6}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1801.01290
      \endverb
      \verb{eprint}
      \verb 1801.01290
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Haarnoja et al_2018_Soft Actor-Critic.pdf;/home/james/Zotero/storage/YYPH8Z7L/1801.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{haarnojaSoftActorCriticAlgorithms2019}{misc}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=45b14f55dd7ae28cb6cb2e23e4a168b9}{%
           family={Haarnoja},
           familyi={H\bibinitperiod},
           given={Tuomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=519033a7338e5ef684c77d4d04748a4a}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Aurick},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2bf28b92c31c717feee2c15487657b25}{%
           family={Hartikainen},
           familyi={H\bibinitperiod},
           given={Kristian},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=641a3f5d5ce834c4b56fb672c5df0207}{%
           family={Tucker},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d235634814ed266793a4de24b71955e6}{%
           family={Ha},
           familyi={H\bibinitperiod},
           given={Sehoon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aaa7cb90b2e1cc2079b5e8a087a903c9}{%
           family={Tan},
           familyi={T\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bbba0ccb50436105a4134d24509b62d7}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Vikash},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fde29d8aa12ec2aa9ab89c495df350fb}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Henry},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d0792eb04b685020eafedbc871aeb84f}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Abhishek},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{fullhash}{c6ac1e78375b5b1cb1c472544f2557df}
      \strng{bibnamehash}{c6ac1e78375b5b1cb1c472544f2557df}
      \strng{authorbibnamehash}{c6ac1e78375b5b1cb1c472544f2557df}
      \strng{authornamehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{authorfullhash}{c6ac1e78375b5b1cb1c472544f2557df}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:1812.05905}
      \field{title}{Soft {{Actor-Critic Algorithms}} and {{Applications}}}
      \field{urlday}{24}
      \field{urlmonth}{8}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1812.05905
      \endverb
      \verb{eprint}
      \verb 1812.05905
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Haarnoja et al_2019_Soft Actor-Critic Algorithms and Applications.pdf;/home/james/Zotero/storage/LAQAN6WZ/1812.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{hafnerLearningLatentDynamics2019}{misc}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=283cecbdc579f4c9098a22907b254877}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4115de371d87baba0d4934fd66756db5}{%
           family={Villegas},
           familyi={V\bibinitperiod},
           given={Ruben},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4467056eb9d0a44c1ec21bbb4d6152c5}{%
           family={Ha},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d09ea8631bf43468107b5ef02c5195aa}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Honglak},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=067f1e3d219657d2c89fbaa1325dbfab}{%
           family={Davidson},
           familyi={D\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \strng{bibnamehash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \strng{authorbibnamehash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1811.04551}
      \field{title}{Learning {{Latent Dynamics}} for {{Planning}} from {{Pixels}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1811.04551
      \endverb
      \verb{eprint}
      \verb 1811.04551
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hafner et al_2019_Learning Latent Dynamics for Planning from Pixels.pdf;/home/james/Zotero/storage/75LXKK22/1811.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{hafnerDreamControlLearning2020}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e34c5aa67281924804d54d88e58ca38a}{%
           family={Norouzi},
           familyi={N\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \strng{bibnamehash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \strng{authorbibnamehash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Learned world models summarize an agent's experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1912.01603}
      \field{shorttitle}{Dream to {{Control}}}
      \field{title}{Dream to {{Control}}: {{Learning Behaviors}} by {{Latent Imagination}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.01603
      \endverb
      \verb{eprint}
      \verb 1912.01603
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hafner et al_2020_Dream to Control.pdf;/home/james/Zotero/storage/95G88IHI/1912.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{hafnerMasteringAtariDiscrete2022}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e34c5aa67281924804d54d88e58ca38a}{%
           family={Norouzi},
           familyi={N\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{71b9635f1977d0972d355d4c4a573913}
      \strng{bibnamehash}{71b9635f1977d0972d355d4c4a573913}
      \strng{authorbibnamehash}{71b9635f1977d0972d355d4c4a573913}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{71b9635f1977d0972d355d4c4a573913}
      \field{extraname}{3}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, Dreamer V2 reaches 200M frames and surpasses the final performance of the top single-GPU agents IQN and Rainbow. DreamerV2 is also applicable to tasks with continuous actions, where it learns an accurate world model of a complex humanoid robot and solves stand-up and walking from only pixel inputs.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{number}{arXiv:2010.02193}
      \field{title}{Mastering {{Atari}} with {{Discrete World Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2010.02193
      \endverb
      \verb{eprint}
      \verb 2010.02193
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hafner et al_2022_Mastering Atari with Discrete World Models.pdf;/home/james/Zotero/storage/UA2F47NY/2010.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{hafnerMasteringDiverseDomains2024}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2caecdc0ecdc4f891514f2ff9518e3cb}{%
           family={Pasukonis},
           familyi={P\bibinitperiod},
           given={Jurgis},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{c697658c389c65d7a42da010daf15748}
      \strng{bibnamehash}{c697658c389c65d7a42da010daf15748}
      \strng{authorbibnamehash}{c697658c389c65d7a42da010daf15748}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{c697658c389c65d7a42da010daf15748}
      \field{extraname}{4}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Developing a general algorithm that learns to solve tasks across a wide range of applications has been a fundamental challenge in artificial intelligence. Although current reinforcement learning algorithms can be readily applied to tasks similar to what they have been developed for, configuring them for new application domains requires significant human expertise and experimentation. We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration. Dreamer learns a model of the environment and improves its behavior by imagining future scenarios. Robustness techniques based on normalization, balancing, and transformations enable stable learning across domains. Applied out of the box, Dreamer is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula. This achievement has been posed as a significant challenge in artificial intelligence that requires exploring farsighted strategies from pixels and sparse rewards in an open world. Our work allows solving challenging control problems without extensive experimentation, making reinforcement learning broadly applicable.}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:2301.04104}
      \field{title}{Mastering {{Diverse Domains}} through {{World Models}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2301.04104
      \endverb
      \verb{eprint}
      \verb 2301.04104
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/HYS3S98G/Hafner et al. - 2024 - Mastering Diverse Domains through World Models.pdf;/home/james/Zotero/storage/R4M4U9NX/2301.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{heMomentumContrastUnsupervised2020}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e68b3965779a4e603c10d027dd82b5c1}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Haoqi},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b626dcc418c3a5c74cfaa4c5e643a71f}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yuxin},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=843b6293b24d49cdfdcda48e1ccd7eb3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Saining},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{52cb9810506b099972148981d95ec86c}
      \strng{bibnamehash}{52cb9810506b099972148981d95ec86c}
      \strng{authorbibnamehash}{52cb9810506b099972148981d95ec86c}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{52cb9810506b099972148981d95ec86c}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1911.05722}
      \field{title}{Momentum {{Contrast}} for {{Unsupervised Visual Representation Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1911.05722
      \endverb
      \verb{eprint}
      \verb 1911.05722
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/PL8SZT3I/He et al. - 2020 - Momentum Contrast for Unsupervised Visual Representation Learning.pdf;/home/james/Zotero/storage/UNCHHJ6N/1911.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{heMaskedAutoencodersAre2021}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ce10870c303bf2f78994acd2df305b39}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Xinlei},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=843b6293b24d49cdfdcda48e1ccd7eb3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Saining},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46e2e0b282bd98dcc736b344f4c7274f}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yanghao},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ecd149fdcb3e0503881d49e545744c3d}{%
           family={DollÃ¡r},
           familyi={D\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{720293b27fe84a23031231f283c72cd1}
      \strng{bibnamehash}{720293b27fe84a23031231f283c72cd1}
      \strng{authorbibnamehash}{720293b27fe84a23031231f283c72cd1}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{720293b27fe84a23031231f283c72cd1}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75\%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3x or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8\%) among methods that use only ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pre-training and shows promising scaling behavior.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:2111.06377}
      \field{title}{Masked {{Autoencoders Are Scalable Vision Learners}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2111.06377
      \endverb
      \verb{eprint}
      \verb 2111.06377
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/He et al_2021_Masked Autoencoders Are Scalable Vision Learners.pdf;/home/james/Zotero/storage/4EWC2432/2111.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{hesselRainbowCombiningImprovements2017}{misc}{}
      \name{author}{10}{}{%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2627fbd818853e670084cf0b17107962}{%
           family={Modayil},
           familyi={M\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e75f0b2e9c29c175e6320c1e96cdf5c8}{%
           family={{van Hasselt}},
           familyi={v\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46cc21fb5dec973c05ceb0f321e02ca0}{%
           family={Ostrovski},
           familyi={O\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5a44cbf0d05e4c50b512bb0c1368d2f}{%
           family={Dabney},
           familyi={D\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c1a26cb7f963abdf071da408366e83a1}{%
           family={Horgan},
           familyi={H\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f31963abd2aa43dd3aafc40aa1252a05}{%
           family={Piot},
           familyi={P\bibinitperiod},
           given={Bilal},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50bebf4ece6d98f0ecef1bcff295ab7e}{%
           family={Azar},
           familyi={A\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{04c4fc38c232f5c2360309d90f2dc80e}
      \strng{fullhash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \strng{bibnamehash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \strng{authorbibnamehash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \strng{authornamehash}{04c4fc38c232f5c2360309d90f2dc80e}
      \strng{authorfullhash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1710.02298}
      \field{shorttitle}{Rainbow}
      \field{title}{Rainbow: {{Combining Improvements}} in {{Deep Reinforcement Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1710.02298
      \endverb
      \verb{eprint}
      \verb 1710.02298
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hessel et al_2017_Rainbow.pdf;/home/james/Zotero/storage/R45S76E4/1710.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{huang2022cleanrl}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=a485c9f2edbeda28fc6122a6d8ef9913}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Shengyi},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=32e389f8fcbcf0f82233cdfb17fc7c2e}{%
           family={Dossa},
           familyi={D\bibinitperiod},
           given={Rousslan\bibnamedelimb Fernand\bibnamedelima Julien},
           giveni={R\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f1dee49ff1f7c58167e78dd52894041e}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Chang},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8cc4095acb7526b1751dcfdb493d8844}{%
           family={Braga},
           familyi={B\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4c84046e785d39de01f660f64cbadb3e}{%
           family={Chakraborty},
           familyi={C\bibinitperiod},
           given={Dipam},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0fb774b6fae5ad2ed906e0161fa9f0bd}{%
           family={Mehta},
           familyi={M\bibinitperiod},
           given={Kinal},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=59f8577a44395d13588ed7a194581fdb}{%
           family={AraÃºjo},
           familyi={A\bibinitperiod},
           given={JoÃ£o\bibnamedelima G.M.},
           giveni={J\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{33f5845a5b5ee5484c495cf2ba4853de}
      \strng{fullhash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \strng{bibnamehash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \strng{authorbibnamehash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \strng{authornamehash}{33f5845a5b5ee5484c495cf2ba4853de}
      \strng{authorfullhash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{274}
      \field{title}{CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms}
      \field{volume}{23}
      \field{year}{2022}
      \field{pages}{1\bibrangedash 18}
      \range{pages}{18}
      \verb{urlraw}
      \verb http://jmlr.org/papers/v23/21-1342.html
      \endverb
      \verb{url}
      \verb http://jmlr.org/papers/v23/21-1342.html
      \endverb
    \endentry
    \entry{jannerWhenTrustYour2021}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=030220ad86ae86f35b535d317d8a98bb}{%
           family={Janner},
           familyi={J\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a018be9fcf5a8ea4185688a73eefa56}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=306746c29cdb22ddddf3606b521cdf1e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Marvin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{22ed8af2a309bb809eb363ab521af746}
      \strng{fullhash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \strng{bibnamehash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \strng{authorbibnamehash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \strng{authornamehash}{22ed8af2a309bb809eb363ab521af746}
      \strng{authorfullhash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:1906.08253}
      \field{shorttitle}{When to {{Trust Your Model}}}
      \field{title}{When to {{Trust Your Model}}: {{Model-Based Policy Optimization}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1906.08253
      \endverb
      \verb{eprint}
      \verb 1906.08253
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Janner et al_2021_When to Trust Your Model.pdf;/home/james/Zotero/storage/ZY3DI9HK/1906.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{julianiStudyPlasticityLoss2024}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=b40f803735aa0d2366759b65737b11b5}{%
           family={Juliani},
           familyi={J\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33495469d5c8f82e0caea745e1547a1a}{%
           family={Ash},
           familyi={A\bibinitperiod},
           given={Jordan\bibnamedelima T.},
           giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{fullhash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{bibnamehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{authorbibnamehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{authornamehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{authorfullhash}{28173441c5ec27e6eabcd50ab831fb9e}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Continual learning with deep neural networks presents challenges distinct from both the fixed-dataset and convex continual learning regimes. One such challenge is plasticity loss, wherein a neural network trained in an online fashion displays a degraded ability to fit new tasks. This problem has been extensively studied in both supervised learning and off-policy reinforcement learning (RL), where a number of remedies have been proposed. Still, plasticity loss has received less attention in the on-policy deep RL setting. Here we perform an extensive set of experiments examining plasticity loss and a variety of mitigation methods in on-policy deep RL. We demonstrate that plasticity loss is pervasive under domain shift in this regime, and that a number of methods developed to resolve it in other settings fail, sometimes even resulting in performance that is worse than performing no intervention at all. In contrast, we find that a class of ``regenerative'' methods are able to consistently mitigate plasticity loss in a variety of contexts, including in gridworld tasks and more challenging environments like Montezuma's Revenge and ProcGen.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:2405.19153}
      \field{title}{A {{Study}} of {{Plasticity Loss}} in {{On-Policy Deep Reinforcement Learning}}}
      \field{urlday}{29}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2405.19153
      \endverb
      \verb{eprint}
      \verb 2405.19153
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/RV6JPVD4/Juliani and Ash - 2024 - A Study of Plasticity Loss in On-Policy Deep Reinf.pdf;/home/james/Zotero/storage/TPXI24F4/2405.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{kaiserModelBasedReinforcementLearning2024}{misc}{}
      \name{author}{14}{}{%
        {{un=0,uniquepart=base,hash=f2bc899b1160163417da7bf510f15d33}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Lukasz},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bee046fabb85a8fb46ac6414d13fa4c5}{%
           family={Babaeizadeh},
           familyi={B\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a5eca6c6f47ed957501df97298fc2f59}{%
           family={Milos},
           familyi={M\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=64834d3a91d16390d4188548afc76fc8}{%
           family={Osinski},
           familyi={O\bibinitperiod},
           given={Blazej},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=886cc29df3761bc097a37b2f4323bb7d}{%
           family={Campbell},
           familyi={C\bibinitperiod},
           given={Roy\bibnamedelima H.},
           giveni={R\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c5b1224768c765a5d03bd6a26af61368}{%
           family={Czechowski},
           familyi={C\bibinitperiod},
           given={Konrad},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8bbc4c5d96f205bada839e74e0202146}{%
           family={Erhan},
           familyi={E\bibinitperiod},
           given={Dumitru},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=058e82495825ae376c6a96a12169e6ee}{%
           family={Finn},
           familyi={F\bibinitperiod},
           given={Chelsea},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0aa3050e04ebd05a764a990d1ebc7c36}{%
           family={Kozakowski},
           familyi={K\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=204e2adab232f612fc459546fb067b67}{%
           family={Mohiuddin},
           familyi={M\bibinitperiod},
           given={Afroz},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7f45cbea23420eb9e29c75c69725248f}{%
           family={Sepassi},
           familyi={S\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=641a3f5d5ce834c4b56fb672c5df0207}{%
           family={Tucker},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=88b44aba31eead485bb3a63154798388}{%
           family={Michalewski},
           familyi={M\bibinitperiod},
           given={Henryk},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{141faaaad26d9473f46ca6887d212b08}
      \strng{fullhash}{f49d53ab71c7ef6629f1efea9390984a}
      \strng{bibnamehash}{f49d53ab71c7ef6629f1efea9390984a}
      \strng{authorbibnamehash}{f49d53ab71c7ef6629f1efea9390984a}
      \strng{authornamehash}{141faaaad26d9473f46ca6887d212b08}
      \strng{authorfullhash}{f49d53ab71c7ef6629f1efea9390984a}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:1903.00374}
      \field{title}{Model-{{Based Reinforcement Learning}} for {{Atari}}}
      \field{urlday}{18}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1903.00374
      \endverb
      \verb{eprint}
      \verb 1903.00374
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/DTUZ3VK7/Kaiser et al. - 2024 - Model-Based Reinforcement Learning for Atari.pdf;/home/james/Zotero/storage/5IXG6WQL/1903.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{kearnsBiasVarianceErrorBounds2000}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=d6e0fc1e9d08f7c702ebed66002adeef}{%
           family={Kearns},
           familyi={K\bibinitperiod},
           given={Michael\bibnamedelima J.},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0778520109d58859c98d71f3b7e75837}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Satinder\bibnamedelima P.},
           giveni={S\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {San Francisco, CA, USA}%
      }
      \list{publisher}{1}{%
        {Morgan Kaufmann Publishers Inc.}%
      }
      \strng{namehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{fullhash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{bibnamehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{authorbibnamehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{authornamehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{authorfullhash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-55860-703-3}
      \field{journaltitle}{Proceedings of the {{Thirteenth Annual Conference}} on {{Computational Learning Theory}}}
      \field{month}{6}
      \field{series}{{{COLT}} '00}
      \field{title}{Bias-{{Variance Error Bounds}} for {{Temporal Difference Updates}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2000}
      \field{urldateera}{ce}
      \field{pages}{142\bibrangedash 147}
      \range{pages}{6}
    \endentry
    \entry{kingmaAutoEncodingVariationalBayes2022}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=53d2880ad8047b61cdae2c6b2803e763}{%
           family={Welling},
           familyi={W\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{fullhash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{bibnamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authorbibnamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authornamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authorfullhash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1312.6114}
      \field{title}{Auto-{{Encoding Variational Bayes}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1312.6114
      \endverb
      \verb{eprint}
      \verb 1312.6114
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/7MM8EYSG/Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf;/home/james/Zotero/storage/8WEIQSBD/1312.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{kostrikovImageAugmentationAll2021}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=36c384c0d52c2e0b0d8bc9f99b9fc985}{%
           family={Kostrikov},
           familyi={K\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c1a92bfddfd960be33e0dbc1cd54ddef}{%
           family={Yarats},
           familyi={Y\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6784304d1cc890b2cb6c6c7f2f3fd76}{%
           family={Fergus},
           familyi={F\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{36a769a033a100a9e50e0fe8308161d7}
      \strng{fullhash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \strng{bibnamehash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \strng{authorbibnamehash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \strng{authornamehash}{36a769a033a100a9e50e0fe8308161d7}
      \strng{authorfullhash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training. The approach leverages input perturbations commonly used in computer vision tasks to regularize the value function. Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC's performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Dreamer, PlaNet, and SLAC) methods and recently proposed contrastive learning (CURL). Our approach can be combined with any model-free reinforcement learning algorithm, requiring only minor modifications. An implementation can be found at https://sites.google.com/view/data-regularized-q.}
      \field{eprintclass}{cs, eess, stat}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2004.13649}
      \field{shorttitle}{Image {{Augmentation Is All You Need}}}
      \field{title}{Image {{Augmentation Is All You Need}}: {{Regularizing Deep Reinforcement Learning}} from {{Pixels}}}
      \field{urlday}{13}
      \field{urlmonth}{9}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2004.13649
      \endverb
      \verb{eprint}
      \verb 2004.13649
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/NT5GU8GQ/Kostrikov et al. - 2021 - Image Augmentation Is All You Need Regularizing D.pdf;/home/james/Zotero/storage/LZ9VZ6D2/2004.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning}
    \endentry
    \entry{kurutachModelEnsembleTrustRegionPolicy2018}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=9b11af4841b4b3e436a27b0f140f45e3}{%
           family={Kurutach},
           familyi={K\bibinitperiod},
           given={Thanard},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a0423de20f2c114c3f6bb51a7a7e76d6}{%
           family={Clavera},
           familyi={C\bibinitperiod},
           given={Ignasi},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=beba2607fa3b01b069f484075d0b9cf2}{%
           family={Duan},
           familyi={D\bibinitperiod},
           given={Yan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=41ea42ab7e09607e91466632ce419d8c}{%
           family={Tamar},
           familyi={T\bibinitperiod},
           given={Aviv},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{bcd852cbf793bc0e57781a2ed546fe5c}
      \strng{fullhash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \strng{bibnamehash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \strng{authorbibnamehash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \strng{authornamehash}{bcd852cbf793bc0e57781a2ed546fe5c}
      \strng{authorfullhash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity, which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1802.10592}
      \field{title}{Model-{{Ensemble Trust-Region Policy Optimization}}}
      \field{urlday}{26}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1802.10592
      \endverb
      \verb{eprint}
      \verb 1802.10592
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/NPZPA3WL/Kurutach et al. - 2018 - Model-Ensemble Trust-Region Policy Optimization.pdf;/home/james/Zotero/storage/JVFZXSE7/1802.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{laskinReinforcementLearningAugmented2020}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=4b7fbc26d49455e302dd6d5ab6a35ddf}{%
           family={Laskin},
           familyi={L\bibinitperiod},
           given={Misha},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a74a7d6a839e48de367e41b7ec29d456}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kimin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aad83400c6061a7a8f6c422951af64cf}{%
           family={Stooke},
           familyi={S\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d4b78f1220fe5cab8395d811fc9c5b2}{%
           family={Pinto},
           familyi={P\bibinitperiod},
           given={Lerrel},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=09fed423ccdd83193718e9e7e2c70481}{%
           family={Srinivas},
           familyi={S\bibinitperiod},
           given={Aravind},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{cec4377fb3611a238af0f919581bf172}
      \strng{fullhash}{a64856e2dc51348cdfe924e33d57a4bb}
      \strng{bibnamehash}{a64856e2dc51348cdfe924e33d57a4bb}
      \strng{authorbibnamehash}{a64856e2dc51348cdfe924e33d57a4bb}
      \strng{authornamehash}{cec4377fb3611a238af0f919581bf172}
      \strng{authorfullhash}{a64856e2dc51348cdfe924e33d57a4bb}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning from visual observations is a fundamental yet challenging problem in Reinforcement Learning (RL). Although algorithmic advances combined with convolutional neural networks have proved to be a recipe for success, current methods are still lacking on two fronts: (a) data-efficiency of learning and (b) generalization to new environments. To this end, we present Reinforcement Learning with Augmented Data (RAD), a simple plug-and-play module that can enhance most RL algorithms. We perform the first extensive study of general data augmentations for RL on both pixel-based and state-based inputs, and introduce two new data augmentations - random translate and random amplitude scale. We show that augmentations such as random translate, crop, color jitter, patch cutout, random convolutions, and amplitude scale can enable simple RL algorithms to outperform complex state-of-the-art methods across common benchmarks. RAD sets a new state-of-the-art in terms of data-efficiency and final performance on the DeepMind Control Suite benchmark for pixel-based control as well as OpenAI Gym benchmark for state-based control. We further demonstrate that RAD significantly improves test-time generalization over existing methods on several OpenAI ProcGen benchmarks.}
      \field{journaltitle}{Advances in {{Neural Information Processing Systems}}}
      \field{title}{Reinforcement {{Learning}} with {{Augmented Data}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{33}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{19884\bibrangedash 19895}
      \range{pages}{12}
      \verb{file}
      \verb /home/james/Zotero/storage/RBDVETXJ/Laskin et al. - 2020 - Reinforcement Learning with Augmented Data.pdf
      \endverb
    \endentry
    \entry{lillicrapContinuousControlDeep2019}{misc}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=2a321a868e44d49baf52b5e2d816fb71}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy\bibnamedelima P.},
           giveni={T\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e0c5cec59a932511b2af6220473fad61}{%
           family={Hunt},
           familyi={H\bibinitperiod},
           given={Jonathan\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4295e4094c426f01903ac60155866130}{%
           family={Pritzel},
           familyi={P\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=231312991eab5915498d6c19c2a8cd4e}{%
           family={Heess},
           familyi={H\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3b79ca47f08451987877fd8682e971e5}{%
           family={Erez},
           familyi={E\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=58112cb88a80c1bc045b6eaab26a8695}{%
           family={Tassa},
           familyi={T\bibinitperiod},
           given={Yuval},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d7805381550fb5f8360345f7f72c0b49}{%
           family={Wierstra},
           familyi={W\bibinitperiod},
           given={Daan},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{e9929f8db9dd2c08064f17b4d9a7c551}
      \strng{fullhash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \strng{bibnamehash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \strng{authorbibnamehash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \strng{authornamehash}{e9929f8db9dd2c08064f17b4d9a7c551}
      \strng{authorfullhash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1509.02971}
      \field{title}{Continuous Control with Deep Reinforcement Learning}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1509.02971
      \endverb
      \verb{eprint}
      \verb 1509.02971
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/WEB39L3B/Lillicrap et al. - 2019 - Continuous control with deep reinforcement learning.pdf;/home/james/Zotero/storage/J3V4JQJJ/1509.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{loshchilovDecoupledWeightDecay2018}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=1241b8181104f1917578d4c7f9b323b6}{%
           family={Loshchilov},
           familyi={L\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=528d4af87fd2ecf5fb8a22db913ce088}{%
           family={Hutter},
           familyi={H\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{fullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{bibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorbibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authornamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorfullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at {\textbackslash}url\{https://github.com/loshchil/AdamW-and-SGDW\}}
      \field{journaltitle}{International {{Conference}} on {{Learning Representations}}}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Decoupled {{Weight Decay Regularization}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/2FPW57V3/Loshchilov and Hutter - 2018 - Decoupled Weight Decay Regularization.pdf
      \endverb
    \endentry
    \entry{lyleUnderstandingPlasticityNeural2023}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=5b82601d6753d5b4566740b519f02b96}{%
           family={Lyle},
           familyi={L\bibinitperiod},
           given={Clare},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eab311bac27bfd4d97008d3e3c762cf0}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Zeyu},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d078365da0923eced35cd9345318ca0}{%
           family={Nikishin},
           familyi={N\bibinitperiod},
           given={Evgenii},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8ff346cbfa06024a8dd0afe01bd765a}{%
           family={Pires},
           familyi={P\bibinitperiod},
           given={Bernardo\bibnamedelima Avila},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7045b009b04d57bd2e19b5dfa0864d4f}{%
           family={Pascanu},
           familyi={P\bibinitperiod},
           given={Razvan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5a44cbf0d05e4c50b512bb0c1368d2f}{%
           family={Dabney},
           familyi={D\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{89eb1cf3866556e56ed3ca88af261bed}
      \strng{fullhash}{8b2e8a254a5d491293879fe9d17a4b93}
      \strng{bibnamehash}{8b2e8a254a5d491293879fe9d17a4b93}
      \strng{authorbibnamehash}{8b2e8a254a5d491293879fe9d17a4b93}
      \strng{authornamehash}{89eb1cf3866556e56ed3ca88af261bed}
      \strng{authorfullhash}{8b2e8a254a5d491293879fe9d17a4b93}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Plasticity, the ability of a neural network to quickly change its predictions in response to new information, is essential for the adaptability and robustness of deep reinforcement learning systems. Deep neural networks are known to lose plasticity over the course of training even in relatively simple learning problems, but the mechanisms driving this phenomenon are still poorly understood. This paper conducts a systematic empirical analysis into plasticity loss, with the goal of understanding the phenomenon mechanistically in order to guide the future development of targeted solutions. We find that loss of plasticity is deeply connected to changes in the curvature of the loss landscape, but that it often occurs in the absence of saturated units. Based on this insight, we identify a number of parameterization and optimization design choices which enable networks to better preserve plasticity over the course of training. We validate the utility of these findings on larger-scale RL benchmarks in the Arcade Learning Environment.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{arXiv:2303.01486}
      \field{title}{Understanding Plasticity in Neural Networks}
      \field{urlday}{20}
      \field{urlmonth}{10}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2303.01486
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/H2KNQDDB/Lyle et al. - 2023 - Understanding plasticity in neural networks.pdf
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{tensorflow2015-whitepaper}{misc}{}
      \name{author}{40}{}{%
        {{un=0,uniquepart=base,hash=396d6419316ec52f4c63b2f85912b61b}{%
           family={MartÃ­n\bibnamedelima Abadi},
           familyi={M\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=f337a7c116835c22bb206d2f0d7c70e0}{%
           family={Ashish\bibnamedelima Agarwal},
           familyi={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=84ac9fcb6c15dcd79c092bc8e20586ba}{%
           family={Paul\bibnamedelima Barham},
           familyi={P\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=d8574748e3086e0b279a58cdba71763d}{%
           family={Eugene\bibnamedelima Brevdo},
           familyi={E\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=c0b56f741b5a5bddfe77f1881c3cc67a}{%
           family={Zhifeng\bibnamedelima Chen},
           familyi={Z\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=8b8dd2e01366c855f42e47027cf23e98}{%
           family={Craig\bibnamedelima Citro},
           familyi={C\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=978a7d9601bf09e03d1bb3f6cce7a0ce}{%
           family={Greg\bibnamedelima S.\bibnamedelimi Corrado},
           familyi={G\bibinitperiod\bibinitdelim S\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=3b500b0dfd88e6e151d29108fdcb82f0}{%
           family={Andy\bibnamedelima Davis},
           familyi={A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=2fd376ea3b3a3da11704c0ee86753dcf}{%
           family={Jeffrey\bibnamedelima Dean},
           familyi={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=5b34e641dd8a00f97c6242ae0353eb90}{%
           family={Matthieu\bibnamedelima Devin},
           familyi={M\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=5b4490947d4e91359646ce3c93cbd2f7}{%
           family={Sanjay\bibnamedelima Ghemawat},
           familyi={S\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1fdef10b94ee122ef6136197f99e3df3}{%
           family={Ian\bibnamedelima Goodfellow},
           familyi={I\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=166ae8a0b435eded68e39e9e2d2a1ee8}{%
           family={Andrew\bibnamedelima Harp},
           familyi={A\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=7e9f7006151cf312bc133568336c68c6}{%
           family={Geoffrey\bibnamedelima Irving},
           familyi={G\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=08c1890e1c33279b8c63c71fa8f19263}{%
           family={Michael\bibnamedelima Isard},
           familyi={M\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=9fce03efe6b3331a1b93ed2e7c0da9d5}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Yangqing},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0c0eea5379268c0c5b68732c90984b6}{%
           family={Rafal\bibnamedelima Jozefowicz},
           familyi={R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=cff46cb4603a73d83b11ea7a9ded9d79}{%
           family={Lukasz\bibnamedelima Kaiser},
           familyi={L\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=d088e0f635523b8b5b18662331e4f44a}{%
           family={Manjunath\bibnamedelima Kudlur},
           familyi={M\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1c24291ae15b979c82aa09a33790cb62}{%
           family={Josh\bibnamedelima Levenberg},
           familyi={J\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=796a3a98ff7545fe10f6a4c17ba016fa}{%
           family={Dandelion\bibnamedelima ManÃ©},
           familyi={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1ee98d232eb1fc1208a8f8ca649e970b}{%
           family={Rajat\bibnamedelima Monga},
           familyi={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b2a15ec3d90955ece50ea26d31100b9a}{%
           family={Sherry\bibnamedelima Moore},
           familyi={S\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1494c573fadad736c58cf1119ac59239}{%
           family={Derek\bibnamedelima Murray},
           familyi={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ecf58eb1684af6cba2c1f126405eedab}{%
           family={Chris\bibnamedelima Olah},
           familyi={C\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=9f43befd94cd09a9aaa7ea8489405a83}{%
           family={Mike\bibnamedelima Schuster},
           familyi={M\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=4712800a228b1179529b9f6e0d1b1838}{%
           family={Jonathon\bibnamedelima Shlens},
           familyi={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=41ad6ff6c026d5a3730269072b31caf1}{%
           family={Benoit\bibnamedelima Steiner},
           familyi={B\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b02f7871db6fc5524cec4ce38e104410}{%
           family={Ilya\bibnamedelima Sutskever},
           familyi={I\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=63288446e47b1d383f522ede84aa6fcc}{%
           family={Kunal\bibnamedelima Talwar},
           familyi={K\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1dec75595b55bf77971f6a932d146b81}{%
           family={Paul\bibnamedelima Tucker},
           familyi={P\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b6680dbb0176cb9bd87a3b26fa6f5cfb}{%
           family={Vincent\bibnamedelima Vanhoucke},
           familyi={V\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=e030c9d199c66657e26138be29814d81}{%
           family={Vijay\bibnamedelima Vasudevan},
           familyi={V\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=04426b798803cfaf3e8aa9280a5d0a58}{%
           family={Fernanda\bibnamedelima ViÃ©gas},
           familyi={F\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=fa7242e11c7d955de2ac1be94ca29073}{%
           family={Oriol\bibnamedelima Vinyals},
           familyi={O\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=8c9ee8f70a3c3d97f85efd01c4e9cbe6}{%
           family={Pete\bibnamedelima Warden},
           familyi={P\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=8e4243c228c72a5e5279e31252887b32}{%
           family={Martin\bibnamedelima Wattenberg},
           familyi={M\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=c6a6eb2597f23589fc9141bdda275996}{%
           family={Martin\bibnamedelima Wicke},
           familyi={M\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=3ea39e6dc6ef47029ae996c7e63f1a48}{%
           family={Yuan\bibnamedelima Yu},
           familyi={Y\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b69feb3a3d59a312b20dbef0b1d2d6de}{%
           family={Xiaoqiang\bibnamedelima Zheng},
           familyi={X\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
      }
      \strng{namehash}{7fdd865be502254047a3b2638dc0cfeb}
      \strng{fullhash}{9b332dc9b33a2f6316d71d525269bd0f}
      \strng{bibnamehash}{f1d28cdb6a316b575768cd5835e052b9}
      \strng{authorbibnamehash}{f1d28cdb6a316b575768cd5835e052b9}
      \strng{authornamehash}{7fdd865be502254047a3b2638dc0cfeb}
      \strng{authorfullhash}{9b332dc9b33a2f6316d71d525269bd0f}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{Software available from tensorflow.org}
      \field{title}{{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems}
      \field{year}{2015}
      \verb{urlraw}
      \verb https://www.tensorflow.org/
      \endverb
      \verb{url}
      \verb https://www.tensorflow.org/
      \endverb
    \endentry
    \entry{micheliTransformersAreSampleEfficient2023}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=da539a6612ef5e086053b6366707183e}{%
           family={Micheli},
           familyi={M\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=645fa2d79cecc93afa96b49040e5c725}{%
           family={Alonso},
           familyi={A\bibinitperiod},
           given={Eloi},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=def3560de15608bae049e94de457b966}{%
           family={Fleuret},
           familyi={F\bibinitperiod},
           given={FranÃ§ois},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8643639c0a82a28443469ca69c2ee337}
      \strng{fullhash}{f3de9bdb74509fe881f88a928f275db2}
      \strng{bibnamehash}{f3de9bdb74509fe881f88a928f275db2}
      \strng{authorbibnamehash}{f3de9bdb74509fe881f88a928f275db2}
      \strng{authornamehash}{8643639c0a82a28443469ca69c2ee337}
      \strng{authorfullhash}{f3de9bdb74509fe881f88a928f275db2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems. Recently, many model-based methods have been designed to address this issue, with learning in the imagination of a world model being one of the most prominent approaches. However, while virtually unlimited interaction with a simulated environment sounds appealing, the world model has to be accurate over extended periods of time. Motivated by the success of Transformers in sequence modeling tasks, we introduce IRIS, a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer. With the equivalent of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean human normalized score of 1.046, and outperforms humans on 10 out of 26 games, setting a new state of the art for methods without lookahead search. To foster future research on Transformers and world models for sample-efficient reinforcement learning, we release our code and models at https://github.com/eloialonso/iris.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2209.00588}
      \field{title}{Transformers Are {{Sample-Efficient World Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2209.00588
      \endverb
      \verb{eprint}
      \verb 2209.00588
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Micheli et al_2023_Transformers are Sample-Efficient World Models.pdf;/home/james/Zotero/storage/CFS39CM5/2209.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{mnihHumanlevelControlDeep2015}{article}{}
      \name{author}{19}{}{%
        {{un=0,uniquepart=base,hash=f7d23cfe4ca0e6bf7a8c251bfa78aca6}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Volodymyr},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=677dfee41a39b5ac7e138f5ce14467e9}{%
           family={Rusu},
           familyi={R\bibinitperiod},
           given={Andrei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1cbd91f7404b2298b46bb46c47c08251}{%
           family={Veness},
           familyi={V\bibinitperiod},
           given={Joel},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be3d55306c5ab7ee716f96f137dddba6}{%
           family={Fidjeland},
           familyi={F\bibinitperiod},
           given={Andreas\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46cc21fb5dec973c05ceb0f321e02ca0}{%
           family={Ostrovski},
           familyi={O\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e381e44037009b1cd834d794735c311}{%
           family={Petersen},
           familyi={P\bibinitperiod},
           given={Stig},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03cf4f0976cc27112d267a8916a2d169}{%
           family={Beattie},
           familyi={B\bibinitperiod},
           given={Charles},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b827d5121d467eeb30ccac8c61094591}{%
           family={Sadik},
           familyi={S\bibinitperiod},
           given={Amir},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=59998a15386f62e4d2776176ab58d49c}{%
           family={King},
           familyi={K\bibinitperiod},
           given={Helen},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a425c81c03d315597e3f92690763e24d}{%
           family={Kumaran},
           familyi={K\bibinitperiod},
           given={Dharshan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d7805381550fb5f8360345f7f72c0b49}{%
           family={Wierstra},
           familyi={W\bibinitperiod},
           given={Daan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=afdf5ed50a24cdca0f42433e4f4848d5}{%
           family={Legg},
           familyi={L\bibinitperiod},
           given={Shane},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Nature Publishing Group}%
      }
      \strng{namehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{fullhash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{bibnamehash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authorbibnamehash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authornamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorfullhash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An artificial agent is developed that learns to play~a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a~performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{7540}
      \field{title}{Human-Level Control through Deep Reinforcement Learning}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{518}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{529\bibrangedash 533}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1038/nature14236
      \endverb
      \keyw{Computer science}
    \endentry
    \entry{nikishinPrimacyBiasDeep2022}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=9d078365da0923eced35cd9345318ca0}{%
           family={Nikishin},
           familyi={N\bibinitperiod},
           given={Evgenii},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e09d377eb804fa206349bcc1d7162ddf}{%
           family={D'Oro},
           familyi={D\bibinitperiod},
           given={Pierluca},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9417eec56d7db4d07719bbb7fe3bcdd}{%
           family={Bacon},
           familyi={B\bibinitperiod},
           given={Pierre-Luc},
           giveni={P\bibinithyphendelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8022d4c3e28ae8c50ebf185095ebf41d}
      \strng{fullhash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \strng{bibnamehash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \strng{authorbibnamehash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \strng{authornamehash}{8022d4c3e28ae8c50ebf185095ebf41d}
      \strng{authorfullhash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This work identifies a common flaw of deep reinforcement learning (RL) algorithms: a tendency to rely on early interactions and ignore useful evidence encountered later. Because of training on progressively growing datasets, deep RL agents incur a risk of overfitting to earlier experiences, negatively affecting the rest of the learning process. Inspired by cognitive science, we refer to this effect as the primacy bias. Through a series of experiments, we dissect the algorithmic aspects of deep RL that exacerbate this bias. We then propose a simple yet generally-applicable mechanism that tackles the primacy bias by periodically resetting a part of the agent. We apply this mechanism to algorithms in both discrete (Atari 100k) and continuous action (DeepMind Control Suite) domains, consistently improving their performance.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:2205.07802}
      \field{title}{The {{Primacy Bias}} in {{Deep Reinforcement Learning}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2205.07802
      \endverb
      \verb{eprint}
      \verb 2205.07802
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/XMQV575X/Nikishin et al. - 2022 - The Primacy Bias in Deep Reinforcement Learning.pdf;/home/james/Zotero/storage/DAHTSBAK/2205.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{ding21diengine}{misc}{}
      \name{author}{9}{}{%
        {{un=0,uniquepart=base,hash=c1117e737511c234c22ce7cbfe564432}{%
           family={Niu},
           familyi={N\bibinitperiod},
           given={Yazhe},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cb35c6357d3a596bd72bb7a8e435f71e}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Jingxin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=84e9cb9612b9988e28a980a4ab11c5a1}{%
           family={Pu},
           familyi={P\bibinitperiod},
           given={Yuan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4708aed5179bfcb6bb2c78017647ea47}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Yunpeng},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cef492fa6b799c8f97ef251c948ac1ba}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jinouwen},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba5fe558cea44767f29b54183dfc1c2e}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Shuai},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=565d18193e6d0a49392d56875ec5c6be}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Liangxuan},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a56aedb5f6ad175a5340edc7bf6267e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Ming},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=93c82128aca25c57cfb17e90d02136d5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {GitHub}%
      }
      \strng{namehash}{95e834099853311376cbe6e32ac26252}
      \strng{fullhash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \strng{bibnamehash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \strng{authorbibnamehash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \strng{authornamehash}{95e834099853311376cbe6e32ac26252}
      \strng{authorfullhash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{howpublished}{\url{https://github.com/opendilab/DI-engine}}
      \field{title}{DI-engine: A Universal AI System/Engine for Decision Intelligence}
      \field{year}{2021}
    \endentry
    \entry{norooziUnsupervisedLearningVisual2017}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=4c5f3dcb3d18394c66a7a0ffa25473ca}{%
           family={Noroozi},
           familyi={N\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b1d1b13c4b9716d6be01da64169529ff}{%
           family={Favaro},
           familyi={F\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{fullhash}{11055406dbc48a44a60942519a1ffe97}
      \strng{bibnamehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{authorbibnamehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{authornamehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{authorfullhash}{11055406dbc48a44a60942519a1ffe97}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we study the problem of image representation learning without human annotation. By following the principles of self-supervision, we build a convolutional neural network (CNN) that can be trained to solve Jigsaw puzzles as a pretext task, which requires no manual labeling, and then later repurposed to solve object classification and detection. To maintain the compatibility across tasks we introduce the context-free network (CFN), a siamese-ennead CNN. The CFN takes image tiles as input and explicitly limits the receptive field (or context) of its early processing units to one tile at a time. We show that the CFN includes fewer parameters than AlexNet while preserving the same semantic learning capabilities. By training the CFN to solve Jigsaw puzzles, we learn both a feature mapping of object parts as well as their correct spatial arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. Our proposed method for learning visual representations outperforms state of the art methods in several transfer learning benchmarks.}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{number}{arXiv:1603.09246}
      \field{title}{Unsupervised {{Learning}} of {{Visual Representations}} by {{Solving Jigsaw Puzzles}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1603.09246
      \endverb
      \verb{eprint}
      \verb 1603.09246
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/8QF5DCGM/Noroozi and Favaro - 2017 - Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles.pdf;/home/james/Zotero/storage/2VRK26Q3/1603.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{openaiSolvingRubiksCube2019}{misc}{}
      \name{author}{19}{ul=2}{%
        {{un=0,uniquepart=base,hash=0523b13262b12c215d8009938f5c14f1}{%
           family={OpenAI},
           familyi={O\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1a2177a207bf8581bc044590f1e55602}{%
           family={Akkaya},
           familyi={A\bibinitperiod},
           given={Ilge},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d8b72cabbd1b548097b4a7b81a0f335}{%
           family={Andrychowicz},
           familyi={A\bibinitperiod},
           given={Marcin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=db785ba8e6356e7dd7e0f860f4f2f473}{%
           family={Chociej},
           familyi={C\bibinitperiod},
           given={Maciek},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e5aa3a709cbe706efba113bec9789364}{%
           family={Litwin},
           familyi={L\bibinitperiod},
           given={Mateusz},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6da1a977c02cecc78ec16c61217dcc42}{%
           family={McGrew},
           familyi={M\bibinitperiod},
           given={Bob},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d79ff0263ade6eee20336810b23e5d8}{%
           family={Petron},
           familyi={P\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=445e6e3c370e31dfc6fa4557bab7bbcb}{%
           family={Paino},
           familyi={P\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=599240d5bfe42aeb65a0c26dae77cd31}{%
           family={Plappert},
           familyi={P\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=34d0d7625e65761eaef54be0603bbf12}{%
           family={Powell},
           familyi={P\bibinitperiod},
           given={Glenn},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e91ce42053256b8eeeb6ba57772fe8b}{%
           family={Ribas},
           familyi={R\bibinitperiod},
           given={Raphael},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5167ef9d0b77bf68557730648baac9b7}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dab05157b89bd0192cb59f4386f74eda}{%
           family={Tezak},
           familyi={T\bibinitperiod},
           given={Nikolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98cbd7022a1c31a6293aa1c8b62bdebf}{%
           family={Tworek},
           familyi={T\bibinitperiod},
           given={Jerry},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=462853f8544f0acfb7014fe747f84922}{%
           family={Welinder},
           familyi={W\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=49d03d499031db786a0e61119024cf5a}{%
           family={Weng},
           familyi={W\bibinitperiod},
           given={Lilian},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a0082b934c2454295be3f0a3b138f21d}{%
           family={Yuan},
           familyi={Y\bibinitperiod},
           given={Qiming},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9fec85bbce1b087a6ebefe26e73f7bf}{%
           family={Zaremba},
           familyi={Z\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{355f5de43f091640722cd6ff601ceb66}
      \strng{fullhash}{533c7f798be0a787c8260607a2dd279a}
      \strng{bibnamehash}{533c7f798be0a787c8260607a2dd279a}
      \strng{authorbibnamehash}{533c7f798be0a787c8260607a2dd279a}
      \strng{authornamehash}{355f5de43f091640722cd6ff601ceb66}
      \strng{authorfullhash}{533c7f798be0a787c8260607a2dd279a}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We demonstrate that models trained only in simulation can be used to solve a manipulation problem of unprecedented complexity on a real robot. This is made possible by two key components: a novel algorithm, which we call automatic domain randomization (ADR) and a robot platform built for machine learning. ADR automatically generates a distribution over randomized environments of ever-increasing difficulty. Control policies and vision state estimators trained with ADR exhibit vastly improved sim2real transfer. For control policies, memory-augmented models trained on an ADR-generated distribution of environments show clear signs of emergent meta-learning at test time. The combination of ADR with our custom robot platform allows us to solve a Rubik's cube with a humanoid robot hand, which involves both control and state estimation problems. Videos summarizing our results are available: https://openai.com/blog/solving-rubiks-cube/}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1910.07113}
      \field{title}{Solving {{Rubik}}'s {{Cube}} with a {{Robot Hand}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1910.07113
      \endverb
      \verb{eprint}
      \verb 1910.07113
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/9JFJ5HT9/OpenAI et al. - 2019 - Solving Rubik's Cube with a Robot Hand.pdf;/home/james/Zotero/storage/523N9S2W/1910.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{openaiDota2Large2019}{misc}{}
      \name{author}{26}{ul=2}{%
        {{un=0,uniquepart=base,hash=0523b13262b12c215d8009938f5c14f1}{%
           family={OpenAI},
           familyi={O\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ca86811e7a0582a9e7cb8d33e7ab445d}{%
           family={Berner},
           familyi={B\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ae2a0efeaf9c031f9b420bcb1c19e54}{%
           family={Brockman},
           familyi={B\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bdcc84061540e15aac439cba59db6577}{%
           family={Chan},
           familyi={C\bibinitperiod},
           given={Brooke},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ece7baf9b320c51ead8e24c1c6386dbf}{%
           family={Cheung},
           familyi={C\bibinitperiod},
           given={Vicki},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b9ef873a5cb802b4a76be3508f175b4}{%
           family={DÄbiak},
           familyi={D\bibinitperiod},
           given={Przemys{Å}aw},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a509b9c62a0e81a58991a81caf48298d}{%
           family={Dennison},
           familyi={D\bibinitperiod},
           given={Christy},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a562eb10ac2870de64b3956df2eb1896}{%
           family={Farhi},
           familyi={F\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9077a5599d2a4f3aa8bb20cef3b6399a}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Quirin},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=49e2023e4e856577f61450fc5149743d}{%
           family={Hashme},
           familyi={H\bibinitperiod},
           given={Shariq},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07acc23f6ec051b64b82cd33255c0a69}{%
           family={Hesse},
           familyi={H\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4eda39963a95c233a262d4191f198aa4}{%
           family={JÃ³zefowicz},
           familyi={J\bibinitperiod},
           given={Rafal},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7006ca8c1ce969019b89de50fece60dd}{%
           family={Gray},
           familyi={G\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd24844b3abaa88e1f3c5c074ad37ab6}{%
           family={Olsson},
           familyi={O\bibinitperiod},
           given={Catherine},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=27d3d977b77156237cdeb5a7b7eaa560}{%
           family={Pachocki},
           familyi={P\bibinitperiod},
           given={Jakub},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=20bb006267a99bf6b2419ac00ec8decb}{%
           family={Petrov},
           familyi={P\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f78abae164f9e9364dd3e0b31887fc08}{%
           family={Pinto},
           familyi={P\bibinitperiod},
           given={Henrique\bibnamedelimb P.\bibnamedelimi d\bibnamedelima O.},
           giveni={H\bibinitperiod\bibinitdelim P\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9db43b2d2fa0f38a4051782eb9de8f87}{%
           family={Raiman},
           familyi={R\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e6f76e1a4d058df028530916774ad3a7}{%
           family={Salimans},
           familyi={S\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e3e581a0808055d754222c3b47b3a7ab}{%
           family={Schlatter},
           familyi={S\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5167ef9d0b77bf68557730648baac9b7}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6657859de18e844e4b1b815e03694c71}{%
           family={Sidor},
           familyi={S\bibinitperiod},
           given={Szymon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d0b3008e85b1a8b38f46556abf1791c7}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=674ede0b9cd02a2bf5fc662972efb9f0}{%
           family={Wolski},
           familyi={W\bibinitperiod},
           given={Filip},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24b5bdd4e149e4c9ed111f6051192cf8}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Susan},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{606c0d1e1c67347217f8584145d77188}
      \strng{fullhash}{b846e5ad21999608d85108783d48f2a5}
      \strng{bibnamehash}{606c0d1e1c67347217f8584145d77188}
      \strng{authorbibnamehash}{606c0d1e1c67347217f8584145d77188}
      \strng{authornamehash}{606c0d1e1c67347217f8584145d77188}
      \strng{authorfullhash}{b846e5ad21999608d85108783d48f2a5}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{On April 13th, 2019, OpenAI Five became the first AI system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for AI systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable AI systems. OpenAI Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG), OpenAI Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1912.06680}
      \field{title}{Dota 2 with {{Large Scale Deep Reinforcement Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.06680
      \endverb
      \verb{eprint}
      \verb 1912.06680
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/OpenAI et al_2019_Dota 2 with Large Scale Deep Reinforcement Learning.pdf;/home/james/Zotero/storage/HFQR3FB9/1912.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{ouyangTrainingLanguageModels2022}{article}{}
      \name{author}{20}{}{%
        {{un=0,uniquepart=base,hash=6e3708cf33f22d79419d7e79124060a8}{%
           family={Ouyang},
           familyi={O\bibinitperiod},
           given={Long},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=495187f3a2c93ddb8083bd18a5702527}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jeffrey},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=214803c09eda269a0ed928d7e5a93461}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Xu},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a7cf026a14a6ceae41b01945420f7d80}{%
           family={Almeida},
           familyi={A\bibinitperiod},
           given={Diogo},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=19714834684eddb04464454a907483b2}{%
           family={Wainwright},
           familyi={W\bibinitperiod},
           given={Carroll},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2321e04943bcadb0275819652b980521}{%
           family={Mishkin},
           familyi={M\bibinitperiod},
           given={Pamela},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6396eaa69e1c798e2c8c503e9ce9067b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Chong},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=abe4801e322e893b23785fd6d0800b5c}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Sandhini},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=57e47da21cfc9e3fa6c754e47b5adcab}{%
           family={Slama},
           familyi={S\bibinitperiod},
           given={Katarina},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=71db9ce8a56e89a1f139670448d55a10}{%
           family={Gray},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9e4edc142b0564cbbb1cf93a401e4434}{%
           family={Hilton},
           familyi={H\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2782098fc110938b6feb76048e568328}{%
           family={Kelton},
           familyi={K\bibinitperiod},
           given={Fraser},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ca6c3bdfd65467cd39e6dc08a0410e65}{%
           family={Miller},
           familyi={M\bibinitperiod},
           given={Luke},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7f5d4524691b522e78f555d453d9b786}{%
           family={Simens},
           familyi={S\bibinitperiod},
           given={Maddie},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e84eff933be9f4887bf369cf181bf12}{%
           family={Askell},
           familyi={A\bibinitperiod},
           given={Amanda},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=462853f8544f0acfb7014fe747f84922}{%
           family={Welinder},
           familyi={W\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cffdbdf7d0beb981d8bb8ea28506a4b2}{%
           family={Christiano},
           familyi={C\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cc754f0620be1073909db48780f1da4d}{%
           family={Leike},
           familyi={L\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7be01fa6277ef22b804ff6cc54c87b72}{%
           family={Lowe},
           familyi={L\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{13d52a5bcb04f48fa855da0c9fb052de}
      \strng{fullhash}{983d5b455a45a1d549eea6ee7ffc45be}
      \strng{bibnamehash}{983d5b455a45a1d549eea6ee7ffc45be}
      \strng{authorbibnamehash}{983d5b455a45a1d549eea6ee7ffc45be}
      \strng{authornamehash}{13d52a5bcb04f48fa855da0c9fb052de}
      \strng{authorfullhash}{983d5b455a45a1d549eea6ee7ffc45be}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.}
      \field{journaltitle}{Advances in {{Neural Information Processing Systems}}}
      \field{langid}{english}
      \field{month}{10}
      \field{title}{Training Language Models to Follow Instructions with Human Feedback}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/KQCF6BYN/Ouyang et al. - 2022 - Training language models to follow instructions with human feedback.pdf
      \endverb
    \endentry
    \entry{paszkePyTorchImperativeStyle2019}{misc}{}
      \name{author}{21}{}{%
        {{un=0,uniquepart=base,hash=56bf0b340039cf8594436a624ff548a9}{%
           family={Paszke},
           familyi={P\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4ba5062e5919c814aceec188d54c01f2}{%
           family={Gross},
           familyi={G\bibinitperiod},
           given={Sam},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e5dfae4582081d649e3a0d5342050016}{%
           family={Massa},
           familyi={M\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b5815e1692fa2d0c1f44eecf509bd7c4}{%
           family={Lerer},
           familyi={L\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b75383e6b48c8360c7a60031424c85cf}{%
           family={Bradbury},
           familyi={B\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f897ed422c34d95af2e22778dfc2607e}{%
           family={Chanan},
           familyi={C\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=046269e070246feb6f394141db80ed87}{%
           family={Killeen},
           familyi={K\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c40352c194e60a3ef458ee7e8685afb5}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Zeming},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6e45f49ec618e619efad90c8e8a61f0c}{%
           family={Gimelshein},
           familyi={G\bibinitperiod},
           given={Natalia},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f65a80959d520337ae99a0798515036c}{%
           family={Antiga},
           familyi={A\bibinitperiod},
           given={Luca},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=954cf7680b6ce14813973eccdca3c4bc}{%
           family={Desmaison},
           familyi={D\bibinitperiod},
           given={Alban},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=048232cf7c525fbc0bc93052fe8cee03}{%
           family={KÃ¶pf},
           familyi={K\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9e701339e56fd0b171145b08288a1b7}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=42ac264897098b400e1367e5922c9b0d}{%
           family={DeVito},
           familyi={D\bibinitperiod},
           given={Zach},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d814afaa50b9e22ab92cc9f8f9a9e43a}{%
           family={Raison},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3feeeebee8583ecc208f7fb3e0a55068}{%
           family={Tejani},
           familyi={T\bibinitperiod},
           given={Alykhan},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e18536d5cb7543731fbf2ca1a4908732}{%
           family={Chilamkurthy},
           familyi={C\bibinitperiod},
           given={Sasank},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0a0b028c6b85c46f368317d0c5bfe3a0}{%
           family={Steiner},
           familyi={S\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=998a001f16bb57c079c1d5afb1cb02c8}{%
           family={Fang},
           familyi={F\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3f19c633bbfb847db6a0e71d3659eacd}{%
           family={Bai},
           familyi={B\bibinitperiod},
           given={Junjie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8ef51a0906e47d2b4472c4e714ed598f}{%
           family={Chintala},
           familyi={C\bibinitperiod},
           given={Soumith},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{fullhash}{4842db6c92a33147f588935fdde44a69}
      \strng{bibnamehash}{c4467cc24b68e421171e0cfd2dcbf915}
      \strng{authorbibnamehash}{c4467cc24b68e421171e0cfd2dcbf915}
      \strng{authornamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authorfullhash}{4842db6c92a33147f588935fdde44a69}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1912.01703}
      \field{shorttitle}{{{PyTorch}}}
      \field{title}{{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.01703
      \endverb
      \verb{eprint}
      \verb 1912.01703
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/9NN95CNL/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Deep Learning Library.pdf;/home/james/Zotero/storage/2R5WC9HL/1912.html
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Mathematical Software,Statistics - Machine Learning}
    \endentry
    \entry{pinedaMBRLLibModularLibrary2021}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=2fd46563677f95093c3df0d7e7be2416}{%
           family={Pineda},
           familyi={P\bibinitperiod},
           given={Luis},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=783779089b4b78ed86b990f3397d0abb}{%
           family={Amos},
           familyi={A\bibinitperiod},
           given={Brandon},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=23d26cc1e55ad87341af3cb88c607c6c}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Amy},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1bf4f76887e5e25f45f673cf5fea0f9c}{%
           family={Lambert},
           familyi={L\bibinitperiod},
           given={Nathan\bibnamedelima O.},
           giveni={N\bibinitperiod\bibinitdelim O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=864584c60b808b517f2a06c664ec116a}{%
           family={Calandra},
           familyi={C\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{d6cf657552ae065d14dd1098c23d0bc3}
      \strng{fullhash}{9509b565122593d122e8915396196373}
      \strng{bibnamehash}{9509b565122593d122e8915396196373}
      \strng{authorbibnamehash}{9509b565122593d122e8915396196373}
      \strng{authornamehash}{d6cf657552ae065d14dd1098c23d0bc3}
      \strng{authorfullhash}{9509b565122593d122e8915396196373}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Model-based reinforcement learning is a compelling framework for data-efficient learning of agents that interact with the world. This family of algorithms has many subcomponents that need to be carefully selected and tuned. As a result the entry-bar for researchers to approach the field and to deploy it in real-world tasks can be daunting. In this paper, we present MBRL-Lib -- a machine learning library for model-based reinforcement learning in continuous state-action spaces based on PyTorch. MBRL-Lib is designed as a platform for both researchers, to easily develop, debug and compare new algorithms, and non-expert user, to lower the entry-bar of deploying state-of-the-art algorithms. MBRL-Lib is open-source at https://github.com/facebookresearch/mbrl-lib.}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:2104.10159}
      \field{shorttitle}{{{MBRL-Lib}}}
      \field{title}{{{MBRL-Lib}}: {{A Modular Library}} for {{Model-based Reinforcement Learning}}}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2104.10159
      \endverb
      \verb{eprint}
      \verb 2104.10159
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/UAF48PXV/Pineda et al. - 2021 - MBRL-Lib A Modular Library for Model-based Reinforcement Learning.pdf;/home/james/Zotero/storage/UPVHFRVI/2104.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control}
    \endentry
    \entry{robineTransformerbasedWorldModels2023}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=8251012c149d8023d80a2bbe6c0d9065}{%
           family={Robine},
           familyi={R\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=db73803c2cf851a4fa23eb24338e8b25}{%
           family={HÃ¶ftmann},
           familyi={H\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e90b27b526070b70451012ee1d68881}{%
           family={Uelwer},
           familyi={U\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b89ff3ea3d3957658253d2b707e09867}{%
           family={Harmeling},
           familyi={H\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{468c24caa94095dd4aa463cae9a801ae}
      \strng{fullhash}{6dd66a07e03e74098b252222b90bec3a}
      \strng{bibnamehash}{6dd66a07e03e74098b252222b90bec3a}
      \strng{authorbibnamehash}{6dd66a07e03e74098b252222b90bec3a}
      \strng{authornamehash}{468c24caa94095dd4aa463cae9a801ae}
      \strng{authorfullhash}{6dd66a07e03e74098b252222b90bec3a}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep neural networks have been successful in many reinforcement learning settings. However, compared to human learners they are overly data hungry. To build a sample-efficient world model, we apply a transformer to real-world episodes in an autoregressive manner: not only the compact latent states and the taken actions but also the experienced or predicted rewards are fed into the transformer, so that it can attend flexibly to all three modalities at different time steps. The transformer allows our world model to access previous states directly, instead of viewing them through a compressed recurrent state. By utilizing the Transformer-XL architecture, it is able to learn long-term dependencies while staying computationally efficient. Our transformer-based world model (TWM) generates meaningful, new experience, which is used to train a policy that outperforms previous model-free and model-based reinforcement learning algorithms on the Atari 100k benchmark.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2303.07109}
      \field{title}{Transformer-Based {{World Models Are Happy With}} 100k {{Interactions}}}
      \field{urlday}{27}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2303.07109
      \endverb
      \verb{eprint}
      \verb 2303.07109
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/GVIXCBHN/Robine et al. - 2023 - Transformer-based World Models Are Happy With 100k Interactions.pdf;/home/james/Zotero/storage/KHNZK8JZ/2303.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{schaulPrioritizedExperienceReplay2016}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d1c6b8444cb95e400ca38d5ae5c5afd3}{%
           family={Quan},
           familyi={Q\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{04a0db021533adedf96ff47bc975d01a}
      \strng{fullhash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \strng{bibnamehash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \strng{authorbibnamehash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \strng{authornamehash}{04a0db021533adedf96ff47bc975d01a}
      \strng{authorfullhash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{number}{arXiv:1511.05952}
      \field{title}{Prioritized {{Experience Replay}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1511.05952
      \endverb
      \verb{eprint}
      \verb 1511.05952
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/CHFNRVNH/Schaul et al. - 2016 - Prioritized Experience Replay.pdf;/home/james/Zotero/storage/J4MBXBBX/1511.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schmidtFastDataEfficientTraining2021}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=317ec33d3bf8a1ad361e079b7606ea9c}{%
           family={Schmidt},
           familyi={S\bibinitperiod},
           given={Dominik},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e6f284000b7dde020f33730affa8dd7b}{%
           family={Schmied},
           familyi={S\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{fullhash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{bibnamehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{authorbibnamehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{authornamehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{authorfullhash}{80b76867f1f54a47af6f13e4ac55ae79}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Across the Arcade Learning Environment, Rainbow achieves a level of performance competitive with humans and modern RL algorithms. However, attaining this level of performance requires large amounts of data and hardware resources, making research in this area computationally expensive and use in practical applications often infeasible. This paper's contribution is threefold: We (1) propose an improved version of Rainbow, seeking to drastically reduce Rainbow's data, training time, and compute requirements while maintaining its competitive performance; (2) we empirically demonstrate the effectiveness of our approach through experiments on the Arcade Learning Environment, and (3) we conduct a number of ablation studies to investigate the effect of the individual proposed modifications. Our improved version of Rainbow reaches a median human normalized score close to classic Rainbow's, while using 20 times less data and requiring only 7.5 hours of training time on a single GPU. We also provide our full implementation including pre-trained models.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2111.10247}
      \field{shorttitle}{Fast and {{Data-Efficient Training}} of {{Rainbow}}}
      \field{title}{Fast and {{Data-Efficient Training}} of {{Rainbow}}: An {{Experimental Study}} on {{Atari}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2111.10247
      \endverb
      \verb{eprint}
      \verb 2111.10247
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schmidt_Schmied_2021_Fast and Data-Efficient Training of Rainbow.pdf;/home/james/Zotero/storage/M74K5ABX/2111.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schrittwieserMasteringAtariGo2020}{article}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=8fad8df927bc0014c0bd6a9feb7aa71d}{%
           family={Schrittwieser},
           familyi={S\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80c63e95a9e243591a33a7e3156f1d78}{%
           family={Hubert},
           familyi={H\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d16b7284df92c9adaee86c37ab992df}{%
           family={Simonyan},
           familyi={S\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50d24de916599d306c5cb1a77156e4b9}{%
           family={Sifre},
           familyi={S\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80f59bf87c57eee7dab96e04c0a83c30}{%
           family={Schmitt},
           familyi={S\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=67c36471603b6de0347c489b0f8b05b0}{%
           family={Lockhart},
           familyi={L\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=368b9b2de627b852658c433b062d4e1e}{%
           family={Graepel},
           familyi={G\bibinitperiod},
           given={Thore},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ba8dd9d821587916ffa0d5d85ba62066}
      \strng{fullhash}{a2393dd56fc0d1677b29875d3184f845}
      \strng{bibnamehash}{a2393dd56fc0d1677b29875d3184f845}
      \strng{authorbibnamehash}{a2393dd56fc0d1677b29875d3184f845}
      \strng{authornamehash}{ba8dd9d821587916ffa0d5d85ba62066}
      \strng{authorfullhash}{a2393dd56fc0d1677b29875d3184f845}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{issn}{0028-0836, 1476-4687}
      \field{journaltitle}{Nature}
      \field{month}{12}
      \field{number}{7839}
      \field{title}{Mastering {{Atari}}, {{Go}}, {{Chess}} and {{Shogi}} by {{Planning}} with a {{Learned Model}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{volume}{588}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{604\bibrangedash 609}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1038/s41586-020-03051-4
      \endverb
      \verb{eprint}
      \verb 1911.08265
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schrittwieser et al_2020_Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf;/home/james/Zotero/storage/XRX7QTMG/1911.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{schroffFaceNetUnifiedEmbedding2015}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=c62e96f68033a3d3cd4639e35a2de4da}{%
           family={Schroff},
           familyi={S\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6cbb997a11c6922af719c32863261918}{%
           family={Kalenichenko},
           familyi={K\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e9a1d678032dfffb4e871a0f622e030}{%
           family={Philbin},
           familyi={P\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{5eafdb6c00f832f72d64a3a8c5e2fa1c}
      \strng{fullhash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \strng{bibnamehash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \strng{authorbibnamehash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \strng{authornamehash}{5eafdb6c00f832f72d64a3a8c5e2fa1c}
      \strng{authorfullhash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63\%. On YouTube Faces DB it achieves 95.12\%. Our system cuts the error rate in comparison to the best published result by 30\% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1503.03832}
      \field{shorttitle}{{{FaceNet}}}
      \field{title}{{{FaceNet}}: {{A Unified Embedding}} for {{Face Recognition}} and {{Clustering}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1503.03832
      \endverb
      \verb{eprint}
      \verb 1503.03832
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/SEE6IFHK/Schroff et al. - 2015 - FaceNet A Unified Embedding for Face Recognition and Clustering.pdf;/home/james/Zotero/storage/IPCU2YUA/1503.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{schulmanTrustRegionPolicy2017}{misc}{}
      \name{author}{5}{ul=2}{%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a901fd78fe1108cfa7d11129644967c7}{%
           family={Moritz},
           familyi={M\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8a36116840c7ee55901618c95fd08a58}{%
           family={Jordan},
           familyi={J\bibinitperiod},
           given={Michael\bibnamedelima I.},
           giveni={M\bibinitperiod\bibinitdelim I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{4290bc9e05fb16d946cdb7a6a222296e}
      \strng{fullhash}{945251de1d41bc2767a541a8148f51da}
      \strng{bibnamehash}{945251de1d41bc2767a541a8148f51da}
      \strng{authorbibnamehash}{945251de1d41bc2767a541a8148f51da}
      \strng{authornamehash}{4290bc9e05fb16d946cdb7a6a222296e}
      \strng{authorfullhash}{945251de1d41bc2767a541a8148f51da}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:1502.05477}
      \field{title}{Trust {{Region Policy Optimization}}}
      \field{urlday}{2}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1502.05477
      \endverb
      \verb{eprint}
      \verb 1502.05477
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schulman et al_2017_Trust Region Policy Optimization.pdf;/home/james/Zotero/storage/Y28SL8PZ/1502.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schulmanProximalPolicyOptimization2017}{misc}{}
      \name{author}{5}{ul=2}{%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=674ede0b9cd02a2bf5fc662972efb9f0}{%
           family={Wolski},
           familyi={W\bibinitperiod},
           given={Filip},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4164e43d8cf919f5e3f8d80f5ea23f36}{%
           family={Dhariwal},
           familyi={D\bibinitperiod},
           given={Prafulla},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a812c46caad94fc8701be37871f303ba}{%
           family={Radford},
           familyi={R\bibinitperiod},
           given={Alec},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be38507da6ab98e7ac01ac2c6b7e13eb}{%
           family={Klimov},
           familyi={K\bibinitperiod},
           given={Oleg},
           giveni={O\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{f85997ca29b89a9a0cc61ebadb2cd7fe}
      \strng{fullhash}{a6c6ed5a5aeb74e536f16291276ae392}
      \strng{bibnamehash}{a6c6ed5a5aeb74e536f16291276ae392}
      \strng{authorbibnamehash}{a6c6ed5a5aeb74e536f16291276ae392}
      \strng{authornamehash}{f85997ca29b89a9a0cc61ebadb2cd7fe}
      \strng{authorfullhash}{a6c6ed5a5aeb74e536f16291276ae392}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{number}{arXiv:1707.06347}
      \field{title}{Proximal {{Policy Optimization Algorithms}}}
      \field{urlday}{2}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1707.06347
      \endverb
      \verb{eprint}
      \verb 1707.06347
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schulman et al_2017_Proximal Policy Optimization Algorithms.pdf;/home/james/Zotero/storage/4AW5IADX/1707.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schulmanHighDimensionalContinuousControl2018}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a901fd78fe1108cfa7d11129644967c7}{%
           family={Moritz},
           familyi={M\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5010abb47d34a51acdafb266a811dc5f}{%
           family={Jordan},
           familyi={J\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8d6613ae59595910252a86a61babf6c8}
      \strng{fullhash}{824be54bbf358cb68164f9e82cccbd21}
      \strng{bibnamehash}{824be54bbf358cb68164f9e82cccbd21}
      \strng{authorbibnamehash}{824be54bbf358cb68164f9e82cccbd21}
      \strng{authornamehash}{8d6613ae59595910252a86a61babf6c8}
      \strng{authorfullhash}{824be54bbf358cb68164f9e82cccbd21}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1506.02438}
      \field{title}{High-{{Dimensional Continuous Control Using Generalized Advantage Estimation}}}
      \field{urlday}{23}
      \field{urlmonth}{7}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1506.02438
      \endverb
      \verb{eprint}
      \verb 1506.02438
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schulman et al_2018_High-Dimensional Continuous Control Using Generalized Advantage Estimation.pdf;/home/james/Zotero/storage/WVY9PNF9/1506.html
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control}
    \endentry
    \entry{schwarzerDataEfficientReinforcementLearning2021}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9c04884349329f54db6669b03ab4d4a}{%
           family={Anand},
           familyi={A\bibinitperiod},
           given={Ankesh},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bb9d1ac8dcc19d49d5d79ec9bf11464a}{%
           family={Goel},
           familyi={G\bibinitperiod},
           given={Rishab},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=68d18c6f3387bc203910c98ed4e1303c}{%
           family={Hjelm},
           familyi={H\bibinitperiod},
           given={R.\bibnamedelimi Devon},
           giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=799d66480d783672ee2f29b7fb418229}{%
           family={Bachman},
           familyi={B\bibinitperiod},
           given={Philip},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{fullhash}{50236f5c9d7cf94f939da49ade6852df}
      \strng{bibnamehash}{50236f5c9d7cf94f939da49ade6852df}
      \strng{authorbibnamehash}{50236f5c9d7cf94f939da49ade6852df}
      \strng{authornamehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{authorfullhash}{50236f5c9d7cf94f939da49ade6852df}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment. Our method, Self-Predictive Representations(SPR), trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent's parameters and we make predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent's representations to be consistent across multiple views of an observation. Our full self-supervised objective, which combines future prediction and data augmentation, achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55\% relative improvement over the previous state-of-the-art. Notably, even in this limited data regime, SPR exceeds expert human scores on 7 out of 26 games. The code associated with this work is available at https://github.com/mila-iqia/spr}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:2007.05929}
      \field{title}{Data-{{Efficient Reinforcement Learning}} with {{Self-Predictive Representations}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2007.05929
      \endverb
      \verb{eprint}
      \verb 2007.05929
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schwarzer et al_2021_Data-Efficient Reinforcement Learning with Self-Predictive Representations.pdf;/home/james/Zotero/storage/CJ3N5GZP/2007.html
      \endverb
      \keyw{Computer Science - Machine Learning,Data-efficient RL,Statistics - Machine Learning}
    \endentry
    \entry{schwarzerBiggerBetterFaster2023}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31615496c3b6b2cb98ee532481ce05bd}{%
           family={{Obando-Ceron}},
           familyi={O\bibinitperiod},
           given={Johan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c381224f01b0b3e0e463075180d66906}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a3ce7bf5b3d6fcc96d09f5142950dd8d}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Rishabh},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd36c2abe3c5c9ea4b21e5258e5f3a37}{%
           family={Castro},
           familyi={C\bibinitperiod},
           given={Pablo\bibnamedelima Samuel},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{fullhash}{592a3526df4ec2a34afa18b5d01c3d32}
      \strng{bibnamehash}{592a3526df4ec2a34afa18b5d01c3d32}
      \strng{authorbibnamehash}{592a3526df4ec2a34afa18b5d01c3d32}
      \strng{authornamehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{authorfullhash}{592a3526df4ec2a34afa18b5d01c3d32}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark. BBF relies on scaling the neural networks used for value estimation, as well as a number of other design choices that enable this scaling in a sample-efficient manner. We conduct extensive analyses of these design choices and provide insights for future work. We end with a discussion about updating the goalposts for sample-efficient RL research on the ALE. We make our code and data publicly available at https://github.com/google-research/google-research/tree/master/bigger\_better\_faster.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2305.19452}
      \field{shorttitle}{Bigger, {{Better}}, {{Faster}}}
      \field{title}{Bigger, {{Better}}, {{Faster}}: {{Human-level Atari}} with Human-Level Efficiency}
      \field{urlday}{1}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2305.19452
      \endverb
      \verb{eprint}
      \verb 2305.19452
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/4UIE9QDK/Schwarzer et al. - 2023 - Bigger, Better, Faster Human-level Atari with hum.pdf;/home/james/Zotero/storage/5F7DCQN3/2305.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{sekarPlanningExploreSelfSupervised2020}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=897066b1efdb6d7ca706f9af32d3ac00}{%
           family={Sekar},
           familyi={S\bibinitperiod},
           given={Ramanan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e74881acde81e3e0bbe845cc98697ce}{%
           family={Rybkin},
           familyi={R\bibinitperiod},
           given={Oleh},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=26789faf98e6ba54553cd620a8da71b2}{%
           family={Daniilidis},
           familyi={D\bibinitperiod},
           given={Kostas},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=09e431093c8637ade01037714cfc992c}{%
           family={Pathak},
           familyi={P\bibinitperiod},
           given={Deepak},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{fbe527297def415bbc47ffc645aaea1b}
      \strng{fullhash}{f55028c18aad16ec28e8f83cd0b15e67}
      \strng{bibnamehash}{f55028c18aad16ec28e8f83cd0b15e67}
      \strng{authorbibnamehash}{f55028c18aad16ec28e8f83cd0b15e67}
      \strng{authornamehash}{fbe527297def415bbc47ffc645aaea1b}
      \strng{authorfullhash}{f55028c18aad16ec28e8f83cd0b15e67}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Reinforcement learning allows solving complex tasks, however, the learning tends to be task-specific and the sample efficiency remains a challenge. We present Plan2Explore, a self-supervised reinforcement learning agent that tackles both these challenges through a new approach to self-supervised exploration and fast adaptation to new tasks, which need not be known during exploration. During exploration, unlike prior methods which retrospectively compute the novelty of observations after the agent has already reached them, our agent acts efficiently by leveraging planning to seek out expected future novelty. After exploration, the agent quickly adapts to multiple downstream tasks in a zero or a few-shot manner. We evaluate on challenging control tasks from high-dimensional image inputs. Without any training supervision or task-specific interaction, Plan2Explore outperforms prior self-supervised exploration methods, and in fact, almost matches the performances oracle which has access to rewards. Videos and code at https://ramanans1.github.io/plan2explore/}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:2005.05960}
      \field{title}{Planning to {{Explore}} via {{Self-Supervised World Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2005.05960
      \endverb
      \verb{eprint}
      \verb 2005.05960
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Sekar et al_2020_Planning to Explore via Self-Supervised World Models.pdf;/home/james/Zotero/storage/4BR97L5S/2005.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{seoMaskedWorldModels2022}{misc}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=ae0ec5c679a01d9aa465ab4c6bd223e8}{%
           family={Seo},
           familyi={S\bibinitperiod},
           given={Younggyo},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33104fd0f457a2964af323817a9d2016}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ad0d24bb008c9b37c59a3279f34cd576}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Fangchen},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d0930396d05237554ef2822bdaa7991}{%
           family={James},
           familyi={J\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a74a7d6a839e48de367e41b7ec29d456}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kimin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8c8e07ad88393070efdc5901bf9676fe}
      \strng{fullhash}{b8129dad0a66bd6a468e2ca397eb7718}
      \strng{bibnamehash}{b8129dad0a66bd6a468e2ca397eb7718}
      \strng{authorbibnamehash}{b8129dad0a66bd6a468e2ca397eb7718}
      \strng{authornamehash}{8c8e07ad88393070efdc5901bf9676fe}
      \strng{authorfullhash}{b8129dad0a66bd6a468e2ca397eb7718}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Visual model-based reinforcement learning (RL) has the potential to enable sample-efficient robot learning from visual observations. Yet the current approaches typically train a single model end-to-end for learning both visual representations and dynamics, making it difficult to accurately model the interaction between robots and small objects. In this work, we introduce a visual model-based RL framework that decouples visual representation learning and dynamics learning. Specifically, we train an autoencoder with convolutional layers and vision transformers (ViT) to reconstruct pixels given masked convolutional features, and learn a latent dynamics model that operates on the representations from the autoencoder. Moreover, to encode task-relevant information, we introduce an auxiliary reward prediction objective for the autoencoder. We continually update both autoencoder and dynamics model using online samples collected from environment interaction. We demonstrate that our decoupling approach achieves state-of-the-art performance on a variety of visual robotic tasks from Meta-world and RLBench, e.g., we achieve 81.7\% success rate on 50 visual robotic manipulation tasks from Meta-world, while the baseline achieves 67.9\%. Code is available on the project website: https://sites.google.com/view/mwm-rl.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2206.14244}
      \field{title}{Masked {{World Models}} for {{Visual Control}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2206.14244
      \endverb
      \verb{eprint}
      \verb 2206.14244
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Seo et al_2022_Masked World Models for Visual Control.pdf;/home/james/Zotero/storage/PNWMPJVN/2206.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{silverMasteringGameGo2016}{article}{}
      \name{author}{20}{}{%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba4b200ce1412a2570cb113366cc9559}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Aja},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c3126321fcb4553dfda5ae96da928ce}{%
           family={Maddison},
           familyi={M\bibinitperiod},
           given={Chris\bibnamedelima J.},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50d24de916599d306c5cb1a77156e4b9}{%
           family={Sifre},
           familyi={S\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=65eeec6e3586f64c853c49d82d697609}{%
           family={{van den Driessche}},
           familyi={v\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8fad8df927bc0014c0bd6a9feb7aa71d}{%
           family={Schrittwieser},
           familyi={S\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1f065703a4f7a60c69ecb59f499d3db3}{%
           family={Panneershelvam},
           familyi={P\bibinitperiod},
           given={Veda},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3075d0e02c0833f6e5fe1addb880898f}{%
           family={Lanctot},
           familyi={L\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a133b469b21b870786119a47b1b691eb}{%
           family={Dieleman},
           familyi={D\bibinitperiod},
           given={Sander},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c19e654fe7f97a2862b0f06588d04c42}{%
           family={Grewe},
           familyi={G\bibinitperiod},
           given={Dominik},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5560aef5a586c04b85130c3be44a3b6a}{%
           family={Nham},
           familyi={N\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d2d0778c1cdd451c75b874b58eec7564}{%
           family={Kalchbrenner},
           familyi={K\bibinitperiod},
           given={Nal},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=958e13979b3920f7fb4793ed8dddcb33}{%
           family={Leach},
           familyi={L\bibinitperiod},
           given={Madeleine},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=368b9b2de627b852658c433b062d4e1e}{%
           family={Graepel},
           familyi={G\bibinitperiod},
           given={Thore},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Nature Publishing Group}%
      }
      \strng{namehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{fullhash}{a04d588961aa93c7ef28f0e5175e82f7}
      \strng{bibnamehash}{a04d588961aa93c7ef28f0e5175e82f7}
      \strng{authorbibnamehash}{a04d588961aa93c7ef28f0e5175e82f7}
      \strng{authornamehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{authorfullhash}{a04d588961aa93c7ef28f0e5175e82f7}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks' to evaluate board positions and `policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{7587}
      \field{title}{Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{529}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{484\bibrangedash 489}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1038/nature16961
      \endverb
      \keyw{Computational science,Computer science,Reward}
    \endentry
    \entry{silverPredictronEndToEndLearning2017}{misc}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f5a8983bab24d2cd5670100e485fc883}{%
           family={Hasselt},
           familyi={H\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0,
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b63b9b2d91f6ba1b1739563edc0432ab}{%
           family={Harley},
           familyi={H\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e75a9df444c5ef79ce4db4c8dd76ddc}{%
           family={{Dulac-Arnold}},
           familyi={D\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ff36bcecacbac6382f6f3048b316d708}{%
           family={Reichert},
           familyi={R\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d4fe8a888824c1acfd5345200ddc5f9b}{%
           family={Rabinowitz},
           familyi={R\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c53eb4a374df4bfac9e88c6cd01fa57d}{%
           family={Barreto},
           familyi={B\bibinitperiod},
           given={Andre},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6598b6ed3c197bb4292561d14d01436f}{%
           family={Degris},
           familyi={D\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{fullhash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \strng{bibnamehash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \strng{authorbibnamehash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \strng{authornamehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{authorfullhash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{One of the key challenges of artificial intelligence is to learn models that are effective in the context of planning. In this document we introduce the predictron architecture. The predictron consists of a fully abstract model, represented by a Markov reward process, that can be rolled forward multiple "imagined" planning steps. Each forward pass of the predictron accumulates internal rewards and values over multiple planning depths. The predictron is trained end-to-end so as to make these accumulated values accurately approximate the true value function. We applied the predictron to procedurally generated random mazes and a simulator for the game of pool. The predictron yielded significantly more accurate predictions than conventional deep neural network architectures.}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1612.08810}
      \field{shorttitle}{The {{Predictron}}}
      \field{title}{The {{Predictron}}: {{End-To-End Learning}} and {{Planning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1612.08810
      \endverb
      \verb{eprint}
      \verb 1612.08810
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/47Y5Q28Y/Silver et al. - 2017 - The Predictron End-To-End Learning and Planning.pdf;/home/james/Zotero/storage/RXLHAJZ3/1612.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing}
    \endentry
    \entry{srinivasCURLContrastiveUnsupervised2020}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=09fed423ccdd83193718e9e7e2c70481}{%
           family={Srinivas},
           familyi={S\bibinitperiod},
           given={Aravind},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af9729d0e8bc4f4722f164d7b1035749}{%
           family={Laskin},
           familyi={L\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{81b286869b6ba5302cf855115e96cc20}
      \strng{fullhash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \strng{bibnamehash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \strng{authorbibnamehash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \strng{authornamehash}{81b286869b6ba5302cf855115e96cc20}
      \strng{authorfullhash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present CURL: Contrastive Unsupervised Representations for Reinforcement Learning. CURL extracts high-level features from raw pixels using contrastive learning and performs off-policy control on top of the extracted features. CURL outperforms prior pixel-based methods, both model-based and model-free, on complex tasks in the DeepMind Control Suite and Atari Games showing 1.9x and 1.2x performance gains at the 100K environment and interaction steps benchmarks respectively. On the DeepMind Control Suite, CURL is the first image-based algorithm to nearly match the sample-efficiency of methods that use state-based features. Our code is open-sourced and available at https://github.com/MishaLaskin/curl.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{9}
      \field{number}{arXiv:2004.04136}
      \field{shorttitle}{{{CURL}}}
      \field{title}{{{CURL}}: {{Contrastive Unsupervised Representations}} for {{Reinforcement Learning}}}
      \field{urlday}{21}
      \field{urlmonth}{6}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2004.04136
      \endverb
      \verb{eprint}
      \verb 2004.04136
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Srinivas et al_2020_CURL.pdf;/home/james/Zotero/storage/V2B9BSM7/2004.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,RL,Statistics - Machine Learning,Unsupervised RL}
    \endentry
    \entry{suttonLearningPredictMethods1988}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S.},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{fullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{bibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorbibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authornamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorfullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article introduces a class of incremental learning procedures specialized for prediction-that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.}
      \field{issn}{1573-0565}
      \field{journaltitle}{Machine Learning}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{1}
      \field{title}{Learning to Predict by the Methods of Temporal Differences}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{3}
      \field{year}{1988}
      \field{urldateera}{ce}
      \field{pages}{9\bibrangedash 44}
      \range{pages}{36}
      \verb{doi}
      \verb 10.1007/BF00115009
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/SIJVVH67/Sutton - 1988 - Learning to predict by the methods of temporal differences.pdf
      \endverb
      \keyw{Artificial Intelligence,connectionism,credit assignment,evaluation functions,Incremental learning,prediction}
    \endentry
    \entry{sutton2018reinforcement}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{fullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{bibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorbibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authornamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorfullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{A Bradford Book}
      \field{title}{Reinforcement learning: An introduction}
      \field{year}{2018}
    \endentry
    \entry{suttonPolicyGradientMethods1999}{inbook}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=09a4af5c985fc9a46727803f19cd8272}{%
           family={McAllester},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74d941c38e5affcd359ed5814815805f}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Satinder},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ad31daafb6eb6186dd51ffeae5196ec0}{%
           family={Mansour},
           familyi={M\bibinitperiod},
           given={Yishay},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{3}{}{%
        {{hash=b355381619d6a313804fe1e82c3c5d5e}{%
           family={Solla},
           familyi={S\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=d0fa2183d141c3c709a512cab4fee1b2}{%
           family={Leen},
           familyi={L\bibinitperiod},
           given={T.},
           giveni={T\bibinitperiod}}}%
        {{hash=45d0bd8fb04f1a74dbec720c7ccf750e}{%
           family={MÃ¼ller},
           familyi={M\bibinitperiod},
           given={K.},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{176c86aa36fab51e81d033c2d8ea8cbe}
      \strng{fullhash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{bibnamehash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{authorbibnamehash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{authornamehash}{176c86aa36fab51e81d033c2d8ea8cbe}
      \strng{authorfullhash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{editorbibnamehash}{fa42941c20b5f08a036d8fc84cd1cdf0}
      \strng{editornamehash}{c8beec784e7d915fa390896f6b5e9dfa}
      \strng{editorfullhash}{fa42941c20b5f08a036d8fc84cd1cdf0}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Advances in {{Neural Information Processing Systems}}}
      \field{title}{Policy {{Gradient Methods}} for {{Reinforcement Learning}} with {{Function Approximation}}}
      \field{volume}{12}
      \field{year}{1999}
    \endentry
    \entry{tassaDeepMindControlSuite2018}{misc}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=58112cb88a80c1bc045b6eaab26a8695}{%
           family={Tassa},
           familyi={T\bibinitperiod},
           given={Yuval},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=237b733d6914e7eb0f991903046d13a3}{%
           family={Doron},
           familyi={D\bibinitperiod},
           given={Yotam},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3eb7f8dffab1558054d5f9ec78d2fac2}{%
           family={Muldal},
           familyi={M\bibinitperiod},
           given={Alistair},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3b79ca47f08451987877fd8682e971e5}{%
           family={Erez},
           familyi={E\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ea8af3b8f68d4c40172af64bc26a53c6}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yazhe},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2065f849a50a25340022b8ea9c67cdf8}{%
           family={Casas},
           familyi={C\bibinitperiod},
           given={Diego\bibnamedelimb de\bibnamedelima Las},
           giveni={D\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c23f8012677b40de82f339368c393522}{%
           family={Budden},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=528d31a6b5c1231e01391e2597dd5491}{%
           family={Abdolmaleki},
           familyi={A\bibinitperiod},
           given={Abbas},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ac49e241f88460f90f9f1ab5f88db248}{%
           family={Merel},
           familyi={M\bibinitperiod},
           given={Josh},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74cc29ccd6d85aa2fba6fdb64104d432}{%
           family={Lefrancq},
           familyi={L\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b5137dee7101e4a7d1b4962348fb537a}
      \strng{fullhash}{2f52eb92fdec83e02a26d2211ea3a512}
      \strng{bibnamehash}{2f52eb92fdec83e02a26d2211ea3a512}
      \strng{authorbibnamehash}{2f52eb92fdec83e02a26d2211ea3a512}
      \strng{authornamehash}{b5137dee7101e4a7d1b4962348fb537a}
      \strng{authorfullhash}{2f52eb92fdec83e02a26d2211ea3a512}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The DeepMind Control Suite is a set of continuous control tasks with a standardised structure and interpretable rewards, intended to serve as performance benchmarks for reinforcement learning agents. The tasks are written in Python and powered by the MuJoCo physics engine, making them easy to use and modify. We include benchmarks for several learning algorithms. The Control Suite is publicly available at https://www.github.com/deepmind/dm\_control . A video summary of all tasks is available at http://youtu.be/rAai4QzcYbs .}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:1801.00690}
      \field{title}{{{DeepMind Control Suite}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1801.00690
      \endverb
      \verb{eprint}
      \verb 1801.00690
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/WCCR5876/Tassa et al. - 2018 - DeepMind Control Suite.pdf;/home/james/Zotero/storage/7WQI6APV/1801.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence}
    \endentry
    \entry{tobinDomainRandomizationTransferring2017}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=e6a2e03971ee3e138dbe64b3a4c5a95a}{%
           family={Tobin},
           familyi={T\bibinitperiod},
           given={Josh},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=71105dfe9b3b73a20fb9a3156d389fad}{%
           family={Fong},
           familyi={F\bibinitperiod},
           given={Rachel},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=143fa59d90387ae4a6aa650dcf1c7ceb}{%
           family={Ray},
           familyi={R\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5167ef9d0b77bf68557730648baac9b7}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9fec85bbce1b087a6ebefe26e73f7bf}{%
           family={Zaremba},
           familyi={Z\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{2c42dddd45e1ea280a64e08c9a87d720}
      \strng{fullhash}{59127397f3045b880071f52e5e66fdf5}
      \strng{bibnamehash}{59127397f3045b880071f52e5e66fdf5}
      \strng{authorbibnamehash}{59127397f3045b880071f52e5e66fdf5}
      \strng{authornamehash}{2c42dddd45e1ea280a64e08c9a87d720}
      \strng{authorfullhash}{59127397f3045b880071f52e5e66fdf5}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Bridging the 'reality gap' that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to \$1.5\$cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated RGB images (without pre-training on real images) to the real world for the purpose of robotic control.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1703.06907}
      \field{title}{Domain {{Randomization}} for {{Transferring Deep Neural Networks}} from {{Simulation}} to the {{Real World}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1703.06907
      \endverb
      \verb{eprint}
      \verb 1703.06907
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/ZRMJ52LT/Tobin et al. - 2017 - Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World.pdf;/home/james/Zotero/storage/6LWYXQFS/1703.html
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{oordNeuralDiscreteRepresentation2018}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=705a5ed355c190be3a39e0a5134d2ae5}{%
           family={Oord},
           familyi={O\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0,
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=494b568c5dc85ba8f3f409635f9c5f25}{%
           family={Vinyals},
           familyi={V\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{d5a17822de636ff8de45307e236e0824}
      \strng{fullhash}{1f8f233c911e6ffbd85ce894897a4da5}
      \strng{bibnamehash}{1f8f233c911e6ffbd85ce894897a4da5}
      \strng{authorbibnamehash}{1f8f233c911e6ffbd85ce894897a4da5}
      \strng{authornamehash}{d5a17822de636ff8de45307e236e0824}
      \strng{authorfullhash}{1f8f233c911e6ffbd85ce894897a4da5}
      \field{sortinit}{v}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:1711.00937}
      \field{title}{Neural {{Discrete Representation Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1711.00937
      \endverb
      \verb{eprint}
      \verb 1711.00937
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Oord et al_2018_Neural Discrete Representation Learning.pdf;/home/james/Zotero/storage/JSPM23UP/1711.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{vanhasseltWhenUseParametric2019}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=e75f0b2e9c29c175e6320c1e96cdf5c8}{%
           family={{van Hasselt}},
           familyi={v\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e99abbc8dd53e5feeb2a428724ce1d2f}{%
           family={Aslanides},
           familyi={A\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{36a61a17516a81e9bf666a75302c9d59}
      \strng{fullhash}{6998db2d1facb5377c74726679d38cd6}
      \strng{bibnamehash}{6998db2d1facb5377c74726679d38cd6}
      \strng{authorbibnamehash}{6998db2d1facb5377c74726679d38cd6}
      \strng{authornamehash}{36a61a17516a81e9bf666a75302c9d59}
      \strng{authorfullhash}{6998db2d1facb5377c74726679d38cd6}
      \field{extraname}{1}
      \field{sortinit}{v}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We examine the question of when and how parametric models are most useful in reinforcement learning. In particular, we look at commonalities and differences between parametric models and experience replay. Replay-based learning algorithms share important traits with model-based approaches, including the ability to plan: to use more computation without additional data to improve predictions and behaviour. We discuss when to expect benefits from either approach, and interpret prior work in this context. We hypothesise that, under suitable conditions, replay-based algorithms should be competitive to or better than model-based algorithms if the model is used only to generate fictional transitions from observed states for an update rule that is otherwise model-free. We validated this hypothesis on Atari 2600 video games. The replay-based algorithm attained state-of-the-art data efficiency, improving over prior results with parametric models.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1906.05243}
      \field{title}{When to Use Parametric Models in Reinforcement Learning?}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1906.05243
      \endverb
      \verb{eprint}
      \verb 1906.05243
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/van Hasselt et al_2019_When to use parametric models in reinforcement learning.pdf;/home/james/Zotero/storage/LT5GCZ6M/1906.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{hasseltDeepReinforcementLearning2015}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=f5a8983bab24d2cd5670100e485fc883}{%
           family={Hasselt},
           familyi={H\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0,
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a665efce46f880c07855c38cd56bd189}
      \strng{fullhash}{2bcc40866d8b979d51a84d2f43f45202}
      \strng{bibnamehash}{2bcc40866d8b979d51a84d2f43f45202}
      \strng{authorbibnamehash}{2bcc40866d8b979d51a84d2f43f45202}
      \strng{authornamehash}{a665efce46f880c07855c38cd56bd189}
      \strng{authorfullhash}{2bcc40866d8b979d51a84d2f43f45202}
      \field{extraname}{2}
      \field{sortinit}{v}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1509.06461}
      \field{title}{Deep {{Reinforcement Learning}} with {{Double Q-learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1509.06461
      \endverb
      \verb{eprint}
      \verb 1509.06461
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/KN8LT52B/Hasselt et al. - 2015 - Deep Reinforcement Learning with Double Q-learning.pdf;/home/james/Zotero/storage/CERMKB9X/1509.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{vaswaniAttentionAllYou2017}{misc}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N.},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2bc899b1160163417da7bf510f15d33}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Lukasz},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{bibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authorbibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1706.03762}
      \field{title}{Attention {{Is All You Need}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1706.03762
      \endverb
      \verb{eprint}
      \verb 1706.03762
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Vaswani et al_2017_Attention Is All You Need.pdf;/home/james/Zotero/storage/MIYXNHJH/1706.html
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning,Transformers}
    \endentry
    \entry{inproceedings}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=da21e966c02c3cfd33d74369c7435c1a}{%
           family={Vincent},
           familyi={V\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=42a970b0a0f1ed24b23064370cc9392f}{%
           family={Larochelle},
           familyi={L\bibinitperiod},
           given={Hugo},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=419350ebbeb4eba5351469f378dee007}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ba1a9455f15a2898752cabc022e1887}{%
           family={Manzagol},
           familyi={M\bibinitperiod},
           given={Pierre-Antoine},
           giveni={P\bibinithyphendelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{17d6344b63d3d08616d701213bf1af6a}
      \strng{fullhash}{178ee493b3884ed5cf4aad60949d7564}
      \strng{bibnamehash}{178ee493b3884ed5cf4aad60949d7564}
      \strng{authorbibnamehash}{178ee493b3884ed5cf4aad60949d7564}
      \strng{authornamehash}{17d6344b63d3d08616d701213bf1af6a}
      \strng{authorfullhash}{178ee493b3884ed5cf4aad60949d7564}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{1}
      \field{series}{Proceedings of the 25th {{International Conference}} on {{Machine Learning}}}
      \field{title}{Extracting and Composing Robust Features with Denoising Autoencoders}
      \field{year}{2008}
      \field{pages}{1096\bibrangedash 1103}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/1390156.1390294
      \endverb
    \endentry
    \entry{vinyalsGrandmasterLevelStarCraft2019}{article}{}
      \name{author}{42}{}{%
        {{un=0,uniquepart=base,hash=494b568c5dc85ba8f3f409635f9c5f25}{%
           family={Vinyals},
           familyi={V\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=92efe2a8e13a9b7a3fb647951ee2391c}{%
           family={Babuschkin},
           familyi={B\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5dc7de68ac7f0299a995822f38a3e705}{%
           family={Czarnecki},
           familyi={C\bibinitperiod},
           given={Wojciech\bibnamedelima M.},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b3fbcff36ec4b37aed7c56f67c21038b}{%
           family={Mathieu},
           familyi={M\bibinitperiod},
           given={MichaÃ«l},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=76a7579d94d000dca5e0071fb3b69382}{%
           family={Dudzik},
           familyi={D\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a79e6bb4ca772c9b3b38f4e9f45b83c}{%
           family={Chung},
           familyi={C\bibinitperiod},
           given={Junyoung},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=17ad757032d822b4a43e828ae592c91e}{%
           family={Choi},
           familyi={C\bibinitperiod},
           given={David\bibnamedelima H.},
           giveni={D\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2820daeb58d4d5a594fbdaf6db68f850}{%
           family={Powell},
           familyi={P\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2687d58e59afed22249974d723704f56}{%
           family={Ewalds},
           familyi={E\bibinitperiod},
           given={Timo},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1c5b83cefd7033a528994276b9c00e87}{%
           family={Georgiev},
           familyi={G\bibinitperiod},
           given={Petko},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d6a1e759373b43eefda2aab3aec6b728}{%
           family={Oh},
           familyi={O\bibinitperiod},
           given={Junhyuk},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c1a26cb7f963abdf071da408366e83a1}{%
           family={Horgan},
           familyi={H\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be1b190734e6a891e14bf8c4adc4d1c3}{%
           family={Kroiss},
           familyi={K\bibinitperiod},
           given={Manuel},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=970650e9394fccd4144d4b829505d2b3}{%
           family={Danihelka},
           familyi={D\bibinitperiod},
           given={Ivo},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba4b200ce1412a2570cb113366cc9559}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Aja},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50d24de916599d306c5cb1a77156e4b9}{%
           family={Sifre},
           familyi={S\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3d7a83ed6eb983ca17cec804631dc22e}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e4fa217e56ca1781ab11713ab27cf2b4}{%
           family={Agapiou},
           familyi={A\bibinitperiod},
           given={John\bibnamedelima P.},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7dc1446dea7ff50b2b02fb83780cc9c6}{%
           family={Jaderberg},
           familyi={J\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=06f6f348a3bb818c79944f71cf518f3f}{%
           family={Vezhnevets},
           familyi={V\bibinitperiod},
           given={Alexander\bibnamedelima S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f64056fe9107fedd28b447d31bfc157b}{%
           family={Leblond},
           familyi={L\bibinitperiod},
           given={RÃ©mi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b1bdbd9e1dcbed6591878a57d5058c54}{%
           family={Pohlen},
           familyi={P\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=39809e64cffbcbfd42bd81da5153546a}{%
           family={Dalibard},
           familyi={D\bibinitperiod},
           given={Valentin},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c23f8012677b40de82f339368c393522}{%
           family={Budden},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=22eaafdd6c3038933341b729e199e0ce}{%
           family={Sulsky},
           familyi={S\bibinitperiod},
           given={Yury},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=88dca93fff01bbe55329c40c0891257d}{%
           family={Molloy},
           familyi={M\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f565c54b0935cdca35d3d90b831013cf}{%
           family={Paine},
           familyi={P\bibinitperiod},
           given={Tom\bibnamedelima L.},
           giveni={T\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2adc0c92c308f233c731321d55efe58f}{%
           family={Gulcehre},
           familyi={G\bibinitperiod},
           given={Caglar},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=05bc8d503a2c310ef0976ace7f9d2734}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ziyu},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a726408819b6f955652c3ffaaedef966}{%
           family={Pfaff},
           familyi={P\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=954bef435a12336c9decd19360a640f5}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yuhuai},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50349f5d4ef065e417356ee70e0f7069}{%
           family={Ring},
           familyi={R\bibinitperiod},
           given={Roman},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=14889c0769f78922934df82a671f0cf3}{%
           family={Yogatama},
           familyi={Y\bibinitperiod},
           given={Dani},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=616c76aced80eaed20688f6ab93db271}{%
           family={WÃ¼nsch},
           familyi={W\bibinitperiod},
           given={Dario},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5f3f9f74e6c498a754b9a8a7b7a53311}{%
           family={McKinney},
           familyi={M\bibinitperiod},
           given={Katrina},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e4c8c37e34209dd0f61d34723d9061fe}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b7585cb31b9235c4a758d152b7f7e828}{%
           family={Apps},
           familyi={A\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Nature Publishing Group}%
      }
      \strng{namehash}{832d19b6ecbaa1d465342fe676ffb29a}
      \strng{fullhash}{e20baf229e73fd131dd91cbcd821c571}
      \strng{bibnamehash}{783c2b117f393260e8cc5d9facb5ba78}
      \strng{authorbibnamehash}{783c2b117f393260e8cc5d9facb5ba78}
      \strng{authornamehash}{832d19b6ecbaa1d465342fe676ffb29a}
      \strng{authorfullhash}{e20baf229e73fd131dd91cbcd821c571}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{7782}
      \field{title}{Grandmaster Level in {{StarCraft II}} Using Multi-Agent Reinforcement Learning}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{575}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{350\bibrangedash 354}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1038/s41586-019-1724-z
      \endverb
      \keyw{Computer science,Statistics}
    \endentry
    \entry{wangDuelingNetworkArchitectures2016}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=05bc8d503a2c310ef0976ace7f9d2734}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ziyu},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f5a8983bab24d2cd5670100e485fc883}{%
           family={Hasselt},
           familyi={H\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0,
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=3075d0e02c0833f6e5fe1addb880898f}{%
           family={Lanctot},
           familyi={L\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cf269f9a5106a41ad53847a68a27db1c}{%
           family={Freitas},
           familyi={F\bibinitperiod},
           given={Nando},
           giveni={N\bibinitperiod},
           givenun=0,
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ce0f3d71b18ee7367558a7b6d6e6973e}
      \strng{fullhash}{df01a276e95745be4e3db8438093d454}
      \strng{bibnamehash}{df01a276e95745be4e3db8438093d454}
      \strng{authorbibnamehash}{df01a276e95745be4e3db8438093d454}
      \strng{authornamehash}{ce0f3d71b18ee7367558a7b6d6e6973e}
      \strng{authorfullhash}{df01a276e95745be4e3db8438093d454}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:1511.06581}
      \field{title}{Dueling {{Network Architectures}} for {{Deep Reinforcement Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1511.06581
      \endverb
      \verb{eprint}
      \verb 1511.06581
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/B4T6P73C/Wang et al. - 2016 - Dueling Network Architectures for Deep Reinforcement Learning.pdf;/home/james/Zotero/storage/BS84858L/1511.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{wengEnvPoolHighlyParallel2022}{misc}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=1d0662e5050b9cf02a15642557cd6293}{%
           family={Weng},
           familyi={W\bibinitperiod},
           given={Jiayi},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d2827b813d1d73df44360201e3296bea}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a485c9f2edbeda28fc6122a6d8ef9913}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Shengyi},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fa97927921a403cfe822973e31081dca}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=600fffd871568e2c04c8fc864359604a}{%
           family={Makoviichuk},
           familyi={M\bibinitperiod},
           given={Denys},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b2920c1e5c13f9f9448bc7ad484b44ed}{%
           family={Makoviychuk},
           familyi={M\bibinitperiod},
           given={Viktor},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d55e742fcb815ec7994f7201aef69793}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Zichen},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=57634a2e7d71f42baa66bf30827f40d4}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Yufan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=735d49a4934b3cf6dc24f676533207be}{%
           family={Luo},
           familyi={L\bibinitperiod},
           given={Ting},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e166a7e4574441f9b8d74c0e13a2cce4}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Yukun},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=faada09468b43ab0d3997004258e0520}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Zhongwen},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a7a92b64300d6c39c3ae492b9ded385}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Shuicheng},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{c645e86784b912941351d8cfcbe832fe}
      \strng{fullhash}{d73c7d873857e2362be84dad0d762e16}
      \strng{bibnamehash}{d73c7d873857e2362be84dad0d762e16}
      \strng{authorbibnamehash}{d73c7d873857e2362be84dad0d762e16}
      \strng{authornamehash}{c645e86784b912941351d8cfcbe832fe}
      \strng{authorfullhash}{d73c7d873857e2362be84dad0d762e16}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{There has been significant progress in developing reinforcement learning (RL) training systems. Past works such as IMPALA, Apex, Seed RL, Sample Factory, and others, aim to improve the system's overall throughput. In this paper, we aim to address a common bottleneck in the RL training system, i.e., parallel environment execution, which is often the slowest part of the whole system but receives little attention. With a curated design for paralleling RL environments, we have improved the RL environment simulation speed across different hardware setups, ranging from a laptop and a modest workstation, to a high-end machine such as NVIDIA DGX-A100. On a high-end machine, EnvPool achieves one million frames per second for the environment execution on Atari environments and three million frames per second on MuJoCo environments. When running EnvPool on a laptop, the speed is 2.8x that of the Python subprocess. Moreover, great compatibility with existing RL training libraries has been demonstrated in the open-sourced community, including CleanRL, rl\_games, DeepMind Acme, etc. Finally, EnvPool allows researchers to iterate their ideas at a much faster pace and has great potential to become the de facto RL environment execution engine. Example runs show that it only takes five minutes to train agents to play Atari Pong and MuJoCo Ant on a laptop. EnvPool is open-sourced at https://github.com/sail-sg/envpool.}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:2206.10558}
      \field{shorttitle}{{{EnvPool}}}
      \field{title}{{{EnvPool}}: {{A Highly Parallel Reinforcement Learning Environment Execution Engine}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2206.10558
      \endverb
      \verb{eprint}
      \verb 2206.10558
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/HH87KM5I/Weng et al. - 2022 - EnvPool A Highly Parallel Reinforcement Learning Environment Execution Engine.pdf;/home/james/Zotero/storage/4G6HQWQR/2206.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning,Computer Science - Performance,Computer Science - Robotics}
    \endentry
    \entry{yampolskiy2018artificial}{book}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=85237c83ab50955dc88666e2ba00959e}{%
           family={Yampolskiy},
           familyi={Y\bibinitperiod},
           given={R.V.},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {CRC Press/Taylor \& Francis Group}%
      }
      \strng{namehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{fullhash}{85237c83ab50955dc88666e2ba00959e}
      \strng{bibnamehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{authorbibnamehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{authornamehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{authorfullhash}{85237c83ab50955dc88666e2ba00959e}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-0-8153-6982-0}
      \field{series}{Chapman \& {{Hall}}/{{CRC}} Artificial Intelligence and Robotics Series}
      \field{title}{Artificial Intelligence Safety and Security}
      \field{year}{2018}
    \endentry
    \entry{yaratsMasteringVisualContinuous2021}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=c1a92bfddfd960be33e0dbc1cd54ddef}{%
           family={Yarats},
           familyi={Y\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6784304d1cc890b2cb6c6c7f2f3fd76}{%
           family={Fergus},
           familyi={F\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0edda5e676d227fa203a6350888089e}{%
           family={Lazaric},
           familyi={L\bibinitperiod},
           given={Alessandro},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d4b78f1220fe5cab8395d811fc9c5b2}{%
           family={Pinto},
           familyi={P\bibinitperiod},
           given={Lerrel},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1416ba9258e17e11da9204cd03a00a44}
      \strng{fullhash}{4db5ff40301013a0f7660d400685bdd9}
      \strng{bibnamehash}{4db5ff40301013a0f7660d400685bdd9}
      \strng{authorbibnamehash}{4db5ff40301013a0f7660d400685bdd9}
      \strng{authornamehash}{1416ba9258e17e11da9204cd03a00a44}
      \strng{authorfullhash}{4db5ff40301013a0f7660d400685bdd9}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for visual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic approach that uses data augmentation to learn directly from pixels. We introduce several improvements that yield state-of-the-art results on the DeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid locomotion tasks directly from pixel observations, previously unattained by model-free RL. DrQ-v2 is conceptually simple, easy to implement, and provides significantly better computational footprint compared to prior work, with the majority of tasks taking just 8 hours to train on a single GPU. Finally, we publicly release DrQ-v2's implementation to provide RL practitioners with a strong and computationally efficient baseline.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:2107.09645}
      \field{shorttitle}{Mastering {{Visual Continuous Control}}}
      \field{title}{Mastering {{Visual Continuous Control}}: {{Improved Data-Augmented Reinforcement Learning}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2107.09645
      \endverb
      \verb{eprint}
      \verb 2107.09645
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/WUJBSACI/Yarats et al. - 2021 - Mastering Visual Continuous Control Improved Data.pdf;/home/james/Zotero/storage/WXJX786X/2107.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{yeMasteringAtariGames2021}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=119346c0749953c9169a3e08144eb042}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Weirui},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f441c03dee89a6c9491367e808d1bdc2}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Shaohuai},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9b11af4841b4b3e436a27b0f140f45e3}{%
           family={Kurutach},
           familyi={K\bibinitperiod},
           given={Thanard},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9c1ecb1f7c47cf02e9e994296746328c}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{bceae5bd124d719847dd2c8c56b20904}
      \strng{fullhash}{3c47a809330452b7725bd5bb7935c771}
      \strng{bibnamehash}{3c47a809330452b7725bd5bb7935c771}
      \strng{authorbibnamehash}{3c47a809330452b7725bd5bb7935c771}
      \strng{authornamehash}{bceae5bd124d719847dd2c8c56b20904}
      \strng{authorfullhash}{3c47a809330452b7725bd5bb7935c771}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3\% mean human performance and 109.0\% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:2111.00210}
      \field{title}{Mastering {{Atari Games}} with {{Limited Data}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2111.00210
      \endverb
      \verb{eprint}
      \verb 2111.00210
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Ye et al_2021_Mastering Atari Games with Limited Data.pdf;/home/james/Zotero/storage/G2MEEKN4/2111.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{zhangColorfulImageColorization2016}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=0c65190dcbd461dee172354f7938ae43}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cae9f806bc99a5f19fadea538fc2db04}{%
           family={Isola},
           familyi={I\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5a663b27298722834a8cf09bb93d8c94}{%
           family={Efros},
           familyi={E\bibinitperiod},
           given={Alexei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a186c318a8836d77467280ce6646a302}
      \strng{fullhash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \strng{bibnamehash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \strng{authorbibnamehash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \strng{authornamehash}{a186c318a8836d77467280ce6646a302}
      \strng{authorfullhash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a "colorization Turing test," asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32\% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1603.08511}
      \field{title}{Colorful {{Image Colorization}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1603.08511
      \endverb
      \verb{eprint}
      \verb 1603.08511
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/UAKXPHDC/Zhang et al. - 2016 - Colorful Image Colorization.pdf;/home/james/Zotero/storage/7WRG6FX3/1603.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
  \enddatalist
  \datalist[entry]{apa/global//global/global}
    \entry{agarwalDeepReinforcementLearning2022}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=a3ce7bf5b3d6fcc96d09f5142950dd8d}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Rishabh},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd36c2abe3c5c9ea4b21e5258e5f3a37}{%
           family={Castro},
           familyi={C\bibinitperiod},
           given={Pablo\bibnamedelima Samuel},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b65e3dca892310aab631e0e18d6dcf30}
      \strng{fullhash}{eca631d7bf56942c4e599af3cdd85af6}
      \strng{bibnamehash}{eca631d7bf56942c4e599af3cdd85af6}
      \strng{authorbibnamehash}{eca631d7bf56942c4e599af3cdd85af6}
      \strng{authornamehash}{b65e3dca892310aab631e0e18d6dcf30}
      \strng{authorfullhash}{eca631d7bf56942c4e599af3cdd85af6}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep reinforcement learning (RL) algorithms are predominantly evaluated by comparing their relative performance on a large suite of tasks. Most published results on deep RL benchmarks compare point estimates of aggregate performance such as mean and median scores across tasks, ignoring the statistical uncertainty implied by the use of a finite number of training runs. Beginning with the Arcade Learning Environment (ALE), the shift towards computationally-demanding benchmarks has led to the practice of evaluating only a small number of runs per task, exacerbating the statistical uncertainty in point estimates. In this paper, we argue that reliable evaluation in the few run deep RL regime cannot ignore the uncertainty in results without running the risk of slowing down progress in the field. We illustrate this point using a case study on the Atari 100k benchmark, where we find substantial discrepancies between conclusions drawn from point estimates alone versus a more thorough statistical analysis. With the aim of increasing the field's confidence in reported results with a handful of runs, we advocate for reporting interval estimates of aggregate performance and propose performance profiles to account for the variability in results, as well as present more robust and efficient aggregate metrics, such as interquartile mean scores, to achieve small uncertainty in results. Using such statistical tools, we scrutinize performance evaluations of existing algorithms on other widely used RL benchmarks including the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies in prior comparisons. Our findings call for a change in how we evaluate performance in deep RL, for which we present a more rigorous evaluation methodology, accompanied with an open-source library rliable, to prevent unreliable results from stagnating the field.}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:2108.13264}
      \field{title}{Deep {{Reinforcement Learning}} at the {{Edge}} of the {{Statistical Precipice}}}
      \field{urlday}{28}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2108.13264
      \endverb
      \verb{eprint}
      \verb 2108.13264
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/XXICT83J/Agarwal et al. - 2022 - Deep Reinforcement Learning at the Edge of the Statistical Precipice.pdf;/home/james/Zotero/storage/ZT6G3NAW/2108.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology}
    \endentry
    \entry{aitchisonAtari5DistillingArcade2022}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=8539a0fc12c334a7cc7e81be93a5f273}{%
           family={Aitchison},
           familyi={A\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3d8ae89787e94a865d889d84d0324751}{%
           family={Sweetser},
           familyi={S\bibinitperiod},
           given={Penny},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=da595386b0c32905953fa716d906652a}{%
           family={Hutter},
           familyi={H\bibinitperiod},
           given={Marcus},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{502e938acf2fdc366dce81a8d0feb085}
      \strng{fullhash}{52a70e4533337ea187b59f4ea7f48d8b}
      \strng{bibnamehash}{52a70e4533337ea187b59f4ea7f48d8b}
      \strng{authorbibnamehash}{52a70e4533337ea187b59f4ea7f48d8b}
      \strng{authornamehash}{502e938acf2fdc366dce81a8d0feb085}
      \strng{authorfullhash}{52a70e4533337ea187b59f4ea7f48d8b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The Arcade Learning Environment (ALE) has become an essential benchmark for assessing the performance of reinforcement learning algorithms. However, the computational cost of generating results on the entire 57-game dataset limits ALE's use and makes the reproducibility of many results infeasible. We propose a novel solution to this problem in the form of a principled methodology for selecting small but representative subsets of environments within a benchmark suite. We applied our method to identify a subset of five ALE games, called Atari-5, which produces 57-game median score estimates within 10\% of their true values. Extending the subset to 10-games recovers 80\% of the variance for log-scores for all games within the 57-game set. We show this level of compression is possible due to a high degree of correlation between many of the games in ALE.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:2210.02019}
      \field{shorttitle}{Atari-5}
      \field{title}{Atari-5: {{Distilling}} the {{Arcade Learning Environment}} down to {{Five Games}}}
      \field{urlday}{17}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2210.02019
      \endverb
      \verb{eprint}
      \verb 2210.02019
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/3ZTJGMVB/Aitchison et al. - 2022 - Atari-5 Distilling the Arcade Learning Environmen.pdf;/home/james/Zotero/storage/R2847YWA/2210.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{bellemareDistributionalPerspectiveReinforcement2017}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5a44cbf0d05e4c50b512bb0c1368d2f}{%
           family={Dabney},
           familyi={D\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d8fa91764a27bf97b87fdcac885745d}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={RÃ©mi},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{fullhash}{388111794c9bc8299b60e3b15be023db}
      \strng{bibnamehash}{388111794c9bc8299b60e3b15be023db}
      \strng{authorbibnamehash}{388111794c9bc8299b60e3b15be023db}
      \strng{authornamehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{authorfullhash}{388111794c9bc8299b60e3b15be023db}
      \field{extraname}{1}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we argue for the fundamental importance of the value distribution: the distribution of the random return received by a reinforcement learning agent. This is in contrast to the common approach to reinforcement learning which models the expectation of this return, or value. Although there is an established body of literature studying the value distribution, thus far it has always been used for a specific purpose such as implementing risk-aware behaviour. We begin with theoretical results in both the policy evaluation and control settings, exposing a significant distributional instability in the latter. We then use the distributional perspective to design a new algorithm which applies Bellman's equation to the learning of approximate value distributions. We evaluate our algorithm using the suite of games from the Arcade Learning Environment. We obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning. Finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1707.06887}
      \field{title}{A {{Distributional Perspective}} on {{Reinforcement Learning}}}
      \field{urlday}{23}
      \field{urlmonth}{7}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 1707.06887
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Bellemare et al_2017_A Distributional Perspective on Reinforcement Learning.pdf;/home/james/Zotero/storage/GS93URP8/1707.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{bellemareArcadeLearningEnvironment2013}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07c80c48e7c42d8390ac0ad0513cbed3}{%
           family={Naddaf},
           familyi={N\bibinitperiod},
           given={Yavar},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1cbd91f7404b2298b46bb46c47c08251}{%
           family={Veness},
           familyi={V\bibinitperiod},
           given={Joel},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3318cb7968ff83b0f4b5a04d8f9ec318}{%
           family={Bowling},
           familyi={B\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{fullhash}{49395aa0bfa961c14ab74a906578e3ee}
      \strng{bibnamehash}{49395aa0bfa961c14ab74a906578e3ee}
      \strng{authorbibnamehash}{49395aa0bfa961c14ab74a906578e3ee}
      \strng{authornamehash}{6053df28940389b0a23ac429c3b0634d}
      \strng{authorfullhash}{49395aa0bfa961c14ab74a906578e3ee}
      \field{extraname}{2}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1207.4708}
      \field{shorttitle}{The {{Arcade Learning Environment}}}
      \field{title}{The {{Arcade Learning Environment}}: {{An Evaluation Platform}} for {{General Agents}}}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1207.4708
      \endverb
      \verb{eprint}
      \verb 1207.4708
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/LSTXSQPY/Bellemare et al. - 2013 - The Arcade Learning Environment An Evaluation Platform for General Agents.pdf;/home/james/Zotero/storage/ZUSAMYHY/1207.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence}
    \endentry
    \entry{jax2018github}{software}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=b75383e6b48c8360c7a60031424c85cf}{%
           family={Bradbury},
           familyi={B\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29563c986154ca2b45d286b4dd5ef92a}{%
           family={Frostig},
           familyi={F\bibinitperiod},
           given={Roy},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ab2d7e7f2bfceec36e42ad1962fde11}{%
           family={Hawkins},
           familyi={H\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e4d515e534ba184f553d5a2a926e0ea7}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Matthew\bibnamedelima James},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0101ae5b219809cf901e7645ca40b9ae}{%
           family={Leary},
           familyi={L\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07e607fb522f06610feb023ecfa712e2}{%
           family={Maclaurin},
           familyi={M\bibinitperiod},
           given={Dougal},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bca7d753be3217d63404d860acb6e5f5}{%
           family={Necula},
           familyi={N\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=56bf0b340039cf8594436a624ff548a9}{%
           family={Paszke},
           familyi={P\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0fd9a0e34f1b2adda41357c948d14986}{%
           family={Vander{P}las},
           familyi={V\bibinitperiod},
           given={Jake},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=02f809ed2547f721c304772c06378c2d}{%
           family={Wanderman-{M}ilne},
           familyi={W\bibinithyphendelim M\bibinitperiod},
           given={Skye},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fe167f78433aabd363ac3c06710a1945}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Qiao},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{be9c2f36b976223518e841214253df92}
      \strng{fullhash}{12f83c04441cfb40a3c9b086929c12bf}
      \strng{bibnamehash}{12f83c04441cfb40a3c9b086929c12bf}
      \strng{authorbibnamehash}{12f83c04441cfb40a3c9b086929c12bf}
      \strng{authornamehash}{be9c2f36b976223518e841214253df92}
      \strng{authorfullhash}{12f83c04441cfb40a3c9b086929c12bf}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{JAX}: composable transformations of {P}ython+{N}um{P}y programs}
      \field{version}{0.3.13}
      \field{year}{2018}
      \verb{urlraw}
      \verb http://github.com/jax-ml/jax
      \endverb
      \verb{url}
      \verb http://github.com/jax-ml/jax
      \endverb
    \endentry
    \entry{brohanRT1RoboticsTransformer2023}{misc}{}
      \name{author}{51}{}{%
        {{un=0,uniquepart=base,hash=f85d2cbec6e9b5ca55d3826bbe4368ad}{%
           family={Brohan},
           familyi={B\bibinitperiod},
           given={Anthony},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=08d6dd07d0aece35ec87bdf93614ef8d}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Noah},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b1f99e7aa4aa0467670b08b913dff35}{%
           family={Carbajal},
           familyi={C\bibinitperiod},
           given={Justice},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=76d42bc2454b74c74d031975757c3b6f}{%
           family={Chebotar},
           familyi={C\bibinitperiod},
           given={Yevgen},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b04d48b46cc6c9274a2d66fb08e5add}{%
           family={Dabis},
           familyi={D\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=058e82495825ae376c6a96a12169e6ee}{%
           family={Finn},
           familyi={F\bibinitperiod},
           given={Chelsea},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a3bf81921be7cabf0697b2b427515e43}{%
           family={Gopalakrishnan},
           familyi={G\bibinitperiod},
           given={Keerthana},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=db5fb91bc488e352c6b92899f58c54f2}{%
           family={Hausman},
           familyi={H\bibinitperiod},
           given={Karol},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b1f80957f6b826692a865bccfb5edb5d}{%
           family={Herzog},
           familyi={H\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c83e3ad829beca29ca183c74f742e020}{%
           family={Hsu},
           familyi={H\bibinitperiod},
           given={Jasmine},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03345358e737db6abfc1f5accfc48533}{%
           family={Ibarz},
           familyi={I\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a096e9107f0463212211c4510c6fa470}{%
           family={Ichter},
           familyi={I\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=94a1e4ffdb54841501b129d269ddba1e}{%
           family={Irpan},
           familyi={I\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=da2fb282fbfcefd85a65e276dccd059d}{%
           family={Jackson},
           familyi={J\bibinitperiod},
           given={Tomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dd87df9934b4226160b2585245b008af}{%
           family={Jesmonth},
           familyi={J\bibinitperiod},
           given={Sally},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c5b78e927d8f921c22fa839298a78f9e}{%
           family={Joshi},
           familyi={J\bibinitperiod},
           given={Nikhil\bibnamedelima J.},
           giveni={N\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b04ec5aef0791c6a41951756f2a0bb3}{%
           family={Julian},
           familyi={J\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dd32ba2d0643a1dfa9dba39af24e2948}{%
           family={Kalashnikov},
           familyi={K\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=766c07beb0725c8ea271df0742be4f83}{%
           family={Kuang},
           familyi={K\bibinitperiod},
           given={Yuheng},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=325829a0eb81f78538ba18de089faa1f}{%
           family={Leal},
           familyi={L\bibinitperiod},
           given={Isabel},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=756814c491139f3349afefe329960ae5}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kuang-Huei},
           giveni={K\bibinithyphendelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=412e1388b73ef19ade8c52ca3431f84c}{%
           family={Lu},
           familyi={L\bibinitperiod},
           given={Yao},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b06397d32f3c4c98e3e4516f8c475ec}{%
           family={Malla},
           familyi={M\bibinitperiod},
           given={Utsav},
           giveni={U\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a68c078d5efd7a18a2906cf09ddd657f}{%
           family={Manjunath},
           familyi={M\bibinitperiod},
           given={Deeksha},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7570e7c3fc2c13d59af4d7cdb9962a4d}{%
           family={Mordatch},
           familyi={M\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3fdbcb94c087d48425327cdfdb5f0827}{%
           family={Nachum},
           familyi={N\bibinitperiod},
           given={Ofir},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7fe2d48ce31c87a150449138bad607f0}{%
           family={Parada},
           familyi={P\bibinitperiod},
           given={Carolina},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2806c0f17dcce991b3e76cc59326f68a}{%
           family={Peralta},
           familyi={P\bibinitperiod},
           given={Jodilyn},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=39824e4aa78149965c2ae5976b4d40fd}{%
           family={Perez},
           familyi={P\bibinitperiod},
           given={Emily},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a31ce25b53500260a67ce7b91c821b6b}{%
           family={Pertsch},
           familyi={P\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33846ea5683179601fc64f8154f39fd5}{%
           family={Quiambao},
           familyi={Q\bibinitperiod},
           given={Jornell},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0bc76ae3489ed701bf62b815b7166ed7}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Kanishka},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3daa95be0b155cfe142bea7643fe022}{%
           family={Ryoo},
           familyi={R\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f1096086ce15f12da081de0f372ff987}{%
           family={Salazar},
           familyi={S\bibinitperiod},
           given={Grecia},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2958a61013cbb0c4eed93a63ad313fa9}{%
           family={Sanketi},
           familyi={S\bibinitperiod},
           given={Pannag},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=451b2df9920d95ad346012159883cfa2}{%
           family={Sayed},
           familyi={S\bibinitperiod},
           given={Kevin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b616dabbd3c472fdb55908119deaf408}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Jaspiar},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03de3c0b4a08fe619740d5bf11f9653e}{%
           family={Sontakke},
           familyi={S\bibinitperiod},
           given={Sumedh},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a3dfa1303288ee802e8bf3ce3abf08a}{%
           family={Stone},
           familyi={S\bibinitperiod},
           given={Austin},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=193380c4c8991077c66dd34b45776e45}{%
           family={Tan},
           familyi={T\bibinitperiod},
           given={Clayton},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=faf79b09b112cd2025ac4b03430780a3}{%
           family={Tran},
           familyi={T\bibinitperiod},
           given={Huong},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8051922e7bd286f884bfbd1023ef62f5}{%
           family={Vanhoucke},
           familyi={V\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=030bf812b3b741bdc09e070d6cbb86e2}{%
           family={Vega},
           familyi={V\bibinitperiod},
           given={Steve},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=644737d9c237bfc5db1369d2ca8f7688}{%
           family={Vuong},
           familyi={V\bibinitperiod},
           given={Quan},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=61e00ed0c44b8bddb9077a74a4ac1167}{%
           family={Xia},
           familyi={X\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=983a85de139e78f8c8e34fa633f08b8c}{%
           family={Xiao},
           familyi={X\bibinitperiod},
           given={Ted},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a9f1e89449a8f9e0a4b65ee24d8f421d}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3c4e72762406de2fb44caf54e7478103}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Sichun},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9deda9161d91175c5ce4efe814e405c7}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Tianhe},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=019a17d953e12f46a852d1314441652e}{%
           family={Zitkovich},
           familyi={Z\bibinitperiod},
           given={Brianna},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{c5d07d4a8918ca9ac03995189e27ade5}
      \strng{fullhash}{f78ae9babdcf9c1a81b98c9ea10ccba5}
      \strng{bibnamehash}{7e821cc9ab174b709c334e7c268601d8}
      \strng{authorbibnamehash}{7e821cc9ab174b709c334e7c268601d8}
      \strng{authornamehash}{c5d07d4a8918ca9ac03995189e27ade5}
      \strng{authorfullhash}{f78ae9babdcf9c1a81b98c9ea10ccba5}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{arXiv:2212.06817}
      \field{shorttitle}{{{RT-1}}}
      \field{title}{{{RT-1}}: {{Robotics Transformer}} for {{Real-World Control}} at {{Scale}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2212.06817
      \endverb
      \verb{eprint}
      \verb 2212.06817
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/PS6RZ8ZS/Brohan et al. - 2023 - RT-1 Robotics Transformer for Real-World Control at Scale.pdf
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{byravanImaginedValueGradients2019}{misc}{}
      \name{author}{9}{}{%
        {{un=0,uniquepart=base,hash=92babce6d69105729d815e93c1bdb54c}{%
           family={Byravan},
           familyi={B\bibinitperiod},
           given={Arunkumar},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d52162d1c5497f647e12128f74d58da4}{%
           family={Springenberg},
           familyi={S\bibinitperiod},
           given={Jost\bibnamedelima Tobias},
           giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=528d31a6b5c1231e01391e2597dd5491}{%
           family={Abdolmaleki},
           familyi={A\bibinitperiod},
           given={Abbas},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fc9873fa16235237944ddb12fc2db97d}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Roland},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=060d57062477e5aa7705774f29f438a2}{%
           family={Neunert},
           familyi={N\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=88b7db69f42e22293022f02f63af62cf}{%
           family={Lampe},
           familyi={L\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4b2968a035ed438b3b9d4f7e3dcb3bff}{%
           family={Siegel},
           familyi={S\bibinitperiod},
           given={Noah},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=231312991eab5915498d6c19c2a8cd4e}{%
           family={Heess},
           familyi={H\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{cf7be3452ad5edfe721b7f3f2f15ae66}
      \strng{fullhash}{967a8b62fadf406697f4d635cca3b7f3}
      \strng{bibnamehash}{967a8b62fadf406697f4d635cca3b7f3}
      \strng{authorbibnamehash}{967a8b62fadf406697f4d635cca3b7f3}
      \strng{authornamehash}{cf7be3452ad5edfe721b7f3f2f15ae66}
      \strng{authorfullhash}{967a8b62fadf406697f4d635cca3b7f3}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Humans are masters at quickly learning many complex tasks, relying on an approximate understanding of the dynamics of their environments. In much the same way, we would like our learning agents to quickly adapt to new tasks. In this paper, we explore how model-based Reinforcement Learning (RL) can facilitate transfer to new tasks. We develop an algorithm that learns an action-conditional, predictive model of expected future observations, rewards and values from which a policy can be derived by following the gradient of the estimated value along imagined trajectories. We show how robust policy optimization can be achieved in robot manipulation tasks even with approximate models that are learned directly from vision and proprioception. We evaluate the efficacy of our approach in a transfer learning scenario, re-using previously learned models on tasks with different reward structures and visual distractors, and show a significant improvement in learning speed compared to strong off-policy baselines. Videos with results can be found at https://sites.google.com/view/ivg-corl19}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1910.04142}
      \field{shorttitle}{Imagined {{Value Gradients}}}
      \field{title}{Imagined {{Value Gradients}}: {{Model-Based Policy Optimization}} with {{Transferable Latent Dynamics Models}}}
      \field{urlday}{26}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1910.04142
      \endverb
      \verb{eprint}
      \verb 1910.04142
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/F8894SKH/Byravan et al. - 2019 - Imagined Value Gradients Model-Based Policy Optimization with Transferable Latent Dynamics Models.pdf;/home/james/Zotero/storage/EIPU6XZ9/1910.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics}
    \endentry
    \entry{castro18dopamine}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=cd36c2abe3c5c9ea4b21e5258e5f3a37}{%
           family={Castro},
           familyi={C\bibinitperiod},
           given={Pablo\bibnamedelima Samuel},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef2e4463869382eb399d48b9f47403ab}{%
           family={Moitra},
           familyi={M\bibinitperiod},
           given={Subhodeep},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=592464775b22487321b185921f1faeb2}{%
           family={Gelada},
           familyi={G\bibinitperiod},
           given={Carles},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3ac9e7dae03c093a86970853c449196}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Saurabh},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ff971ecddde7a07f22ce8cf2802bfd41}
      \strng{fullhash}{57bac6fc4d83645cb17e6ca14f921295}
      \strng{bibnamehash}{57bac6fc4d83645cb17e6ca14f921295}
      \strng{authorbibnamehash}{57bac6fc4d83645cb17e6ca14f921295}
      \strng{authornamehash}{ff971ecddde7a07f22ce8cf2802bfd41}
      \strng{authorfullhash}{57bac6fc4d83645cb17e6ca14f921295}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{title}{Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning}
      \field{year}{2018}
      \verb{urlraw}
      \verb http://arxiv.org/abs/1812.06110
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1812.06110
      \endverb
    \endentry
    \entry{chenExploringSimpleSiamese2020}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=ce10870c303bf2f78994acd2df305b39}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Xinlei},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{fullhash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{bibnamehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{authorbibnamehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{authornamehash}{61962cb16a5a83c9961a624ef2c87fb9}
      \strng{authorfullhash}{61962cb16a5a83c9961a624ef2c87fb9}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Siamese networks have become a common structure in various recent models for unsupervised visual representation learning. These models maximize the similarity between two augmentations of one image, subject to certain conditions for avoiding collapsing solutions. In this paper, we report surprising empirical results that simple Siamese networks can learn meaningful representations even using none of the following: (i) negative sample pairs, (ii) large batches, (iii) momentum encoders. Our experiments show that collapsing solutions do exist for the loss and structure, but a stop-gradient operation plays an essential role in preventing collapsing. We provide a hypothesis on the implication of stop-gradient, and further show proof-of-concept experiments verifying it. Our "SimSiam" method achieves competitive results on ImageNet and downstream tasks. We hope this simple baseline will motivate people to rethink the roles of Siamese architectures for unsupervised representation learning. Code will be made available.}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2011.10566}
      \field{title}{Exploring {{Simple Siamese Representation Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2011.10566
      \endverb
      \verb{eprint}
      \verb 2011.10566
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/9FVXCAVE/Chen and He - 2020 - Exploring Simple Siamese Representation Learning.pdf;/home/james/Zotero/storage/5PPK88RE/2011.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{chopraLearningSimilarityMetric2005}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=5eb35fffcf75e0932c31b19f424238fe}{%
           family={Chopra},
           familyi={C\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ae95119be0d9d86ffdec9f3142af353e}{%
           family={Hadsell},
           familyi={H\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9ae8dc3a930d73e11e1b22a9ef065055}{%
           family={LeCun},
           familyi={L\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b449f514f35191985ab69f9a22beec46}
      \strng{fullhash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \strng{bibnamehash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \strng{authorbibnamehash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \strng{authornamehash}{b449f514f35191985ab69f9a22beec46}
      \strng{authorfullhash}{2ae0f8c523dc089c2a9603bade8daeb5}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the "semantic" distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves.}
      \field{issn}{1063-6919}
      \field{journaltitle}{2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)}
      \field{month}{6}
      \field{title}{Learning a Similarity Metric Discriminatively, with Application to Face Verification}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{1}
      \field{year}{2005}
      \field{urldateera}{ce}
      \field{pages}{539\bibrangedash 546 vol. 1}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1109/CVPR.2005.202
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/IUFWXFXS/1467314.html
      \endverb
      \keyw{Artificial neural networks,Character generation,Drives,Face recognition,Glass,Robustness,Spatial databases,Support vector machine classification,Support vector machines,System testing}
    \endentry
    \entry{chuaDeepReinforcementLearning2018}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=5a627648d87fbb1650833684cd5d6fa9}{%
           family={Chua},
           familyi={C\bibinitperiod},
           given={Kurtland},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=864584c60b808b517f2a06c664ec116a}{%
           family={Calandra},
           familyi={C\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b4f598eab77331a1e5a5f3c9ce3ed17d}{%
           family={McAllister},
           familyi={M\bibinitperiod},
           given={Rowan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{f1e092bd96dfea65399b02a0fd64242a}
      \strng{fullhash}{56a8bebfe5f201534436e41113469d43}
      \strng{bibnamehash}{56a8bebfe5f201534436e41113469d43}
      \strng{authorbibnamehash}{56a8bebfe5f201534436e41113469d43}
      \strng{authornamehash}{f1e092bd96dfea65399b02a0fd64242a}
      \strng{authorfullhash}{56a8bebfe5f201534436e41113469d43}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:1805.12114}
      \field{title}{Deep {{Reinforcement Learning}} in a {{Handful}} of {{Trials}} Using {{Probabilistic Dynamics Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1805.12114
      \endverb
      \verb{eprint}
      \verb 1805.12114
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Chua et al_2018_Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics.pdf;/home/james/Zotero/storage/G256PNY5/1805.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{deboerTutorialCrossEntropyMethod2005}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=543cc24c01bba57efb3df90f45ed0292}{%
           family={{de Boer}},
           familyi={d\bibinitperiod},
           given={Pieter-Tjerk},
           giveni={P\bibinithyphendelim T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bdeae732a8a2bf629098c06d021dceb5}{%
           family={Kroese},
           familyi={K\bibinitperiod},
           given={Dirk\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cb41e7e037f839138136e53088340de0}{%
           family={Mannor},
           familyi={M\bibinitperiod},
           given={Shie},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74bcd83ba931505aa6a17e6d83add62d}{%
           family={Rubinstein},
           familyi={R\bibinitperiod},
           given={Reuven\bibnamedelima Y.},
           giveni={R\bibinitperiod\bibinitdelim Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b24a48d8f9f915d4abfaae4e4d43fdf8}
      \strng{fullhash}{18c1837b8e3ea7181baf4054fc0958a0}
      \strng{bibnamehash}{18c1837b8e3ea7181baf4054fc0958a0}
      \strng{authorbibnamehash}{18c1837b8e3ea7181baf4054fc0958a0}
      \strng{authornamehash}{b24a48d8f9f915d4abfaae4e4d43fdf8}
      \strng{authorfullhash}{18c1837b8e3ea7181baf4054fc0958a0}
      \field{sortinit}{d}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The cross-entropy (CE) method is a new generic approach to combinatorial and multi-extremal optimization and rare event simulation. The purpose of this tutorial is to give a gentle introduction to the CE method. We present the CE methodology, the basic algorithm and its modifications, and discuss applications in combinatorial optimization and machine learning.}
      \field{issn}{1572-9338}
      \field{journaltitle}{Annals of Operations Research}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{1}
      \field{title}{A {{Tutorial}} on the {{Cross-Entropy Method}}}
      \field{urlday}{28}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{134}
      \field{year}{2005}
      \field{urldateera}{ce}
      \field{pages}{19\bibrangedash 67}
      \range{pages}{49}
      \verb{doi}
      \verb 10.1007/s10479-005-5724-z
      \endverb
      \keyw{cross-entropy method,machine learning,Monte-Carlo simulation,randomized optimization,rare events}
    \endentry
    \entry{devlinBERTPretrainingDeep2019}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=13202969e372bc82318f9629cbdd199b}{%
           family={Devlin},
           familyi={D\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a45784fe7163b45f11d166564f5d24b6}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Ming-Wei},
           giveni={M\bibinithyphendelim W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8dde73b4194f5bc4230c4808f3fc1534}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kenton},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b92aa283415413bb8d2a1548716d0c7d}{%
           family={Toutanova},
           familyi={T\bibinitperiod},
           given={Kristina},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ad8e2e2a80d28ade21e86852b804fc9b}
      \strng{fullhash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{bibnamehash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authorbibnamehash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \strng{authornamehash}{ad8e2e2a80d28ade21e86852b804fc9b}
      \strng{authorfullhash}{e8bccd48302a14eeba57d9dce2f49ef4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:1810.04805}
      \field{shorttitle}{{{BERT}}}
      \field{title}{{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1810.04805
      \endverb
      \verb{eprint}
      \verb 1810.04805
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Devlin et al_2019_BERT.pdf;/home/james/Zotero/storage/EGGQPIYZ/1810.html
      \endverb
      \keyw{Computer Science - Computation and Language,LMs,Transformers}
    \endentry
    \entry{dorkaDynamicUpdatetoDataRatio2023}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=5a7a8c9907b9dc822d54ed243ca623b7}{%
           family={Dorka},
           familyi={D\bibinitperiod},
           given={Nicolai},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3861b5daf60d03468cc6b9c900fbeb0b}{%
           family={Welschehold},
           familyi={W\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98f4ab1bc2ac191d8f8a0651315ce9c0}{%
           family={Burgard},
           familyi={B\bibinitperiod},
           given={Wolfram},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ec4dc6b46663e18265ce610d3ef30049}
      \strng{fullhash}{10553f199504d62f0f104c83d2bf14f4}
      \strng{bibnamehash}{10553f199504d62f0f104c83d2bf14f4}
      \strng{authorbibnamehash}{10553f199504d62f0f104c83d2bf14f4}
      \strng{authornamehash}{ec4dc6b46663e18265ce610d3ef30049}
      \strng{authorfullhash}{10553f199504d62f0f104c83d2bf14f4}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Early stopping based on the validation set performance is a popular approach to find the right balance between under- and overfitting in the context of supervised learning. However, in reinforcement learning, even for supervised sub-problems such as world model learning, early stopping is not applicable as the dataset is continually evolving. As a solution, we propose a new general method that dynamically adjusts the update to data (UTD) ratio during training based on under- and overfitting detection on a small subset of the continuously collected experience not used for training. We apply our method to DreamerV2, a state-of-the-art model-based reinforcement learning algorithm, and evaluate it on the DeepMind Control Suite and the Atari \$100\$k benchmark. The results demonstrate that one can better balance under- and overestimation by adjusting the UTD ratio with our approach compared to the default setting in DreamerV2 and that it is competitive with an extensive hyperparameter search which is not feasible for many applications. Our method eliminates the need to set the UTD hyperparameter by hand and even leads to a higher robustness with regard to other learning-related hyperparameters further reducing the amount of necessary tuning.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2303.10144}
      \field{shorttitle}{Dynamic {{Update-to-Data Ratio}}}
      \field{title}{Dynamic {{Update-to-Data Ratio}}: {{Minimizing World Model Overfitting}}}
      \field{urlday}{28}
      \field{urlmonth}{10}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2303.10144
      \endverb
      \verb{eprint}
      \verb 2303.10144
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/QYEQFJ65/Dorka et al. - 2023 - Dynamic Update-to-Data Ratio Minimizing World Model Overfitting.pdf;/home/james/Zotero/storage/W3H9549Z/2303.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{doroSampleEfficientReinforcementLearning2022}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=e09d377eb804fa206349bcc1d7162ddf}{%
           family={D'Oro},
           familyi={D\bibinitperiod},
           given={Pierluca},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d078365da0923eced35cd9345318ca0}{%
           family={Nikishin},
           familyi={N\bibinitperiod},
           given={Evgenii},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9417eec56d7db4d07719bbb7fe3bcdd}{%
           family={Bacon},
           familyi={B\bibinitperiod},
           given={Pierre-Luc},
           giveni={P\bibinithyphendelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ce2ba9e0396ea93595cefce10a25f9d1}
      \strng{fullhash}{9acc5d19062a330a79f7b970244a0ad9}
      \strng{bibnamehash}{9acc5d19062a330a79f7b970244a0ad9}
      \strng{authorbibnamehash}{9acc5d19062a330a79f7b970244a0ad9}
      \strng{authornamehash}{ce2ba9e0396ea93595cefce10a25f9d1}
      \strng{authorfullhash}{9acc5d19062a330a79f7b970244a0ad9}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Increasing the replay ratio, the number of updates of an agent's parameters per environment interaction, is an appealing strategy for improving the sample efficiency of deep reinforcement learning algorithms. In this work, we show that fully or partially resetting the parameters of deep reinforcement learning agents causes better replay ratio scaling capabilities to emerge. We push the limits of the sample efficiency of carefully-modified algorithms by training them using an order of magnitude more updates than usual, significantly improving their performance in the Atari 100k and DeepMind Control Suite benchmarks. We then provide an analysis of the design choices required for favorable replay ratio scaling to be possible and discuss inherent limits and tradeoffs.}
      \field{journaltitle}{The {{Eleventh International Conference}} on {{Learning Representations}}}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Sample-{{Efficient Reinforcement Learning}} by {{Breaking}} the {{Replay Ratio Barrier}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/56KZMTMH/D'Oro et al. - 2022 - Sample-Efficient Reinforcement Learning by Breakin.pdf
      \endverb
    \endentry
    \entry{farquharTreeQNATreeCDifferentiable2018}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=de7fc27bb6e6105440cd3039a5c9b684}{%
           family={Farquhar},
           familyi={F\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b3ff4029884ead9928954ea33714192c}{%
           family={RocktÃ¤schel},
           familyi={R\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a16299a48b44fa1c82d5c13151401004}{%
           family={Igl},
           familyi={I\bibinitperiod},
           given={Maximilian},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d05819cf2b4fe22ba972c9b2b5d8c9d}{%
           family={Whiteson},
           familyi={W\bibinitperiod},
           given={Shimon},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a674e854056b940bb7a84a7b613b17a0}
      \strng{fullhash}{d82f83d049512ecb33743027292cf97a}
      \strng{bibnamehash}{d82f83d049512ecb33743027292cf97a}
      \strng{authorbibnamehash}{d82f83d049512ecb33743027292cf97a}
      \strng{authornamehash}{a674e854056b940bb7a84a7b613b17a0}
      \strng{authorfullhash}{d82f83d049512ecb33743027292cf97a}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Combining deep model-free reinforcement learning with on-line planning is a promising approach to building on the successes of deep RL. On-line planning with look-ahead trees has proven successful in environments where transition models are known a priori. However, in complex environments where transition models need to be learned from data, the deficiencies of learned models have limited their utility for planning. To address these challenges, we propose TreeQN, a differentiable, recursive, tree-structured model that serves as a drop-in replacement for any value function network in deep RL with discrete actions. TreeQN dynamically constructs a tree by recursively applying a transition model in a learned abstract state space and then aggregating predicted rewards and state-values using a tree backup to estimate Q-values. We also propose ATreeC, an actor-critic variant that augments TreeQN with a softmax layer to form a stochastic policy network. Both approaches are trained end-to-end, such that the learned model is optimised for its actual use in the tree. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a box-pushing task, as well as n-step DQN and value prediction networks (Oh et al. 2017) on multiple Atari games. Furthermore, we present ablation studies that demonstrate the effect of different auxiliary losses on learning transition models.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1710.11417}
      \field{shorttitle}{{{TreeQN}} and {{ATreeC}}}
      \field{title}{{{TreeQN}} and {{ATreeC}}: {{Differentiable Tree-Structured Models}} for {{Deep Reinforcement Learning}}}
      \field{urlday}{2}
      \field{urlmonth}{4}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1710.11417
      \endverb
      \verb{eprint}
      \verb 1710.11417
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Farquhar et al_2018_TreeQN and ATreeC.pdf;/home/james/Zotero/storage/4JU2SQAH/1710.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning}
    \endentry
    \entry{fortunatoNoisyNetworksExploration2019}{misc}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=dfc7f8069848dbc66435c3acc3172871}{%
           family={Fortunato},
           familyi={F\bibinitperiod},
           given={Meire},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c08c463bfe294c33c09d1f2c5a3b1e24}{%
           family={Azar},
           familyi={A\bibinitperiod},
           given={Mohammad\bibnamedelima Gheshlaghi},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f31963abd2aa43dd3aafc40aa1252a05}{%
           family={Piot},
           familyi={P\bibinitperiod},
           given={Bilal},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d3255f46b9e59e322e3fba6ce3daa11}{%
           family={Menick},
           familyi={M\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d78832306745d08c2a95154ee3e0a1b7}{%
           family={Osband},
           familyi={O\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fef11d6229576d005bc4434cdcf7091e}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Vlad},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ce2c8d8bf1e96e9845a930fb6264204f}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={Remi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fa8a4817aef70fffae62a48b98481ef7}{%
           family={Pietquin},
           familyi={P\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24fe1af011227491e54e299ba4cb24b5}{%
           family={Blundell},
           familyi={B\bibinitperiod},
           given={Charles},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=afdf5ed50a24cdca0f42433e4f4848d5}{%
           family={Legg},
           familyi={L\bibinitperiod},
           given={Shane},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8d92fb6b77c2a76599fe0b1aeffffa08}
      \strng{fullhash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \strng{bibnamehash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \strng{authorbibnamehash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \strng{authornamehash}{8d92fb6b77c2a76599fe0b1aeffffa08}
      \strng{authorfullhash}{a97f6c4a50ec5f02b6fed7e12b05eb60}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce NoisyNet, a deep reinforcement learning agent with parametric noise added to its weights, and show that the induced stochasticity of the agent's policy can be used to aid efficient exploration. The parameters of the noise are learned with gradient descent along with the remaining network weights. NoisyNet is straightforward to implement and adds little computational overhead. We find that replacing the conventional exploration heuristics for A3C, DQN and dueling agents (entropy reward and \${\textbackslash}epsilon\$-greedy respectively) with NoisyNet yields substantially higher scores for a wide range of Atari games, in some cases advancing the agent from sub to super-human performance.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1706.10295}
      \field{title}{Noisy {{Networks}} for {{Exploration}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1706.10295
      \endverb
      \verb{eprint}
      \verb 1706.10295
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/QK3I2G27/Fortunato et al. - 2019 - Noisy Networks for Exploration.pdf;/home/james/Zotero/storage/VYV9II9Y/1706.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{francois-lavetHowDiscountDeep2016}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=ef083153331d849d68dca175e0afd86d}{%
           family={{FranÃ§ois-Lavet}},
           familyi={F\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3c261c6c8f7ce19f21763516b0af342}{%
           family={Fonteneau},
           familyi={F\bibinitperiod},
           given={Raphael},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6fbe33fd3b6a25f54629f311cb113551}{%
           family={Ernst},
           familyi={E\bibinitperiod},
           given={Damien},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a60ab02792ecd3844cbf1a41d97ebc40}
      \strng{fullhash}{4728e62162f069458d32b659d9c2ec07}
      \strng{bibnamehash}{4728e62162f069458d32b659d9c2ec07}
      \strng{authorbibnamehash}{4728e62162f069458d32b659d9c2ec07}
      \strng{authornamehash}{a60ab02792ecd3844cbf1a41d97ebc40}
      \strng{authorfullhash}{4728e62162f069458d32b659d9c2ec07}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Using deep neural nets as function approximator for reinforcement learning tasks have recently been shown to be very powerful for solving problems approaching real-world complexity. Using these results as a benchmark, we discuss the role that the discount factor may play in the quality of the learning process of a deep Q-network (DQN). When the discount factor progressively increases up to its final value, we empirically show that it is possible to significantly reduce the number of learning steps. When used in conjunction with a varying learning rate, we empirically show that it outperforms original DQN on several experiments. We relate this phenomenon with the instabilities of neural networks when they are used in an approximate Dynamic Programming setting. We also describe the possibility to fall within a local optimum during the learning process, thus connecting our discussion with the exploration/exploitation dilemma.}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:1512.02011}
      \field{shorttitle}{How to {{Discount Deep Reinforcement Learning}}}
      \field{title}{How to {{Discount Deep Reinforcement Learning}}: {{Towards New Dynamic Strategies}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1512.02011
      \endverb
      \verb{eprint}
      \verb 1512.02011
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/TWXWRW7G/FranÃ§ois-Lavet et al. - 2016 - How to Discount Deep Reinforcement Learning Towards New Dynamic Strategies.pdf;/home/james/Zotero/storage/QP5YHIDA/1512.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{gidarisUnsupervisedRepresentationLearning2018}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=46e96c4d02697413846440921900e9ce}{%
           family={Gidaris},
           familyi={G\bibinitperiod},
           given={Spyros},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f12bafa3883b5e94ed5bbcab458128c4}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Praveer},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b19df6325edc9e76749ac30a9d962c7}{%
           family={Komodakis},
           familyi={K\bibinitperiod},
           given={Nikos},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{91463ca4ff04b91c7362bf8123b8141a}
      \strng{fullhash}{6803481e0cd09c5bddcfc136edc99d2b}
      \strng{bibnamehash}{6803481e0cd09c5bddcfc136edc99d2b}
      \strng{authorbibnamehash}{6803481e0cd09c5bddcfc136edc99d2b}
      \strng{authornamehash}{91463ca4ff04b91c7362bf8123b8141a}
      \strng{authorfullhash}{6803481e0cd09c5bddcfc136edc99d2b}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4\% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: https://github.com/gidariss/FeatureLearningRotNet .}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1803.07728}
      \field{title}{Unsupervised {{Representation Learning}} by {{Predicting Image Rotations}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1803.07728
      \endverb
      \verb{eprint}
      \verb 1803.07728
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/J5T2P75U/Gidaris et al. - 2018 - Unsupervised Representation Learning by Predicting Image Rotations.pdf;/home/james/Zotero/storage/M5YVEZ3L/1803.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{grillBootstrapYourOwn2020}{misc}{}
      \name{author}{14}{}{%
        {{un=0,uniquepart=base,hash=152351efb2aa1ec8470b935d63d68a21}{%
           family={Grill},
           familyi={G\bibinitperiod},
           given={Jean-Bastien},
           giveni={J\bibinithyphendelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3af936a4e6dd4b0086458a45dfac6da}{%
           family={Strub},
           familyi={S\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba254bce2809834e8b51cd526e20c1c2}{%
           family={AltchÃ©},
           familyi={A\bibinitperiod},
           given={Florent},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=53e127de75e9241aa5b25e378a90fea1}{%
           family={Tallec},
           familyi={T\bibinitperiod},
           given={Corentin},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bb66a15fe0e5fcdb7d3ba216e5cf9974}{%
           family={Richemond},
           familyi={R\bibinitperiod},
           given={Pierre\bibnamedelima H.},
           giveni={P\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eee8c4b85d5c4e1f4bc70218d34ba69d}{%
           family={Buchatskaya},
           familyi={B\bibinitperiod},
           given={Elena},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=96b67cea31d7dd5c10af974faba91947}{%
           family={Doersch},
           familyi={D\bibinitperiod},
           given={Carl},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8ff346cbfa06024a8dd0afe01bd765a}{%
           family={Pires},
           familyi={P\bibinitperiod},
           given={Bernardo\bibnamedelima Avila},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=610da8bda1894dde64553a72f1a275ea}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Zhaohan\bibnamedelima Daniel},
           giveni={Z\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c08c463bfe294c33c09d1f2c5a3b1e24}{%
           family={Azar},
           familyi={A\bibinitperiod},
           given={Mohammad\bibnamedelima Gheshlaghi},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f31963abd2aa43dd3aafc40aa1252a05}{%
           family={Piot},
           familyi={P\bibinitperiod},
           given={Bilal},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d8fa91764a27bf97b87fdcac885745d}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={RÃ©mi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e25b9b55e0d33d8e554fb428b0122ba9}{%
           family={Valko},
           familyi={V\bibinitperiod},
           given={Michal},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{37900d0162e64eae8ddfb8300b650795}
      \strng{fullhash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \strng{bibnamehash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \strng{authorbibnamehash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \strng{authornamehash}{37900d0162e64eae8ddfb8300b650795}
      \strng{authorfullhash}{7c7006f0e81e1263f8c3ecc0ec1766a9}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches \$74.3{\textbackslash}\%\$ top-1 classification accuracy on ImageNet using a linear evaluation with a ResNet-50 architecture and \$79.6{\textbackslash}\%\$ with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks. Our implementation and pretrained models are given on GitHub.}
      \field{eprinttype}{arXiv}
      \field{month}{9}
      \field{number}{arXiv:2006.07733}
      \field{shorttitle}{Bootstrap Your Own Latent}
      \field{title}{Bootstrap Your Own Latent: {{A}} New Approach to Self-Supervised {{Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2006.07733
      \endverb
      \verb{eprint}
      \verb 2006.07733
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/BR83I5BP/Grill et al. - 2020 - Bootstrap your own latent A new approach to self-supervised Learning.pdf;/home/james/Zotero/storage/EF8GD23Y/2006.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{haRecurrentWorldModels2018}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=4467056eb9d0a44c1ec21bbb4d6152c5}{%
           family={Ha},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=288bdbcfe1b91ad7484d7a24f74f99ed}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={JÃ¼rgen},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{fullhash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{bibnamehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{authorbibnamehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{authornamehash}{ac33097a207e3840f68fa6e4bd34710c}
      \strng{authorfullhash}{ac33097a207e3840f68fa6e4bd34710c}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A generative recurrent neural network is quickly trained in an unsupervised manner to model popular reinforcement learning environments through compressed spatio-temporal representations. The world model's extracted features are fed into compact and simple policies trained by evolution, achieving state of the art results in various environments. We also train our agent entirely inside of an environment generated by its own internal world model, and transfer this policy back into the actual environment. Interactive version of this paper is available at https://worldmodels.github.io}
      \field{journaltitle}{Advances in {{Neural Information Processing Systems}}}
      \field{title}{Recurrent {{World Models Facilitate Policy Evolution}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{31}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/9YXWGU7I/Ha and Schmidhuber - 2018 - Recurrent World Models Facilitate Policy Evolution.pdf
      \endverb
    \endentry
    \entry{haarnojaSoftActorCriticOffPolicy2018}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=45b14f55dd7ae28cb6cb2e23e4a168b9}{%
           family={Haarnoja},
           familyi={H\bibinitperiod},
           given={Tuomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=519033a7338e5ef684c77d4d04748a4a}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Aurick},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{fullhash}{951e86110020d3107317b3e819f3d92d}
      \strng{bibnamehash}{951e86110020d3107317b3e819f3d92d}
      \strng{authorbibnamehash}{951e86110020d3107317b3e819f3d92d}
      \strng{authornamehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{authorfullhash}{951e86110020d3107317b3e819f3d92d}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{number}{arXiv:1801.01290}
      \field{shorttitle}{Soft {{Actor-Critic}}}
      \field{title}{Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}}
      \field{urlday}{14}
      \field{urlmonth}{6}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1801.01290
      \endverb
      \verb{eprint}
      \verb 1801.01290
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Haarnoja et al_2018_Soft Actor-Critic.pdf;/home/james/Zotero/storage/YYPH8Z7L/1801.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{haarnojaSoftActorCriticAlgorithms2019}{misc}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=45b14f55dd7ae28cb6cb2e23e4a168b9}{%
           family={Haarnoja},
           familyi={H\bibinitperiod},
           given={Tuomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=519033a7338e5ef684c77d4d04748a4a}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Aurick},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2bf28b92c31c717feee2c15487657b25}{%
           family={Hartikainen},
           familyi={H\bibinitperiod},
           given={Kristian},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=641a3f5d5ce834c4b56fb672c5df0207}{%
           family={Tucker},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d235634814ed266793a4de24b71955e6}{%
           family={Ha},
           familyi={H\bibinitperiod},
           given={Sehoon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aaa7cb90b2e1cc2079b5e8a087a903c9}{%
           family={Tan},
           familyi={T\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bbba0ccb50436105a4134d24509b62d7}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Vikash},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fde29d8aa12ec2aa9ab89c495df350fb}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Henry},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d0792eb04b685020eafedbc871aeb84f}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Abhishek},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{fullhash}{c6ac1e78375b5b1cb1c472544f2557df}
      \strng{bibnamehash}{c6ac1e78375b5b1cb1c472544f2557df}
      \strng{authorbibnamehash}{c6ac1e78375b5b1cb1c472544f2557df}
      \strng{authornamehash}{b8c131de85c5000ff50df59a4d062227}
      \strng{authorfullhash}{c6ac1e78375b5b1cb1c472544f2557df}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:1812.05905}
      \field{title}{Soft {{Actor-Critic Algorithms}} and {{Applications}}}
      \field{urlday}{24}
      \field{urlmonth}{8}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1812.05905
      \endverb
      \verb{eprint}
      \verb 1812.05905
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Haarnoja et al_2019_Soft Actor-Critic Algorithms and Applications.pdf;/home/james/Zotero/storage/LAQAN6WZ/1812.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{hafnerDreamControlLearning2020}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e34c5aa67281924804d54d88e58ca38a}{%
           family={Norouzi},
           familyi={N\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \strng{bibnamehash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \strng{authorbibnamehash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{88c74a45afdd86b1e3b1ee23d1d5c536}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Learned world models summarize an agent's experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1912.01603}
      \field{shorttitle}{Dream to {{Control}}}
      \field{title}{Dream to {{Control}}: {{Learning Behaviors}} by {{Latent Imagination}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.01603
      \endverb
      \verb{eprint}
      \verb 1912.01603
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hafner et al_2020_Dream to Control.pdf;/home/james/Zotero/storage/95G88IHI/1912.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{hafnerLearningLatentDynamics2019}{misc}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=283cecbdc579f4c9098a22907b254877}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4115de371d87baba0d4934fd66756db5}{%
           family={Villegas},
           familyi={V\bibinitperiod},
           given={Ruben},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4467056eb9d0a44c1ec21bbb4d6152c5}{%
           family={Ha},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d09ea8631bf43468107b5ef02c5195aa}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Honglak},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=067f1e3d219657d2c89fbaa1325dbfab}{%
           family={Davidson},
           familyi={D\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \strng{bibnamehash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \strng{authorbibnamehash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{b5972ac26d4817a7a1e0027fd3747ad0}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1811.04551}
      \field{title}{Learning {{Latent Dynamics}} for {{Planning}} from {{Pixels}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1811.04551
      \endverb
      \verb{eprint}
      \verb 1811.04551
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hafner et al_2019_Learning Latent Dynamics for Planning from Pixels.pdf;/home/james/Zotero/storage/75LXKK22/1811.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{hafnerMasteringAtariDiscrete2022}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e34c5aa67281924804d54d88e58ca38a}{%
           family={Norouzi},
           familyi={N\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{71b9635f1977d0972d355d4c4a573913}
      \strng{bibnamehash}{71b9635f1977d0972d355d4c4a573913}
      \strng{authorbibnamehash}{71b9635f1977d0972d355d4c4a573913}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{71b9635f1977d0972d355d4c4a573913}
      \field{extraname}{3}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, Dreamer V2 reaches 200M frames and surpasses the final performance of the top single-GPU agents IQN and Rainbow. DreamerV2 is also applicable to tasks with continuous actions, where it learns an accurate world model of a complex humanoid robot and solves stand-up and walking from only pixel inputs.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{number}{arXiv:2010.02193}
      \field{title}{Mastering {{Atari}} with {{Discrete World Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2010.02193
      \endverb
      \verb{eprint}
      \verb 2010.02193
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hafner et al_2022_Mastering Atari with Discrete World Models.pdf;/home/james/Zotero/storage/UA2F47NY/2010.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{hafnerMasteringDiverseDomains2024}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2caecdc0ecdc4f891514f2ff9518e3cb}{%
           family={Pasukonis},
           familyi={P\bibinitperiod},
           given={Jurgis},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{fullhash}{c697658c389c65d7a42da010daf15748}
      \strng{bibnamehash}{c697658c389c65d7a42da010daf15748}
      \strng{authorbibnamehash}{c697658c389c65d7a42da010daf15748}
      \strng{authornamehash}{9aca3b76f5abae60a22a50ebaaabe505}
      \strng{authorfullhash}{c697658c389c65d7a42da010daf15748}
      \field{extraname}{4}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Developing a general algorithm that learns to solve tasks across a wide range of applications has been a fundamental challenge in artificial intelligence. Although current reinforcement learning algorithms can be readily applied to tasks similar to what they have been developed for, configuring them for new application domains requires significant human expertise and experimentation. We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration. Dreamer learns a model of the environment and improves its behavior by imagining future scenarios. Robustness techniques based on normalization, balancing, and transformations enable stable learning across domains. Applied out of the box, Dreamer is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula. This achievement has been posed as a significant challenge in artificial intelligence that requires exploring farsighted strategies from pixels and sparse rewards in an open world. Our work allows solving challenging control problems without extensive experimentation, making reinforcement learning broadly applicable.}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:2301.04104}
      \field{title}{Mastering {{Diverse Domains}} through {{World Models}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2301.04104
      \endverb
      \verb{eprint}
      \verb 2301.04104
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/HYS3S98G/Hafner et al. - 2024 - Mastering Diverse Domains through World Models.pdf;/home/james/Zotero/storage/R4M4U9NX/2301.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{heMaskedAutoencodersAre2021}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ce10870c303bf2f78994acd2df305b39}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Xinlei},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=843b6293b24d49cdfdcda48e1ccd7eb3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Saining},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46e2e0b282bd98dcc736b344f4c7274f}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yanghao},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ecd149fdcb3e0503881d49e545744c3d}{%
           family={DollÃ¡r},
           familyi={D\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{720293b27fe84a23031231f283c72cd1}
      \strng{bibnamehash}{720293b27fe84a23031231f283c72cd1}
      \strng{authorbibnamehash}{720293b27fe84a23031231f283c72cd1}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{720293b27fe84a23031231f283c72cd1}
      \field{extraname}{1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75\%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3x or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8\%) among methods that use only ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pre-training and shows promising scaling behavior.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:2111.06377}
      \field{title}{Masked {{Autoencoders Are Scalable Vision Learners}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2111.06377
      \endverb
      \verb{eprint}
      \verb 2111.06377
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/He et al_2021_Masked Autoencoders Are Scalable Vision Learners.pdf;/home/james/Zotero/storage/4EWC2432/2111.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{heMomentumContrastUnsupervised2020}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e68b3965779a4e603c10d027dd82b5c1}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Haoqi},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b626dcc418c3a5c74cfaa4c5e643a71f}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yuxin},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=843b6293b24d49cdfdcda48e1ccd7eb3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Saining},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{52cb9810506b099972148981d95ec86c}
      \strng{bibnamehash}{52cb9810506b099972148981d95ec86c}
      \strng{authorbibnamehash}{52cb9810506b099972148981d95ec86c}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{52cb9810506b099972148981d95ec86c}
      \field{extraname}{2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1911.05722}
      \field{title}{Momentum {{Contrast}} for {{Unsupervised Visual Representation Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1911.05722
      \endverb
      \verb{eprint}
      \verb 1911.05722
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/PL8SZT3I/He et al. - 2020 - Momentum Contrast for Unsupervised Visual Representation Learning.pdf;/home/james/Zotero/storage/UNCHHJ6N/1911.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{hesselRainbowCombiningImprovements2017}{misc}{}
      \name{author}{10}{}{%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2627fbd818853e670084cf0b17107962}{%
           family={Modayil},
           familyi={M\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e75f0b2e9c29c175e6320c1e96cdf5c8}{%
           family={{van Hasselt}},
           familyi={v\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46cc21fb5dec973c05ceb0f321e02ca0}{%
           family={Ostrovski},
           familyi={O\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5a44cbf0d05e4c50b512bb0c1368d2f}{%
           family={Dabney},
           familyi={D\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c1a26cb7f963abdf071da408366e83a1}{%
           family={Horgan},
           familyi={H\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f31963abd2aa43dd3aafc40aa1252a05}{%
           family={Piot},
           familyi={P\bibinitperiod},
           given={Bilal},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50bebf4ece6d98f0ecef1bcff295ab7e}{%
           family={Azar},
           familyi={A\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{04c4fc38c232f5c2360309d90f2dc80e}
      \strng{fullhash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \strng{bibnamehash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \strng{authorbibnamehash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \strng{authornamehash}{04c4fc38c232f5c2360309d90f2dc80e}
      \strng{authorfullhash}{81d605e2c57adf7d67e22fd9e9cf0c50}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1710.02298}
      \field{shorttitle}{Rainbow}
      \field{title}{Rainbow: {{Combining Improvements}} in {{Deep Reinforcement Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1710.02298
      \endverb
      \verb{eprint}
      \verb 1710.02298
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Hessel et al_2017_Rainbow.pdf;/home/james/Zotero/storage/R45S76E4/1710.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{huang2022cleanrl}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=a485c9f2edbeda28fc6122a6d8ef9913}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Shengyi},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=32e389f8fcbcf0f82233cdfb17fc7c2e}{%
           family={Dossa},
           familyi={D\bibinitperiod},
           given={Rousslan\bibnamedelimb Fernand\bibnamedelima Julien},
           giveni={R\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f1dee49ff1f7c58167e78dd52894041e}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Chang},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8cc4095acb7526b1751dcfdb493d8844}{%
           family={Braga},
           familyi={B\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4c84046e785d39de01f660f64cbadb3e}{%
           family={Chakraborty},
           familyi={C\bibinitperiod},
           given={Dipam},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0fb774b6fae5ad2ed906e0161fa9f0bd}{%
           family={Mehta},
           familyi={M\bibinitperiod},
           given={Kinal},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=59f8577a44395d13588ed7a194581fdb}{%
           family={AraÃºjo},
           familyi={A\bibinitperiod},
           given={JoÃ£o\bibnamedelima G.M.},
           giveni={J\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{33f5845a5b5ee5484c495cf2ba4853de}
      \strng{fullhash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \strng{bibnamehash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \strng{authorbibnamehash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \strng{authornamehash}{33f5845a5b5ee5484c495cf2ba4853de}
      \strng{authorfullhash}{3d7fe08cb1c7ee6fdc79a7abf1163e66}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{274}
      \field{title}{CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms}
      \field{volume}{23}
      \field{year}{2022}
      \field{pages}{1\bibrangedash 18}
      \range{pages}{18}
      \verb{urlraw}
      \verb http://jmlr.org/papers/v23/21-1342.html
      \endverb
      \verb{url}
      \verb http://jmlr.org/papers/v23/21-1342.html
      \endverb
    \endentry
    \entry{jannerWhenTrustYour2021}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=030220ad86ae86f35b535d317d8a98bb}{%
           family={Janner},
           familyi={J\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a018be9fcf5a8ea4185688a73eefa56}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=306746c29cdb22ddddf3606b521cdf1e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Marvin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{22ed8af2a309bb809eb363ab521af746}
      \strng{fullhash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \strng{bibnamehash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \strng{authorbibnamehash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \strng{authornamehash}{22ed8af2a309bb809eb363ab521af746}
      \strng{authorfullhash}{4bcf0b8ed6b1f9be6c2d8e6bca5f33d9}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:1906.08253}
      \field{shorttitle}{When to {{Trust Your Model}}}
      \field{title}{When to {{Trust Your Model}}: {{Model-Based Policy Optimization}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1906.08253
      \endverb
      \verb{eprint}
      \verb 1906.08253
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Janner et al_2021_When to Trust Your Model.pdf;/home/james/Zotero/storage/ZY3DI9HK/1906.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{julianiStudyPlasticityLoss2024}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=b40f803735aa0d2366759b65737b11b5}{%
           family={Juliani},
           familyi={J\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33495469d5c8f82e0caea745e1547a1a}{%
           family={Ash},
           familyi={A\bibinitperiod},
           given={Jordan\bibnamedelima T.},
           giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{fullhash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{bibnamehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{authorbibnamehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{authornamehash}{28173441c5ec27e6eabcd50ab831fb9e}
      \strng{authorfullhash}{28173441c5ec27e6eabcd50ab831fb9e}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Continual learning with deep neural networks presents challenges distinct from both the fixed-dataset and convex continual learning regimes. One such challenge is plasticity loss, wherein a neural network trained in an online fashion displays a degraded ability to fit new tasks. This problem has been extensively studied in both supervised learning and off-policy reinforcement learning (RL), where a number of remedies have been proposed. Still, plasticity loss has received less attention in the on-policy deep RL setting. Here we perform an extensive set of experiments examining plasticity loss and a variety of mitigation methods in on-policy deep RL. We demonstrate that plasticity loss is pervasive under domain shift in this regime, and that a number of methods developed to resolve it in other settings fail, sometimes even resulting in performance that is worse than performing no intervention at all. In contrast, we find that a class of ``regenerative'' methods are able to consistently mitigate plasticity loss in a variety of contexts, including in gridworld tasks and more challenging environments like Montezuma's Revenge and ProcGen.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:2405.19153}
      \field{title}{A {{Study}} of {{Plasticity Loss}} in {{On-Policy Deep Reinforcement Learning}}}
      \field{urlday}{29}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2405.19153
      \endverb
      \verb{eprint}
      \verb 2405.19153
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/RV6JPVD4/Juliani and Ash - 2024 - A Study of Plasticity Loss in On-Policy Deep Reinf.pdf;/home/james/Zotero/storage/TPXI24F4/2405.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{kaiserModelBasedReinforcementLearning2024}{misc}{}
      \name{author}{14}{}{%
        {{un=0,uniquepart=base,hash=f2bc899b1160163417da7bf510f15d33}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Lukasz},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bee046fabb85a8fb46ac6414d13fa4c5}{%
           family={Babaeizadeh},
           familyi={B\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a5eca6c6f47ed957501df97298fc2f59}{%
           family={Milos},
           familyi={M\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=64834d3a91d16390d4188548afc76fc8}{%
           family={Osinski},
           familyi={O\bibinitperiod},
           given={Blazej},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=886cc29df3761bc097a37b2f4323bb7d}{%
           family={Campbell},
           familyi={C\bibinitperiod},
           given={Roy\bibnamedelima H.},
           giveni={R\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c5b1224768c765a5d03bd6a26af61368}{%
           family={Czechowski},
           familyi={C\bibinitperiod},
           given={Konrad},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8bbc4c5d96f205bada839e74e0202146}{%
           family={Erhan},
           familyi={E\bibinitperiod},
           given={Dumitru},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=058e82495825ae376c6a96a12169e6ee}{%
           family={Finn},
           familyi={F\bibinitperiod},
           given={Chelsea},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0aa3050e04ebd05a764a990d1ebc7c36}{%
           family={Kozakowski},
           familyi={K\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=204e2adab232f612fc459546fb067b67}{%
           family={Mohiuddin},
           familyi={M\bibinitperiod},
           given={Afroz},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7f45cbea23420eb9e29c75c69725248f}{%
           family={Sepassi},
           familyi={S\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=641a3f5d5ce834c4b56fb672c5df0207}{%
           family={Tucker},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=88b44aba31eead485bb3a63154798388}{%
           family={Michalewski},
           familyi={M\bibinitperiod},
           given={Henryk},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{141faaaad26d9473f46ca6887d212b08}
      \strng{fullhash}{f49d53ab71c7ef6629f1efea9390984a}
      \strng{bibnamehash}{f49d53ab71c7ef6629f1efea9390984a}
      \strng{authorbibnamehash}{f49d53ab71c7ef6629f1efea9390984a}
      \strng{authornamehash}{141faaaad26d9473f46ca6887d212b08}
      \strng{authorfullhash}{f49d53ab71c7ef6629f1efea9390984a}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:1903.00374}
      \field{title}{Model-{{Based Reinforcement Learning}} for {{Atari}}}
      \field{urlday}{18}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1903.00374
      \endverb
      \verb{eprint}
      \verb 1903.00374
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/DTUZ3VK7/Kaiser et al. - 2024 - Model-Based Reinforcement Learning for Atari.pdf;/home/james/Zotero/storage/5IXG6WQL/1903.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{kearnsBiasVarianceErrorBounds2000}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=d6e0fc1e9d08f7c702ebed66002adeef}{%
           family={Kearns},
           familyi={K\bibinitperiod},
           given={Michael\bibnamedelima J.},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0778520109d58859c98d71f3b7e75837}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Satinder\bibnamedelima P.},
           giveni={S\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {San Francisco, CA, USA}%
      }
      \list{publisher}{1}{%
        {Morgan Kaufmann Publishers Inc.}%
      }
      \strng{namehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{fullhash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{bibnamehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{authorbibnamehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{authornamehash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \strng{authorfullhash}{bdf3ea3e00da4dc7b84e7fa42eda8e99}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-55860-703-3}
      \field{journaltitle}{Proceedings of the {{Thirteenth Annual Conference}} on {{Computational Learning Theory}}}
      \field{month}{6}
      \field{series}{{{COLT}} '00}
      \field{title}{Bias-{{Variance Error Bounds}} for {{Temporal Difference Updates}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2000}
      \field{urldateera}{ce}
      \field{pages}{142\bibrangedash 147}
      \range{pages}{6}
    \endentry
    \entry{kingmaAutoEncodingVariationalBayes2022}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=53d2880ad8047b61cdae2c6b2803e763}{%
           family={Welling},
           familyi={W\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{fullhash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{bibnamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authorbibnamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authornamehash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \strng{authorfullhash}{aabdd5db7a1ed298b1dfb6824d032c66}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1312.6114}
      \field{title}{Auto-{{Encoding Variational Bayes}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1312.6114
      \endverb
      \verb{eprint}
      \verb 1312.6114
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/7MM8EYSG/Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf;/home/james/Zotero/storage/8WEIQSBD/1312.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{kostrikovImageAugmentationAll2021}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=36c384c0d52c2e0b0d8bc9f99b9fc985}{%
           family={Kostrikov},
           familyi={K\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c1a92bfddfd960be33e0dbc1cd54ddef}{%
           family={Yarats},
           familyi={Y\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6784304d1cc890b2cb6c6c7f2f3fd76}{%
           family={Fergus},
           familyi={F\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{36a769a033a100a9e50e0fe8308161d7}
      \strng{fullhash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \strng{bibnamehash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \strng{authorbibnamehash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \strng{authornamehash}{36a769a033a100a9e50e0fe8308161d7}
      \strng{authorfullhash}{e3cbdd5bd1db98ce9c2d6b16dbbc053a}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training. The approach leverages input perturbations commonly used in computer vision tasks to regularize the value function. Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC's performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Dreamer, PlaNet, and SLAC) methods and recently proposed contrastive learning (CURL). Our approach can be combined with any model-free reinforcement learning algorithm, requiring only minor modifications. An implementation can be found at https://sites.google.com/view/data-regularized-q.}
      \field{eprintclass}{cs, eess, stat}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2004.13649}
      \field{shorttitle}{Image {{Augmentation Is All You Need}}}
      \field{title}{Image {{Augmentation Is All You Need}}: {{Regularizing Deep Reinforcement Learning}} from {{Pixels}}}
      \field{urlday}{13}
      \field{urlmonth}{9}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2004.13649
      \endverb
      \verb{eprint}
      \verb 2004.13649
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/NT5GU8GQ/Kostrikov et al. - 2021 - Image Augmentation Is All You Need Regularizing D.pdf;/home/james/Zotero/storage/LZ9VZ6D2/2004.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning}
    \endentry
    \entry{kurutachModelEnsembleTrustRegionPolicy2018}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=9b11af4841b4b3e436a27b0f140f45e3}{%
           family={Kurutach},
           familyi={K\bibinitperiod},
           given={Thanard},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a0423de20f2c114c3f6bb51a7a7e76d6}{%
           family={Clavera},
           familyi={C\bibinitperiod},
           given={Ignasi},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=beba2607fa3b01b069f484075d0b9cf2}{%
           family={Duan},
           familyi={D\bibinitperiod},
           given={Yan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=41ea42ab7e09607e91466632ce419d8c}{%
           family={Tamar},
           familyi={T\bibinitperiod},
           given={Aviv},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{bcd852cbf793bc0e57781a2ed546fe5c}
      \strng{fullhash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \strng{bibnamehash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \strng{authorbibnamehash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \strng{authornamehash}{bcd852cbf793bc0e57781a2ed546fe5c}
      \strng{authorfullhash}{83fbd36aed10efd1a69b63ff92d4e05e}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity, which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1802.10592}
      \field{title}{Model-{{Ensemble Trust-Region Policy Optimization}}}
      \field{urlday}{26}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1802.10592
      \endverb
      \verb{eprint}
      \verb 1802.10592
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/NPZPA3WL/Kurutach et al. - 2018 - Model-Ensemble Trust-Region Policy Optimization.pdf;/home/james/Zotero/storage/JVFZXSE7/1802.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{laskinReinforcementLearningAugmented2020}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=4b7fbc26d49455e302dd6d5ab6a35ddf}{%
           family={Laskin},
           familyi={L\bibinitperiod},
           given={Misha},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a74a7d6a839e48de367e41b7ec29d456}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kimin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aad83400c6061a7a8f6c422951af64cf}{%
           family={Stooke},
           familyi={S\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d4b78f1220fe5cab8395d811fc9c5b2}{%
           family={Pinto},
           familyi={P\bibinitperiod},
           given={Lerrel},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=09fed423ccdd83193718e9e7e2c70481}{%
           family={Srinivas},
           familyi={S\bibinitperiod},
           given={Aravind},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{cec4377fb3611a238af0f919581bf172}
      \strng{fullhash}{a64856e2dc51348cdfe924e33d57a4bb}
      \strng{bibnamehash}{a64856e2dc51348cdfe924e33d57a4bb}
      \strng{authorbibnamehash}{a64856e2dc51348cdfe924e33d57a4bb}
      \strng{authornamehash}{cec4377fb3611a238af0f919581bf172}
      \strng{authorfullhash}{a64856e2dc51348cdfe924e33d57a4bb}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning from visual observations is a fundamental yet challenging problem in Reinforcement Learning (RL). Although algorithmic advances combined with convolutional neural networks have proved to be a recipe for success, current methods are still lacking on two fronts: (a) data-efficiency of learning and (b) generalization to new environments. To this end, we present Reinforcement Learning with Augmented Data (RAD), a simple plug-and-play module that can enhance most RL algorithms. We perform the first extensive study of general data augmentations for RL on both pixel-based and state-based inputs, and introduce two new data augmentations - random translate and random amplitude scale. We show that augmentations such as random translate, crop, color jitter, patch cutout, random convolutions, and amplitude scale can enable simple RL algorithms to outperform complex state-of-the-art methods across common benchmarks. RAD sets a new state-of-the-art in terms of data-efficiency and final performance on the DeepMind Control Suite benchmark for pixel-based control as well as OpenAI Gym benchmark for state-based control. We further demonstrate that RAD significantly improves test-time generalization over existing methods on several OpenAI ProcGen benchmarks.}
      \field{journaltitle}{Advances in {{Neural Information Processing Systems}}}
      \field{title}{Reinforcement {{Learning}} with {{Augmented Data}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{33}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{19884\bibrangedash 19895}
      \range{pages}{12}
      \verb{file}
      \verb /home/james/Zotero/storage/RBDVETXJ/Laskin et al. - 2020 - Reinforcement Learning with Augmented Data.pdf
      \endverb
    \endentry
    \entry{lillicrapContinuousControlDeep2019}{misc}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=2a321a868e44d49baf52b5e2d816fb71}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy\bibnamedelima P.},
           giveni={T\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e0c5cec59a932511b2af6220473fad61}{%
           family={Hunt},
           familyi={H\bibinitperiod},
           given={Jonathan\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4295e4094c426f01903ac60155866130}{%
           family={Pritzel},
           familyi={P\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=231312991eab5915498d6c19c2a8cd4e}{%
           family={Heess},
           familyi={H\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3b79ca47f08451987877fd8682e971e5}{%
           family={Erez},
           familyi={E\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=58112cb88a80c1bc045b6eaab26a8695}{%
           family={Tassa},
           familyi={T\bibinitperiod},
           given={Yuval},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d7805381550fb5f8360345f7f72c0b49}{%
           family={Wierstra},
           familyi={W\bibinitperiod},
           given={Daan},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{e9929f8db9dd2c08064f17b4d9a7c551}
      \strng{fullhash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \strng{bibnamehash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \strng{authorbibnamehash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \strng{authornamehash}{e9929f8db9dd2c08064f17b4d9a7c551}
      \strng{authorfullhash}{9f2f0357b439f9ae4a3953d81392aaa0}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1509.02971}
      \field{title}{Continuous Control with Deep Reinforcement Learning}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1509.02971
      \endverb
      \verb{eprint}
      \verb 1509.02971
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/WEB39L3B/Lillicrap et al. - 2019 - Continuous control with deep reinforcement learning.pdf;/home/james/Zotero/storage/J3V4JQJJ/1509.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{loshchilovDecoupledWeightDecay2018}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=1241b8181104f1917578d4c7f9b323b6}{%
           family={Loshchilov},
           familyi={L\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=528d4af87fd2ecf5fb8a22db913ce088}{%
           family={Hutter},
           familyi={H\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{fullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{bibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorbibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authornamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorfullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at {\textbackslash}url\{https://github.com/loshchil/AdamW-and-SGDW\}}
      \field{journaltitle}{International {{Conference}} on {{Learning Representations}}}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Decoupled {{Weight Decay Regularization}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/2FPW57V3/Loshchilov and Hutter - 2018 - Decoupled Weight Decay Regularization.pdf
      \endverb
    \endentry
    \entry{lyleUnderstandingPlasticityNeural2023}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=5b82601d6753d5b4566740b519f02b96}{%
           family={Lyle},
           familyi={L\bibinitperiod},
           given={Clare},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eab311bac27bfd4d97008d3e3c762cf0}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Zeyu},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d078365da0923eced35cd9345318ca0}{%
           family={Nikishin},
           familyi={N\bibinitperiod},
           given={Evgenii},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8ff346cbfa06024a8dd0afe01bd765a}{%
           family={Pires},
           familyi={P\bibinitperiod},
           given={Bernardo\bibnamedelima Avila},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7045b009b04d57bd2e19b5dfa0864d4f}{%
           family={Pascanu},
           familyi={P\bibinitperiod},
           given={Razvan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5a44cbf0d05e4c50b512bb0c1368d2f}{%
           family={Dabney},
           familyi={D\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{89eb1cf3866556e56ed3ca88af261bed}
      \strng{fullhash}{8b2e8a254a5d491293879fe9d17a4b93}
      \strng{bibnamehash}{8b2e8a254a5d491293879fe9d17a4b93}
      \strng{authorbibnamehash}{8b2e8a254a5d491293879fe9d17a4b93}
      \strng{authornamehash}{89eb1cf3866556e56ed3ca88af261bed}
      \strng{authorfullhash}{8b2e8a254a5d491293879fe9d17a4b93}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Plasticity, the ability of a neural network to quickly change its predictions in response to new information, is essential for the adaptability and robustness of deep reinforcement learning systems. Deep neural networks are known to lose plasticity over the course of training even in relatively simple learning problems, but the mechanisms driving this phenomenon are still poorly understood. This paper conducts a systematic empirical analysis into plasticity loss, with the goal of understanding the phenomenon mechanistically in order to guide the future development of targeted solutions. We find that loss of plasticity is deeply connected to changes in the curvature of the loss landscape, but that it often occurs in the absence of saturated units. Based on this insight, we identify a number of parameterization and optimization design choices which enable networks to better preserve plasticity over the course of training. We validate the utility of these findings on larger-scale RL benchmarks in the Arcade Learning Environment.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{arXiv:2303.01486}
      \field{title}{Understanding Plasticity in Neural Networks}
      \field{urlday}{20}
      \field{urlmonth}{10}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2303.01486
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/H2KNQDDB/Lyle et al. - 2023 - Understanding plasticity in neural networks.pdf
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{tensorflow2015-whitepaper}{misc}{}
      \name{author}{40}{}{%
        {{un=0,uniquepart=base,hash=396d6419316ec52f4c63b2f85912b61b}{%
           family={MartÃ­n\bibnamedelima Abadi},
           familyi={M\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=f337a7c116835c22bb206d2f0d7c70e0}{%
           family={Ashish\bibnamedelima Agarwal},
           familyi={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=84ac9fcb6c15dcd79c092bc8e20586ba}{%
           family={Paul\bibnamedelima Barham},
           familyi={P\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=d8574748e3086e0b279a58cdba71763d}{%
           family={Eugene\bibnamedelima Brevdo},
           familyi={E\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=c0b56f741b5a5bddfe77f1881c3cc67a}{%
           family={Zhifeng\bibnamedelima Chen},
           familyi={Z\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=8b8dd2e01366c855f42e47027cf23e98}{%
           family={Craig\bibnamedelima Citro},
           familyi={C\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=978a7d9601bf09e03d1bb3f6cce7a0ce}{%
           family={Greg\bibnamedelima S.\bibnamedelimi Corrado},
           familyi={G\bibinitperiod\bibinitdelim S\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=3b500b0dfd88e6e151d29108fdcb82f0}{%
           family={Andy\bibnamedelima Davis},
           familyi={A\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=2fd376ea3b3a3da11704c0ee86753dcf}{%
           family={Jeffrey\bibnamedelima Dean},
           familyi={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=5b34e641dd8a00f97c6242ae0353eb90}{%
           family={Matthieu\bibnamedelima Devin},
           familyi={M\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=5b4490947d4e91359646ce3c93cbd2f7}{%
           family={Sanjay\bibnamedelima Ghemawat},
           familyi={S\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1fdef10b94ee122ef6136197f99e3df3}{%
           family={Ian\bibnamedelima Goodfellow},
           familyi={I\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=166ae8a0b435eded68e39e9e2d2a1ee8}{%
           family={Andrew\bibnamedelima Harp},
           familyi={A\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=7e9f7006151cf312bc133568336c68c6}{%
           family={Geoffrey\bibnamedelima Irving},
           familyi={G\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=08c1890e1c33279b8c63c71fa8f19263}{%
           family={Michael\bibnamedelima Isard},
           familyi={M\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=9fce03efe6b3331a1b93ed2e7c0da9d5}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Yangqing},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0c0eea5379268c0c5b68732c90984b6}{%
           family={Rafal\bibnamedelima Jozefowicz},
           familyi={R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=cff46cb4603a73d83b11ea7a9ded9d79}{%
           family={Lukasz\bibnamedelima Kaiser},
           familyi={L\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=d088e0f635523b8b5b18662331e4f44a}{%
           family={Manjunath\bibnamedelima Kudlur},
           familyi={M\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1c24291ae15b979c82aa09a33790cb62}{%
           family={Josh\bibnamedelima Levenberg},
           familyi={J\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=796a3a98ff7545fe10f6a4c17ba016fa}{%
           family={Dandelion\bibnamedelima ManÃ©},
           familyi={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1ee98d232eb1fc1208a8f8ca649e970b}{%
           family={Rajat\bibnamedelima Monga},
           familyi={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b2a15ec3d90955ece50ea26d31100b9a}{%
           family={Sherry\bibnamedelima Moore},
           familyi={S\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1494c573fadad736c58cf1119ac59239}{%
           family={Derek\bibnamedelima Murray},
           familyi={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ecf58eb1684af6cba2c1f126405eedab}{%
           family={Chris\bibnamedelima Olah},
           familyi={C\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=9f43befd94cd09a9aaa7ea8489405a83}{%
           family={Mike\bibnamedelima Schuster},
           familyi={M\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=4712800a228b1179529b9f6e0d1b1838}{%
           family={Jonathon\bibnamedelima Shlens},
           familyi={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=41ad6ff6c026d5a3730269072b31caf1}{%
           family={Benoit\bibnamedelima Steiner},
           familyi={B\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b02f7871db6fc5524cec4ce38e104410}{%
           family={Ilya\bibnamedelima Sutskever},
           familyi={I\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=63288446e47b1d383f522ede84aa6fcc}{%
           family={Kunal\bibnamedelima Talwar},
           familyi={K\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1dec75595b55bf77971f6a932d146b81}{%
           family={Paul\bibnamedelima Tucker},
           familyi={P\bibinitperiod\bibinitdelim T\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b6680dbb0176cb9bd87a3b26fa6f5cfb}{%
           family={Vincent\bibnamedelima Vanhoucke},
           familyi={V\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=e030c9d199c66657e26138be29814d81}{%
           family={Vijay\bibnamedelima Vasudevan},
           familyi={V\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=04426b798803cfaf3e8aa9280a5d0a58}{%
           family={Fernanda\bibnamedelima ViÃ©gas},
           familyi={F\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=fa7242e11c7d955de2ac1be94ca29073}{%
           family={Oriol\bibnamedelima Vinyals},
           familyi={O\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=8c9ee8f70a3c3d97f85efd01c4e9cbe6}{%
           family={Pete\bibnamedelima Warden},
           familyi={P\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=8e4243c228c72a5e5279e31252887b32}{%
           family={Martin\bibnamedelima Wattenberg},
           familyi={M\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=c6a6eb2597f23589fc9141bdda275996}{%
           family={Martin\bibnamedelima Wicke},
           familyi={M\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=3ea39e6dc6ef47029ae996c7e63f1a48}{%
           family={Yuan\bibnamedelima Yu},
           familyi={Y\bibinitperiod\bibinitdelim Y\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=b69feb3a3d59a312b20dbef0b1d2d6de}{%
           family={Xiaoqiang\bibnamedelima Zheng},
           familyi={X\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
      }
      \strng{namehash}{7fdd865be502254047a3b2638dc0cfeb}
      \strng{fullhash}{9b332dc9b33a2f6316d71d525269bd0f}
      \strng{bibnamehash}{f1d28cdb6a316b575768cd5835e052b9}
      \strng{authorbibnamehash}{f1d28cdb6a316b575768cd5835e052b9}
      \strng{authornamehash}{7fdd865be502254047a3b2638dc0cfeb}
      \strng{authorfullhash}{9b332dc9b33a2f6316d71d525269bd0f}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{Software available from tensorflow.org}
      \field{title}{{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems}
      \field{year}{2015}
      \verb{urlraw}
      \verb https://www.tensorflow.org/
      \endverb
      \verb{url}
      \verb https://www.tensorflow.org/
      \endverb
    \endentry
    \entry{micheliTransformersAreSampleEfficient2023}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=da539a6612ef5e086053b6366707183e}{%
           family={Micheli},
           familyi={M\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=645fa2d79cecc93afa96b49040e5c725}{%
           family={Alonso},
           familyi={A\bibinitperiod},
           given={Eloi},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=def3560de15608bae049e94de457b966}{%
           family={Fleuret},
           familyi={F\bibinitperiod},
           given={FranÃ§ois},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8643639c0a82a28443469ca69c2ee337}
      \strng{fullhash}{f3de9bdb74509fe881f88a928f275db2}
      \strng{bibnamehash}{f3de9bdb74509fe881f88a928f275db2}
      \strng{authorbibnamehash}{f3de9bdb74509fe881f88a928f275db2}
      \strng{authornamehash}{8643639c0a82a28443469ca69c2ee337}
      \strng{authorfullhash}{f3de9bdb74509fe881f88a928f275db2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems. Recently, many model-based methods have been designed to address this issue, with learning in the imagination of a world model being one of the most prominent approaches. However, while virtually unlimited interaction with a simulated environment sounds appealing, the world model has to be accurate over extended periods of time. Motivated by the success of Transformers in sequence modeling tasks, we introduce IRIS, a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer. With the equivalent of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean human normalized score of 1.046, and outperforms humans on 10 out of 26 games, setting a new state of the art for methods without lookahead search. To foster future research on Transformers and world models for sample-efficient reinforcement learning, we release our code and models at https://github.com/eloialonso/iris.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2209.00588}
      \field{title}{Transformers Are {{Sample-Efficient World Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2209.00588
      \endverb
      \verb{eprint}
      \verb 2209.00588
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Micheli et al_2023_Transformers are Sample-Efficient World Models.pdf;/home/james/Zotero/storage/CFS39CM5/2209.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{mnihHumanlevelControlDeep2015}{article}{}
      \name{author}{19}{}{%
        {{un=0,uniquepart=base,hash=f7d23cfe4ca0e6bf7a8c251bfa78aca6}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Volodymyr},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=677dfee41a39b5ac7e138f5ce14467e9}{%
           family={Rusu},
           familyi={R\bibinitperiod},
           given={Andrei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1cbd91f7404b2298b46bb46c47c08251}{%
           family={Veness},
           familyi={V\bibinitperiod},
           given={Joel},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eae3aa0ab9cb8b33a1ade80739e79e57}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be3d55306c5ab7ee716f96f137dddba6}{%
           family={Fidjeland},
           familyi={F\bibinitperiod},
           given={Andreas\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46cc21fb5dec973c05ceb0f321e02ca0}{%
           family={Ostrovski},
           familyi={O\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e381e44037009b1cd834d794735c311}{%
           family={Petersen},
           familyi={P\bibinitperiod},
           given={Stig},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03cf4f0976cc27112d267a8916a2d169}{%
           family={Beattie},
           familyi={B\bibinitperiod},
           given={Charles},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b827d5121d467eeb30ccac8c61094591}{%
           family={Sadik},
           familyi={S\bibinitperiod},
           given={Amir},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=59998a15386f62e4d2776176ab58d49c}{%
           family={King},
           familyi={K\bibinitperiod},
           given={Helen},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a425c81c03d315597e3f92690763e24d}{%
           family={Kumaran},
           familyi={K\bibinitperiod},
           given={Dharshan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d7805381550fb5f8360345f7f72c0b49}{%
           family={Wierstra},
           familyi={W\bibinitperiod},
           given={Daan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=afdf5ed50a24cdca0f42433e4f4848d5}{%
           family={Legg},
           familyi={L\bibinitperiod},
           given={Shane},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Nature Publishing Group}%
      }
      \strng{namehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{fullhash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{bibnamehash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authorbibnamehash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \strng{authornamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorfullhash}{29e1f598b04c2ec7e97aaeb02f70e0c8}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An artificial agent is developed that learns to play~a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a~performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{7540}
      \field{title}{Human-Level Control through Deep Reinforcement Learning}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{518}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{529\bibrangedash 533}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1038/nature14236
      \endverb
      \keyw{Computer science}
    \endentry
    \entry{nikishinPrimacyBiasDeep2022}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=9d078365da0923eced35cd9345318ca0}{%
           family={Nikishin},
           familyi={N\bibinitperiod},
           given={Evgenii},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e09d377eb804fa206349bcc1d7162ddf}{%
           family={D'Oro},
           familyi={D\bibinitperiod},
           given={Pierluca},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9417eec56d7db4d07719bbb7fe3bcdd}{%
           family={Bacon},
           familyi={B\bibinitperiod},
           given={Pierre-Luc},
           giveni={P\bibinithyphendelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8022d4c3e28ae8c50ebf185095ebf41d}
      \strng{fullhash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \strng{bibnamehash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \strng{authorbibnamehash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \strng{authornamehash}{8022d4c3e28ae8c50ebf185095ebf41d}
      \strng{authorfullhash}{3f03d94b497bbe1b29c0e9621e0fcbd7}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This work identifies a common flaw of deep reinforcement learning (RL) algorithms: a tendency to rely on early interactions and ignore useful evidence encountered later. Because of training on progressively growing datasets, deep RL agents incur a risk of overfitting to earlier experiences, negatively affecting the rest of the learning process. Inspired by cognitive science, we refer to this effect as the primacy bias. Through a series of experiments, we dissect the algorithmic aspects of deep RL that exacerbate this bias. We then propose a simple yet generally-applicable mechanism that tackles the primacy bias by periodically resetting a part of the agent. We apply this mechanism to algorithms in both discrete (Atari 100k) and continuous action (DeepMind Control Suite) domains, consistently improving their performance.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:2205.07802}
      \field{title}{The {{Primacy Bias}} in {{Deep Reinforcement Learning}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2205.07802
      \endverb
      \verb{eprint}
      \verb 2205.07802
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/XMQV575X/Nikishin et al. - 2022 - The Primacy Bias in Deep Reinforcement Learning.pdf;/home/james/Zotero/storage/DAHTSBAK/2205.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{ding21diengine}{misc}{}
      \name{author}{9}{}{%
        {{un=0,uniquepart=base,hash=c1117e737511c234c22ce7cbfe564432}{%
           family={Niu},
           familyi={N\bibinitperiod},
           given={Yazhe},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cb35c6357d3a596bd72bb7a8e435f71e}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Jingxin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=84e9cb9612b9988e28a980a4ab11c5a1}{%
           family={Pu},
           familyi={P\bibinitperiod},
           given={Yuan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4708aed5179bfcb6bb2c78017647ea47}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Yunpeng},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cef492fa6b799c8f97ef251c948ac1ba}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jinouwen},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba5fe558cea44767f29b54183dfc1c2e}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Shuai},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=565d18193e6d0a49392d56875ec5c6be}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Liangxuan},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a56aedb5f6ad175a5340edc7bf6267e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Ming},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=93c82128aca25c57cfb17e90d02136d5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {GitHub}%
      }
      \strng{namehash}{95e834099853311376cbe6e32ac26252}
      \strng{fullhash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \strng{bibnamehash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \strng{authorbibnamehash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \strng{authornamehash}{95e834099853311376cbe6e32ac26252}
      \strng{authorfullhash}{a5d04dc19a1e9931c5b1a931b2906eb4}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{howpublished}{\url{https://github.com/opendilab/DI-engine}}
      \field{title}{DI-engine: A Universal AI System/Engine for Decision Intelligence}
      \field{year}{2021}
    \endentry
    \entry{norooziUnsupervisedLearningVisual2017}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=4c5f3dcb3d18394c66a7a0ffa25473ca}{%
           family={Noroozi},
           familyi={N\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b1d1b13c4b9716d6be01da64169529ff}{%
           family={Favaro},
           familyi={F\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{fullhash}{11055406dbc48a44a60942519a1ffe97}
      \strng{bibnamehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{authorbibnamehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{authornamehash}{11055406dbc48a44a60942519a1ffe97}
      \strng{authorfullhash}{11055406dbc48a44a60942519a1ffe97}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we study the problem of image representation learning without human annotation. By following the principles of self-supervision, we build a convolutional neural network (CNN) that can be trained to solve Jigsaw puzzles as a pretext task, which requires no manual labeling, and then later repurposed to solve object classification and detection. To maintain the compatibility across tasks we introduce the context-free network (CFN), a siamese-ennead CNN. The CFN takes image tiles as input and explicitly limits the receptive field (or context) of its early processing units to one tile at a time. We show that the CFN includes fewer parameters than AlexNet while preserving the same semantic learning capabilities. By training the CFN to solve Jigsaw puzzles, we learn both a feature mapping of object parts as well as their correct spatial arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. Our proposed method for learning visual representations outperforms state of the art methods in several transfer learning benchmarks.}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{number}{arXiv:1603.09246}
      \field{title}{Unsupervised {{Learning}} of {{Visual Representations}} by {{Solving Jigsaw Puzzles}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1603.09246
      \endverb
      \verb{eprint}
      \verb 1603.09246
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/8QF5DCGM/Noroozi and Favaro - 2017 - Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles.pdf;/home/james/Zotero/storage/2VRK26Q3/1603.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{openaiSolvingRubiksCube2019}{misc}{}
      \name{author}{19}{ul=2}{%
        {{un=0,uniquepart=base,hash=0523b13262b12c215d8009938f5c14f1}{%
           family={OpenAI},
           familyi={O\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1a2177a207bf8581bc044590f1e55602}{%
           family={Akkaya},
           familyi={A\bibinitperiod},
           given={Ilge},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d8b72cabbd1b548097b4a7b81a0f335}{%
           family={Andrychowicz},
           familyi={A\bibinitperiod},
           given={Marcin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=db785ba8e6356e7dd7e0f860f4f2f473}{%
           family={Chociej},
           familyi={C\bibinitperiod},
           given={Maciek},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e5aa3a709cbe706efba113bec9789364}{%
           family={Litwin},
           familyi={L\bibinitperiod},
           given={Mateusz},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6da1a977c02cecc78ec16c61217dcc42}{%
           family={McGrew},
           familyi={M\bibinitperiod},
           given={Bob},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d79ff0263ade6eee20336810b23e5d8}{%
           family={Petron},
           familyi={P\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=445e6e3c370e31dfc6fa4557bab7bbcb}{%
           family={Paino},
           familyi={P\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=599240d5bfe42aeb65a0c26dae77cd31}{%
           family={Plappert},
           familyi={P\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=34d0d7625e65761eaef54be0603bbf12}{%
           family={Powell},
           familyi={P\bibinitperiod},
           given={Glenn},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e91ce42053256b8eeeb6ba57772fe8b}{%
           family={Ribas},
           familyi={R\bibinitperiod},
           given={Raphael},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5167ef9d0b77bf68557730648baac9b7}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dab05157b89bd0192cb59f4386f74eda}{%
           family={Tezak},
           familyi={T\bibinitperiod},
           given={Nikolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98cbd7022a1c31a6293aa1c8b62bdebf}{%
           family={Tworek},
           familyi={T\bibinitperiod},
           given={Jerry},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=462853f8544f0acfb7014fe747f84922}{%
           family={Welinder},
           familyi={W\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=49d03d499031db786a0e61119024cf5a}{%
           family={Weng},
           familyi={W\bibinitperiod},
           given={Lilian},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a0082b934c2454295be3f0a3b138f21d}{%
           family={Yuan},
           familyi={Y\bibinitperiod},
           given={Qiming},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9fec85bbce1b087a6ebefe26e73f7bf}{%
           family={Zaremba},
           familyi={Z\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{355f5de43f091640722cd6ff601ceb66}
      \strng{fullhash}{533c7f798be0a787c8260607a2dd279a}
      \strng{bibnamehash}{533c7f798be0a787c8260607a2dd279a}
      \strng{authorbibnamehash}{533c7f798be0a787c8260607a2dd279a}
      \strng{authornamehash}{355f5de43f091640722cd6ff601ceb66}
      \strng{authorfullhash}{533c7f798be0a787c8260607a2dd279a}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We demonstrate that models trained only in simulation can be used to solve a manipulation problem of unprecedented complexity on a real robot. This is made possible by two key components: a novel algorithm, which we call automatic domain randomization (ADR) and a robot platform built for machine learning. ADR automatically generates a distribution over randomized environments of ever-increasing difficulty. Control policies and vision state estimators trained with ADR exhibit vastly improved sim2real transfer. For control policies, memory-augmented models trained on an ADR-generated distribution of environments show clear signs of emergent meta-learning at test time. The combination of ADR with our custom robot platform allows us to solve a Rubik's cube with a humanoid robot hand, which involves both control and state estimation problems. Videos summarizing our results are available: https://openai.com/blog/solving-rubiks-cube/}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1910.07113}
      \field{title}{Solving {{Rubik}}'s {{Cube}} with a {{Robot Hand}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1910.07113
      \endverb
      \verb{eprint}
      \verb 1910.07113
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/9JFJ5HT9/OpenAI et al. - 2019 - Solving Rubik's Cube with a Robot Hand.pdf;/home/james/Zotero/storage/523N9S2W/1910.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{openaiDota2Large2019}{misc}{}
      \name{author}{26}{ul=2}{%
        {{un=0,uniquepart=base,hash=0523b13262b12c215d8009938f5c14f1}{%
           family={OpenAI},
           familyi={O\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ca86811e7a0582a9e7cb8d33e7ab445d}{%
           family={Berner},
           familyi={B\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ae2a0efeaf9c031f9b420bcb1c19e54}{%
           family={Brockman},
           familyi={B\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bdcc84061540e15aac439cba59db6577}{%
           family={Chan},
           familyi={C\bibinitperiod},
           given={Brooke},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ece7baf9b320c51ead8e24c1c6386dbf}{%
           family={Cheung},
           familyi={C\bibinitperiod},
           given={Vicki},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5b9ef873a5cb802b4a76be3508f175b4}{%
           family={DÄbiak},
           familyi={D\bibinitperiod},
           given={Przemys{Å}aw},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a509b9c62a0e81a58991a81caf48298d}{%
           family={Dennison},
           familyi={D\bibinitperiod},
           given={Christy},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a562eb10ac2870de64b3956df2eb1896}{%
           family={Farhi},
           familyi={F\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9077a5599d2a4f3aa8bb20cef3b6399a}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Quirin},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=49e2023e4e856577f61450fc5149743d}{%
           family={Hashme},
           familyi={H\bibinitperiod},
           given={Shariq},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07acc23f6ec051b64b82cd33255c0a69}{%
           family={Hesse},
           familyi={H\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4eda39963a95c233a262d4191f198aa4}{%
           family={JÃ³zefowicz},
           familyi={J\bibinitperiod},
           given={Rafal},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7006ca8c1ce969019b89de50fece60dd}{%
           family={Gray},
           familyi={G\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd24844b3abaa88e1f3c5c074ad37ab6}{%
           family={Olsson},
           familyi={O\bibinitperiod},
           given={Catherine},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=27d3d977b77156237cdeb5a7b7eaa560}{%
           family={Pachocki},
           familyi={P\bibinitperiod},
           given={Jakub},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=20bb006267a99bf6b2419ac00ec8decb}{%
           family={Petrov},
           familyi={P\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f78abae164f9e9364dd3e0b31887fc08}{%
           family={Pinto},
           familyi={P\bibinitperiod},
           given={Henrique\bibnamedelimb P.\bibnamedelimi d\bibnamedelima O.},
           giveni={H\bibinitperiod\bibinitdelim P\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9db43b2d2fa0f38a4051782eb9de8f87}{%
           family={Raiman},
           familyi={R\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e6f76e1a4d058df028530916774ad3a7}{%
           family={Salimans},
           familyi={S\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e3e581a0808055d754222c3b47b3a7ab}{%
           family={Schlatter},
           familyi={S\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5167ef9d0b77bf68557730648baac9b7}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6657859de18e844e4b1b815e03694c71}{%
           family={Sidor},
           familyi={S\bibinitperiod},
           given={Szymon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d0b3008e85b1a8b38f46556abf1791c7}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=674ede0b9cd02a2bf5fc662972efb9f0}{%
           family={Wolski},
           familyi={W\bibinitperiod},
           given={Filip},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24b5bdd4e149e4c9ed111f6051192cf8}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Susan},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{606c0d1e1c67347217f8584145d77188}
      \strng{fullhash}{b846e5ad21999608d85108783d48f2a5}
      \strng{bibnamehash}{606c0d1e1c67347217f8584145d77188}
      \strng{authorbibnamehash}{606c0d1e1c67347217f8584145d77188}
      \strng{authornamehash}{606c0d1e1c67347217f8584145d77188}
      \strng{authorfullhash}{b846e5ad21999608d85108783d48f2a5}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{On April 13th, 2019, OpenAI Five became the first AI system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for AI systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable AI systems. OpenAI Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG), OpenAI Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1912.06680}
      \field{title}{Dota 2 with {{Large Scale Deep Reinforcement Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.06680
      \endverb
      \verb{eprint}
      \verb 1912.06680
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/OpenAI et al_2019_Dota 2 with Large Scale Deep Reinforcement Learning.pdf;/home/james/Zotero/storage/HFQR3FB9/1912.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{ouyangTrainingLanguageModels2022}{article}{}
      \name{author}{20}{}{%
        {{un=0,uniquepart=base,hash=6e3708cf33f22d79419d7e79124060a8}{%
           family={Ouyang},
           familyi={O\bibinitperiod},
           given={Long},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=495187f3a2c93ddb8083bd18a5702527}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jeffrey},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=214803c09eda269a0ed928d7e5a93461}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Xu},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a7cf026a14a6ceae41b01945420f7d80}{%
           family={Almeida},
           familyi={A\bibinitperiod},
           given={Diogo},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=19714834684eddb04464454a907483b2}{%
           family={Wainwright},
           familyi={W\bibinitperiod},
           given={Carroll},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2321e04943bcadb0275819652b980521}{%
           family={Mishkin},
           familyi={M\bibinitperiod},
           given={Pamela},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6396eaa69e1c798e2c8c503e9ce9067b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Chong},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=abe4801e322e893b23785fd6d0800b5c}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Sandhini},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=57e47da21cfc9e3fa6c754e47b5adcab}{%
           family={Slama},
           familyi={S\bibinitperiod},
           given={Katarina},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=71db9ce8a56e89a1f139670448d55a10}{%
           family={Gray},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9e4edc142b0564cbbb1cf93a401e4434}{%
           family={Hilton},
           familyi={H\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2782098fc110938b6feb76048e568328}{%
           family={Kelton},
           familyi={K\bibinitperiod},
           given={Fraser},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ca6c3bdfd65467cd39e6dc08a0410e65}{%
           family={Miller},
           familyi={M\bibinitperiod},
           given={Luke},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7f5d4524691b522e78f555d453d9b786}{%
           family={Simens},
           familyi={S\bibinitperiod},
           given={Maddie},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e84eff933be9f4887bf369cf181bf12}{%
           family={Askell},
           familyi={A\bibinitperiod},
           given={Amanda},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=462853f8544f0acfb7014fe747f84922}{%
           family={Welinder},
           familyi={W\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cffdbdf7d0beb981d8bb8ea28506a4b2}{%
           family={Christiano},
           familyi={C\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cc754f0620be1073909db48780f1da4d}{%
           family={Leike},
           familyi={L\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7be01fa6277ef22b804ff6cc54c87b72}{%
           family={Lowe},
           familyi={L\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{13d52a5bcb04f48fa855da0c9fb052de}
      \strng{fullhash}{983d5b455a45a1d549eea6ee7ffc45be}
      \strng{bibnamehash}{983d5b455a45a1d549eea6ee7ffc45be}
      \strng{authorbibnamehash}{983d5b455a45a1d549eea6ee7ffc45be}
      \strng{authornamehash}{13d52a5bcb04f48fa855da0c9fb052de}
      \strng{authorfullhash}{983d5b455a45a1d549eea6ee7ffc45be}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.}
      \field{journaltitle}{Advances in {{Neural Information Processing Systems}}}
      \field{langid}{english}
      \field{month}{10}
      \field{title}{Training Language Models to Follow Instructions with Human Feedback}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb /home/james/Zotero/storage/KQCF6BYN/Ouyang et al. - 2022 - Training language models to follow instructions with human feedback.pdf
      \endverb
    \endentry
    \entry{paszkePyTorchImperativeStyle2019}{misc}{}
      \name{author}{21}{}{%
        {{un=0,uniquepart=base,hash=56bf0b340039cf8594436a624ff548a9}{%
           family={Paszke},
           familyi={P\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4ba5062e5919c814aceec188d54c01f2}{%
           family={Gross},
           familyi={G\bibinitperiod},
           given={Sam},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e5dfae4582081d649e3a0d5342050016}{%
           family={Massa},
           familyi={M\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b5815e1692fa2d0c1f44eecf509bd7c4}{%
           family={Lerer},
           familyi={L\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b75383e6b48c8360c7a60031424c85cf}{%
           family={Bradbury},
           familyi={B\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f897ed422c34d95af2e22778dfc2607e}{%
           family={Chanan},
           familyi={C\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=046269e070246feb6f394141db80ed87}{%
           family={Killeen},
           familyi={K\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c40352c194e60a3ef458ee7e8685afb5}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Zeming},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6e45f49ec618e619efad90c8e8a61f0c}{%
           family={Gimelshein},
           familyi={G\bibinitperiod},
           given={Natalia},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f65a80959d520337ae99a0798515036c}{%
           family={Antiga},
           familyi={A\bibinitperiod},
           given={Luca},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=954cf7680b6ce14813973eccdca3c4bc}{%
           family={Desmaison},
           familyi={D\bibinitperiod},
           given={Alban},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=048232cf7c525fbc0bc93052fe8cee03}{%
           family={KÃ¶pf},
           familyi={K\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9e701339e56fd0b171145b08288a1b7}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=42ac264897098b400e1367e5922c9b0d}{%
           family={DeVito},
           familyi={D\bibinitperiod},
           given={Zach},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d814afaa50b9e22ab92cc9f8f9a9e43a}{%
           family={Raison},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3feeeebee8583ecc208f7fb3e0a55068}{%
           family={Tejani},
           familyi={T\bibinitperiod},
           given={Alykhan},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e18536d5cb7543731fbf2ca1a4908732}{%
           family={Chilamkurthy},
           familyi={C\bibinitperiod},
           given={Sasank},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0a0b028c6b85c46f368317d0c5bfe3a0}{%
           family={Steiner},
           familyi={S\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=998a001f16bb57c079c1d5afb1cb02c8}{%
           family={Fang},
           familyi={F\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3f19c633bbfb847db6a0e71d3659eacd}{%
           family={Bai},
           familyi={B\bibinitperiod},
           given={Junjie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8ef51a0906e47d2b4472c4e714ed598f}{%
           family={Chintala},
           familyi={C\bibinitperiod},
           given={Soumith},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{fullhash}{4842db6c92a33147f588935fdde44a69}
      \strng{bibnamehash}{c4467cc24b68e421171e0cfd2dcbf915}
      \strng{authorbibnamehash}{c4467cc24b68e421171e0cfd2dcbf915}
      \strng{authornamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authorfullhash}{4842db6c92a33147f588935fdde44a69}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1912.01703}
      \field{shorttitle}{{{PyTorch}}}
      \field{title}{{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.01703
      \endverb
      \verb{eprint}
      \verb 1912.01703
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/9NN95CNL/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Deep Learning Library.pdf;/home/james/Zotero/storage/2R5WC9HL/1912.html
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Mathematical Software,Statistics - Machine Learning}
    \endentry
    \entry{pinedaMBRLLibModularLibrary2021}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=2fd46563677f95093c3df0d7e7be2416}{%
           family={Pineda},
           familyi={P\bibinitperiod},
           given={Luis},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=783779089b4b78ed86b990f3397d0abb}{%
           family={Amos},
           familyi={A\bibinitperiod},
           given={Brandon},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=23d26cc1e55ad87341af3cb88c607c6c}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Amy},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1bf4f76887e5e25f45f673cf5fea0f9c}{%
           family={Lambert},
           familyi={L\bibinitperiod},
           given={Nathan\bibnamedelima O.},
           giveni={N\bibinitperiod\bibinitdelim O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=864584c60b808b517f2a06c664ec116a}{%
           family={Calandra},
           familyi={C\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{d6cf657552ae065d14dd1098c23d0bc3}
      \strng{fullhash}{9509b565122593d122e8915396196373}
      \strng{bibnamehash}{9509b565122593d122e8915396196373}
      \strng{authorbibnamehash}{9509b565122593d122e8915396196373}
      \strng{authornamehash}{d6cf657552ae065d14dd1098c23d0bc3}
      \strng{authorfullhash}{9509b565122593d122e8915396196373}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Model-based reinforcement learning is a compelling framework for data-efficient learning of agents that interact with the world. This family of algorithms has many subcomponents that need to be carefully selected and tuned. As a result the entry-bar for researchers to approach the field and to deploy it in real-world tasks can be daunting. In this paper, we present MBRL-Lib -- a machine learning library for model-based reinforcement learning in continuous state-action spaces based on PyTorch. MBRL-Lib is designed as a platform for both researchers, to easily develop, debug and compare new algorithms, and non-expert user, to lower the entry-bar of deploying state-of-the-art algorithms. MBRL-Lib is open-source at https://github.com/facebookresearch/mbrl-lib.}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:2104.10159}
      \field{shorttitle}{{{MBRL-Lib}}}
      \field{title}{{{MBRL-Lib}}: {{A Modular Library}} for {{Model-based Reinforcement Learning}}}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2104.10159
      \endverb
      \verb{eprint}
      \verb 2104.10159
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/UAF48PXV/Pineda et al. - 2021 - MBRL-Lib A Modular Library for Model-based Reinforcement Learning.pdf;/home/james/Zotero/storage/UPVHFRVI/2104.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control}
    \endentry
    \entry{robineTransformerbasedWorldModels2023}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=8251012c149d8023d80a2bbe6c0d9065}{%
           family={Robine},
           familyi={R\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=db73803c2cf851a4fa23eb24338e8b25}{%
           family={HÃ¶ftmann},
           familyi={H\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e90b27b526070b70451012ee1d68881}{%
           family={Uelwer},
           familyi={U\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b89ff3ea3d3957658253d2b707e09867}{%
           family={Harmeling},
           familyi={H\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{468c24caa94095dd4aa463cae9a801ae}
      \strng{fullhash}{6dd66a07e03e74098b252222b90bec3a}
      \strng{bibnamehash}{6dd66a07e03e74098b252222b90bec3a}
      \strng{authorbibnamehash}{6dd66a07e03e74098b252222b90bec3a}
      \strng{authornamehash}{468c24caa94095dd4aa463cae9a801ae}
      \strng{authorfullhash}{6dd66a07e03e74098b252222b90bec3a}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep neural networks have been successful in many reinforcement learning settings. However, compared to human learners they are overly data hungry. To build a sample-efficient world model, we apply a transformer to real-world episodes in an autoregressive manner: not only the compact latent states and the taken actions but also the experienced or predicted rewards are fed into the transformer, so that it can attend flexibly to all three modalities at different time steps. The transformer allows our world model to access previous states directly, instead of viewing them through a compressed recurrent state. By utilizing the Transformer-XL architecture, it is able to learn long-term dependencies while staying computationally efficient. Our transformer-based world model (TWM) generates meaningful, new experience, which is used to train a policy that outperforms previous model-free and model-based reinforcement learning algorithms on the Atari 100k benchmark.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:2303.07109}
      \field{title}{Transformer-Based {{World Models Are Happy With}} 100k {{Interactions}}}
      \field{urlday}{27}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2303.07109
      \endverb
      \verb{eprint}
      \verb 2303.07109
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/GVIXCBHN/Robine et al. - 2023 - Transformer-based World Models Are Happy With 100k Interactions.pdf;/home/james/Zotero/storage/KHNZK8JZ/2303.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{schaulPrioritizedExperienceReplay2016}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d1c6b8444cb95e400ca38d5ae5c5afd3}{%
           family={Quan},
           familyi={Q\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{04a0db021533adedf96ff47bc975d01a}
      \strng{fullhash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \strng{bibnamehash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \strng{authorbibnamehash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \strng{authornamehash}{04a0db021533adedf96ff47bc975d01a}
      \strng{authorfullhash}{cf83dab6b2af35a31aaeaaf1c6f70196}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{number}{arXiv:1511.05952}
      \field{title}{Prioritized {{Experience Replay}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1511.05952
      \endverb
      \verb{eprint}
      \verb 1511.05952
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/CHFNRVNH/Schaul et al. - 2016 - Prioritized Experience Replay.pdf;/home/james/Zotero/storage/J4MBXBBX/1511.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schmidtFastDataEfficientTraining2021}{misc}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=317ec33d3bf8a1ad361e079b7606ea9c}{%
           family={Schmidt},
           familyi={S\bibinitperiod},
           given={Dominik},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e6f284000b7dde020f33730affa8dd7b}{%
           family={Schmied},
           familyi={S\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{fullhash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{bibnamehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{authorbibnamehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{authornamehash}{80b76867f1f54a47af6f13e4ac55ae79}
      \strng{authorfullhash}{80b76867f1f54a47af6f13e4ac55ae79}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Across the Arcade Learning Environment, Rainbow achieves a level of performance competitive with humans and modern RL algorithms. However, attaining this level of performance requires large amounts of data and hardware resources, making research in this area computationally expensive and use in practical applications often infeasible. This paper's contribution is threefold: We (1) propose an improved version of Rainbow, seeking to drastically reduce Rainbow's data, training time, and compute requirements while maintaining its competitive performance; (2) we empirically demonstrate the effectiveness of our approach through experiments on the Arcade Learning Environment, and (3) we conduct a number of ablation studies to investigate the effect of the individual proposed modifications. Our improved version of Rainbow reaches a median human normalized score close to classic Rainbow's, while using 20 times less data and requiring only 7.5 hours of training time on a single GPU. We also provide our full implementation including pre-trained models.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2111.10247}
      \field{shorttitle}{Fast and {{Data-Efficient Training}} of {{Rainbow}}}
      \field{title}{Fast and {{Data-Efficient Training}} of {{Rainbow}}: An {{Experimental Study}} on {{Atari}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2111.10247
      \endverb
      \verb{eprint}
      \verb 2111.10247
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schmidt_Schmied_2021_Fast and Data-Efficient Training of Rainbow.pdf;/home/james/Zotero/storage/M74K5ABX/2111.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schrittwieserMasteringAtariGo2020}{article}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=8fad8df927bc0014c0bd6a9feb7aa71d}{%
           family={Schrittwieser},
           familyi={S\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80c63e95a9e243591a33a7e3156f1d78}{%
           family={Hubert},
           familyi={H\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d16b7284df92c9adaee86c37ab992df}{%
           family={Simonyan},
           familyi={S\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50d24de916599d306c5cb1a77156e4b9}{%
           family={Sifre},
           familyi={S\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80f59bf87c57eee7dab96e04c0a83c30}{%
           family={Schmitt},
           familyi={S\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=67c36471603b6de0347c489b0f8b05b0}{%
           family={Lockhart},
           familyi={L\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=368b9b2de627b852658c433b062d4e1e}{%
           family={Graepel},
           familyi={G\bibinitperiod},
           given={Thore},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ba8dd9d821587916ffa0d5d85ba62066}
      \strng{fullhash}{a2393dd56fc0d1677b29875d3184f845}
      \strng{bibnamehash}{a2393dd56fc0d1677b29875d3184f845}
      \strng{authorbibnamehash}{a2393dd56fc0d1677b29875d3184f845}
      \strng{authornamehash}{ba8dd9d821587916ffa0d5d85ba62066}
      \strng{authorfullhash}{a2393dd56fc0d1677b29875d3184f845}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{issn}{0028-0836, 1476-4687}
      \field{journaltitle}{Nature}
      \field{month}{12}
      \field{number}{7839}
      \field{title}{Mastering {{Atari}}, {{Go}}, {{Chess}} and {{Shogi}} by {{Planning}} with a {{Learned Model}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{volume}{588}
      \field{year}{2020}
      \field{urldateera}{ce}
      \field{pages}{604\bibrangedash 609}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1038/s41586-020-03051-4
      \endverb
      \verb{eprint}
      \verb 1911.08265
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schrittwieser et al_2020_Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf;/home/james/Zotero/storage/XRX7QTMG/1911.html
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{schroffFaceNetUnifiedEmbedding2015}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=c62e96f68033a3d3cd4639e35a2de4da}{%
           family={Schroff},
           familyi={S\bibinitperiod},
           given={Florian},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6cbb997a11c6922af719c32863261918}{%
           family={Kalenichenko},
           familyi={K\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e9a1d678032dfffb4e871a0f622e030}{%
           family={Philbin},
           familyi={P\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{5eafdb6c00f832f72d64a3a8c5e2fa1c}
      \strng{fullhash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \strng{bibnamehash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \strng{authorbibnamehash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \strng{authornamehash}{5eafdb6c00f832f72d64a3a8c5e2fa1c}
      \strng{authorfullhash}{474363fec59aa6cdd11f5b6b8275a8f2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63\%. On YouTube Faces DB it achieves 95.12\%. Our system cuts the error rate in comparison to the best published result by 30\% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1503.03832}
      \field{shorttitle}{{{FaceNet}}}
      \field{title}{{{FaceNet}}: {{A Unified Embedding}} for {{Face Recognition}} and {{Clustering}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1503.03832
      \endverb
      \verb{eprint}
      \verb 1503.03832
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/SEE6IFHK/Schroff et al. - 2015 - FaceNet A Unified Embedding for Face Recognition and Clustering.pdf;/home/james/Zotero/storage/IPCU2YUA/1503.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{schulmanTrustRegionPolicy2017}{misc}{}
      \name{author}{5}{ul=2}{%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a901fd78fe1108cfa7d11129644967c7}{%
           family={Moritz},
           familyi={M\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8a36116840c7ee55901618c95fd08a58}{%
           family={Jordan},
           familyi={J\bibinitperiod},
           given={Michael\bibnamedelima I.},
           giveni={M\bibinitperiod\bibinitdelim I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{4290bc9e05fb16d946cdb7a6a222296e}
      \strng{fullhash}{945251de1d41bc2767a541a8148f51da}
      \strng{bibnamehash}{945251de1d41bc2767a541a8148f51da}
      \strng{authorbibnamehash}{945251de1d41bc2767a541a8148f51da}
      \strng{authornamehash}{4290bc9e05fb16d946cdb7a6a222296e}
      \strng{authorfullhash}{945251de1d41bc2767a541a8148f51da}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:1502.05477}
      \field{title}{Trust {{Region Policy Optimization}}}
      \field{urlday}{2}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1502.05477
      \endverb
      \verb{eprint}
      \verb 1502.05477
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schulman et al_2017_Trust Region Policy Optimization.pdf;/home/james/Zotero/storage/Y28SL8PZ/1502.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schulmanHighDimensionalContinuousControl2018}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a901fd78fe1108cfa7d11129644967c7}{%
           family={Moritz},
           familyi={M\bibinitperiod},
           given={Philipp},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5010abb47d34a51acdafb266a811dc5f}{%
           family={Jordan},
           familyi={J\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8d6613ae59595910252a86a61babf6c8}
      \strng{fullhash}{824be54bbf358cb68164f9e82cccbd21}
      \strng{bibnamehash}{824be54bbf358cb68164f9e82cccbd21}
      \strng{authorbibnamehash}{824be54bbf358cb68164f9e82cccbd21}
      \strng{authornamehash}{8d6613ae59595910252a86a61babf6c8}
      \strng{authorfullhash}{824be54bbf358cb68164f9e82cccbd21}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1506.02438}
      \field{title}{High-{{Dimensional Continuous Control Using Generalized Advantage Estimation}}}
      \field{urlday}{23}
      \field{urlmonth}{7}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1506.02438
      \endverb
      \verb{eprint}
      \verb 1506.02438
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schulman et al_2018_High-Dimensional Continuous Control Using Generalized Advantage Estimation.pdf;/home/james/Zotero/storage/WVY9PNF9/1506.html
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control}
    \endentry
    \entry{schulmanProximalPolicyOptimization2017}{misc}{}
      \name{author}{5}{ul=2}{%
        {{un=0,uniquepart=base,hash=3e09bd2a25d237ebdaed560a07c0451e}{%
           family={Schulman},
           familyi={S\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=674ede0b9cd02a2bf5fc662972efb9f0}{%
           family={Wolski},
           familyi={W\bibinitperiod},
           given={Filip},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4164e43d8cf919f5e3f8d80f5ea23f36}{%
           family={Dhariwal},
           familyi={D\bibinitperiod},
           given={Prafulla},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a812c46caad94fc8701be37871f303ba}{%
           family={Radford},
           familyi={R\bibinitperiod},
           given={Alec},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be38507da6ab98e7ac01ac2c6b7e13eb}{%
           family={Klimov},
           familyi={K\bibinitperiod},
           given={Oleg},
           giveni={O\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{f85997ca29b89a9a0cc61ebadb2cd7fe}
      \strng{fullhash}{a6c6ed5a5aeb74e536f16291276ae392}
      \strng{bibnamehash}{a6c6ed5a5aeb74e536f16291276ae392}
      \strng{authorbibnamehash}{a6c6ed5a5aeb74e536f16291276ae392}
      \strng{authornamehash}{f85997ca29b89a9a0cc61ebadb2cd7fe}
      \strng{authorfullhash}{a6c6ed5a5aeb74e536f16291276ae392}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{number}{arXiv:1707.06347}
      \field{title}{Proximal {{Policy Optimization Algorithms}}}
      \field{urlday}{2}
      \field{urlmonth}{5}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1707.06347
      \endverb
      \verb{eprint}
      \verb 1707.06347
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schulman et al_2017_Proximal Policy Optimization Algorithms.pdf;/home/james/Zotero/storage/4AW5IADX/1707.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{schwarzerDataEfficientReinforcementLearning2021}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9c04884349329f54db6669b03ab4d4a}{%
           family={Anand},
           familyi={A\bibinitperiod},
           given={Ankesh},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bb9d1ac8dcc19d49d5d79ec9bf11464a}{%
           family={Goel},
           familyi={G\bibinitperiod},
           given={Rishab},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=68d18c6f3387bc203910c98ed4e1303c}{%
           family={Hjelm},
           familyi={H\bibinitperiod},
           given={R.\bibnamedelimi Devon},
           giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=799d66480d783672ee2f29b7fb418229}{%
           family={Bachman},
           familyi={B\bibinitperiod},
           given={Philip},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{fullhash}{50236f5c9d7cf94f939da49ade6852df}
      \strng{bibnamehash}{50236f5c9d7cf94f939da49ade6852df}
      \strng{authorbibnamehash}{50236f5c9d7cf94f939da49ade6852df}
      \strng{authornamehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{authorfullhash}{50236f5c9d7cf94f939da49ade6852df}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While deep reinforcement learning excels at solving tasks where large amounts of data can be collected through virtually unlimited interaction with the environment, learning from limited interaction remains a key challenge. We posit that an agent can learn more efficiently if we augment reward maximization with self-supervised objectives based on structure in its visual input and sequential interaction with the environment. Our method, Self-Predictive Representations(SPR), trains an agent to predict its own latent state representations multiple steps into the future. We compute target representations for future states using an encoder which is an exponential moving average of the agent's parameters and we make predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. We further improve performance by adding data augmentation to the future prediction loss, which forces the agent's representations to be consistent across multiple views of an observation. Our full self-supervised objective, which combines future prediction and data augmentation, achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55\% relative improvement over the previous state-of-the-art. Notably, even in this limited data regime, SPR exceeds expert human scores on 7 out of 26 games. The code associated with this work is available at https://github.com/mila-iqia/spr}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:2007.05929}
      \field{title}{Data-{{Efficient Reinforcement Learning}} with {{Self-Predictive Representations}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2007.05929
      \endverb
      \verb{eprint}
      \verb 2007.05929
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Schwarzer et al_2021_Data-Efficient Reinforcement Learning with Self-Predictive Representations.pdf;/home/james/Zotero/storage/CJ3N5GZP/2007.html
      \endverb
      \keyw{Computer Science - Machine Learning,Data-efficient RL,Statistics - Machine Learning}
    \endentry
    \entry{schwarzerBiggerBetterFaster2023}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=5e724d9aa88c5bd77b7e95a500cd9ec3}{%
           family={Schwarzer},
           familyi={S\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31615496c3b6b2cb98ee532481ce05bd}{%
           family={{Obando-Ceron}},
           familyi={O\bibinitperiod},
           given={Johan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c381224f01b0b3e0e463075180d66906}{%
           family={Bellemare},
           familyi={B\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a3ce7bf5b3d6fcc96d09f5142950dd8d}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Rishabh},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd36c2abe3c5c9ea4b21e5258e5f3a37}{%
           family={Castro},
           familyi={C\bibinitperiod},
           given={Pablo\bibnamedelima Samuel},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{fullhash}{592a3526df4ec2a34afa18b5d01c3d32}
      \strng{bibnamehash}{592a3526df4ec2a34afa18b5d01c3d32}
      \strng{authorbibnamehash}{592a3526df4ec2a34afa18b5d01c3d32}
      \strng{authornamehash}{1c32db7b54e96fe956ac41dbc76038d8}
      \strng{authorfullhash}{592a3526df4ec2a34afa18b5d01c3d32}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark. BBF relies on scaling the neural networks used for value estimation, as well as a number of other design choices that enable this scaling in a sample-efficient manner. We conduct extensive analyses of these design choices and provide insights for future work. We end with a discussion about updating the goalposts for sample-efficient RL research on the ALE. We make our code and data publicly available at https://github.com/google-research/google-research/tree/master/bigger\_better\_faster.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2305.19452}
      \field{shorttitle}{Bigger, {{Better}}, {{Faster}}}
      \field{title}{Bigger, {{Better}}, {{Faster}}: {{Human-level Atari}} with Human-Level Efficiency}
      \field{urlday}{1}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2305.19452
      \endverb
      \verb{eprint}
      \verb 2305.19452
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/4UIE9QDK/Schwarzer et al. - 2023 - Bigger, Better, Faster Human-level Atari with hum.pdf;/home/james/Zotero/storage/5F7DCQN3/2305.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{sekarPlanningExploreSelfSupervised2020}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=897066b1efdb6d7ca706f9af32d3ac00}{%
           family={Sekar},
           familyi={S\bibinitperiod},
           given={Ramanan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5e74881acde81e3e0bbe845cc98697ce}{%
           family={Rybkin},
           familyi={R\bibinitperiod},
           given={Oleh},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=26789faf98e6ba54553cd620a8da71b2}{%
           family={Daniilidis},
           familyi={D\bibinitperiod},
           given={Kostas},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=09e431093c8637ade01037714cfc992c}{%
           family={Pathak},
           familyi={P\bibinitperiod},
           given={Deepak},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{fbe527297def415bbc47ffc645aaea1b}
      \strng{fullhash}{f55028c18aad16ec28e8f83cd0b15e67}
      \strng{bibnamehash}{f55028c18aad16ec28e8f83cd0b15e67}
      \strng{authorbibnamehash}{f55028c18aad16ec28e8f83cd0b15e67}
      \strng{authornamehash}{fbe527297def415bbc47ffc645aaea1b}
      \strng{authorfullhash}{f55028c18aad16ec28e8f83cd0b15e67}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Reinforcement learning allows solving complex tasks, however, the learning tends to be task-specific and the sample efficiency remains a challenge. We present Plan2Explore, a self-supervised reinforcement learning agent that tackles both these challenges through a new approach to self-supervised exploration and fast adaptation to new tasks, which need not be known during exploration. During exploration, unlike prior methods which retrospectively compute the novelty of observations after the agent has already reached them, our agent acts efficiently by leveraging planning to seek out expected future novelty. After exploration, the agent quickly adapts to multiple downstream tasks in a zero or a few-shot manner. We evaluate on challenging control tasks from high-dimensional image inputs. Without any training supervision or task-specific interaction, Plan2Explore outperforms prior self-supervised exploration methods, and in fact, almost matches the performances oracle which has access to rewards. Videos and code at https://ramanans1.github.io/plan2explore/}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:2005.05960}
      \field{title}{Planning to {{Explore}} via {{Self-Supervised World Models}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2005.05960
      \endverb
      \verb{eprint}
      \verb 2005.05960
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Sekar et al_2020_Planning to Explore via Self-Supervised World Models.pdf;/home/james/Zotero/storage/4BR97L5S/2005.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics,Statistics - Machine Learning}
    \endentry
    \entry{seoMaskedWorldModels2022}{misc}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=ae0ec5c679a01d9aa465ab4c6bd223e8}{%
           family={Seo},
           familyi={S\bibinitperiod},
           given={Younggyo},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a1d86e250a782086160211ed8814f06}{%
           family={Hafner},
           familyi={H\bibinitperiod},
           given={Danijar},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33104fd0f457a2964af323817a9d2016}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ad0d24bb008c9b37c59a3279f34cd576}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Fangchen},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d0930396d05237554ef2822bdaa7991}{%
           family={James},
           familyi={J\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a74a7d6a839e48de367e41b7ec29d456}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kimin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8c8e07ad88393070efdc5901bf9676fe}
      \strng{fullhash}{b8129dad0a66bd6a468e2ca397eb7718}
      \strng{bibnamehash}{b8129dad0a66bd6a468e2ca397eb7718}
      \strng{authorbibnamehash}{b8129dad0a66bd6a468e2ca397eb7718}
      \strng{authornamehash}{8c8e07ad88393070efdc5901bf9676fe}
      \strng{authorfullhash}{b8129dad0a66bd6a468e2ca397eb7718}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Visual model-based reinforcement learning (RL) has the potential to enable sample-efficient robot learning from visual observations. Yet the current approaches typically train a single model end-to-end for learning both visual representations and dynamics, making it difficult to accurately model the interaction between robots and small objects. In this work, we introduce a visual model-based RL framework that decouples visual representation learning and dynamics learning. Specifically, we train an autoencoder with convolutional layers and vision transformers (ViT) to reconstruct pixels given masked convolutional features, and learn a latent dynamics model that operates on the representations from the autoencoder. Moreover, to encode task-relevant information, we introduce an auxiliary reward prediction objective for the autoencoder. We continually update both autoencoder and dynamics model using online samples collected from environment interaction. We demonstrate that our decoupling approach achieves state-of-the-art performance on a variety of visual robotic tasks from Meta-world and RLBench, e.g., we achieve 81.7\% success rate on 50 visual robotic manipulation tasks from Meta-world, while the baseline achieves 67.9\%. Code is available on the project website: https://sites.google.com/view/mwm-rl.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{number}{arXiv:2206.14244}
      \field{title}{Masked {{World Models}} for {{Visual Control}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2206.14244
      \endverb
      \verb{eprint}
      \verb 2206.14244
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Seo et al_2022_Masked World Models for Visual Control.pdf;/home/james/Zotero/storage/PNWMPJVN/2206.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{silverMasteringGameGo2016}{article}{}
      \name{author}{20}{}{%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba4b200ce1412a2570cb113366cc9559}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Aja},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c3126321fcb4553dfda5ae96da928ce}{%
           family={Maddison},
           familyi={M\bibinitperiod},
           given={Chris\bibnamedelima J.},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50d24de916599d306c5cb1a77156e4b9}{%
           family={Sifre},
           familyi={S\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=65eeec6e3586f64c853c49d82d697609}{%
           family={{van den Driessche}},
           familyi={v\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8fad8df927bc0014c0bd6a9feb7aa71d}{%
           family={Schrittwieser},
           familyi={S\bibinitperiod},
           given={Julian},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1f065703a4f7a60c69ecb59f499d3db3}{%
           family={Panneershelvam},
           familyi={P\bibinitperiod},
           given={Veda},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3075d0e02c0833f6e5fe1addb880898f}{%
           family={Lanctot},
           familyi={L\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a133b469b21b870786119a47b1b691eb}{%
           family={Dieleman},
           familyi={D\bibinitperiod},
           given={Sander},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c19e654fe7f97a2862b0f06588d04c42}{%
           family={Grewe},
           familyi={G\bibinitperiod},
           given={Dominik},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5560aef5a586c04b85130c3be44a3b6a}{%
           family={Nham},
           familyi={N\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d2d0778c1cdd451c75b874b58eec7564}{%
           family={Kalchbrenner},
           familyi={K\bibinitperiod},
           given={Nal},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=958e13979b3920f7fb4793ed8dddcb33}{%
           family={Leach},
           familyi={L\bibinitperiod},
           given={Madeleine},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=368b9b2de627b852658c433b062d4e1e}{%
           family={Graepel},
           familyi={G\bibinitperiod},
           given={Thore},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Nature Publishing Group}%
      }
      \strng{namehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{fullhash}{a04d588961aa93c7ef28f0e5175e82f7}
      \strng{bibnamehash}{a04d588961aa93c7ef28f0e5175e82f7}
      \strng{authorbibnamehash}{a04d588961aa93c7ef28f0e5175e82f7}
      \strng{authornamehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{authorfullhash}{a04d588961aa93c7ef28f0e5175e82f7}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks' to evaluate board positions and `policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{7587}
      \field{title}{Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search}
      \field{urlday}{23}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{529}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{484\bibrangedash 489}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1038/nature16961
      \endverb
      \keyw{Computational science,Computer science,Reward}
    \endentry
    \entry{silverPredictronEndToEndLearning2017}{misc}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f5a8983bab24d2cd5670100e485fc883}{%
           family={Hasselt},
           familyi={H\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0,
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b63b9b2d91f6ba1b1739563edc0432ab}{%
           family={Harley},
           familyi={H\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1e75a9df444c5ef79ce4db4c8dd76ddc}{%
           family={{Dulac-Arnold}},
           familyi={D\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ff36bcecacbac6382f6f3048b316d708}{%
           family={Reichert},
           familyi={R\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d4fe8a888824c1acfd5345200ddc5f9b}{%
           family={Rabinowitz},
           familyi={R\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c53eb4a374df4bfac9e88c6cd01fa57d}{%
           family={Barreto},
           familyi={B\bibinitperiod},
           given={Andre},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6598b6ed3c197bb4292561d14d01436f}{%
           family={Degris},
           familyi={D\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{fullhash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \strng{bibnamehash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \strng{authorbibnamehash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \strng{authornamehash}{4ccacac34637df06f749428b6ec5052e}
      \strng{authorfullhash}{55ada5c136139d4731c1e4cf3a0dd40d}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{One of the key challenges of artificial intelligence is to learn models that are effective in the context of planning. In this document we introduce the predictron architecture. The predictron consists of a fully abstract model, represented by a Markov reward process, that can be rolled forward multiple "imagined" planning steps. Each forward pass of the predictron accumulates internal rewards and values over multiple planning depths. The predictron is trained end-to-end so as to make these accumulated values accurately approximate the true value function. We applied the predictron to procedurally generated random mazes and a simulator for the game of pool. The predictron yielded significantly more accurate predictions than conventional deep neural network architectures.}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:1612.08810}
      \field{shorttitle}{The {{Predictron}}}
      \field{title}{The {{Predictron}}: {{End-To-End Learning}} and {{Planning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1612.08810
      \endverb
      \verb{eprint}
      \verb 1612.08810
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/47Y5Q28Y/Silver et al. - 2017 - The Predictron End-To-End Learning and Planning.pdf;/home/james/Zotero/storage/RXLHAJZ3/1612.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing}
    \endentry
    \entry{srinivasCURLContrastiveUnsupervised2020}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=09fed423ccdd83193718e9e7e2c70481}{%
           family={Srinivas},
           familyi={S\bibinitperiod},
           given={Aravind},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=af9729d0e8bc4f4722f164d7b1035749}{%
           family={Laskin},
           familyi={L\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{81b286869b6ba5302cf855115e96cc20}
      \strng{fullhash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \strng{bibnamehash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \strng{authorbibnamehash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \strng{authornamehash}{81b286869b6ba5302cf855115e96cc20}
      \strng{authorfullhash}{4e7ca6a9c7b3f3a426917b11fbf10637}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present CURL: Contrastive Unsupervised Representations for Reinforcement Learning. CURL extracts high-level features from raw pixels using contrastive learning and performs off-policy control on top of the extracted features. CURL outperforms prior pixel-based methods, both model-based and model-free, on complex tasks in the DeepMind Control Suite and Atari Games showing 1.9x and 1.2x performance gains at the 100K environment and interaction steps benchmarks respectively. On the DeepMind Control Suite, CURL is the first image-based algorithm to nearly match the sample-efficiency of methods that use state-based features. Our code is open-sourced and available at https://github.com/MishaLaskin/curl.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{9}
      \field{number}{arXiv:2004.04136}
      \field{shorttitle}{{{CURL}}}
      \field{title}{{{CURL}}: {{Contrastive Unsupervised Representations}} for {{Reinforcement Learning}}}
      \field{urlday}{21}
      \field{urlmonth}{6}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2004.04136
      \endverb
      \verb{eprint}
      \verb 2004.04136
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Srinivas et al_2020_CURL.pdf;/home/james/Zotero/storage/V2B9BSM7/2004.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,RL,Statistics - Machine Learning,Unsupervised RL}
    \endentry
    \entry{suttonLearningPredictMethods1988}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S.},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{fullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{bibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorbibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authornamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorfullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article introduces a class of incremental learning procedures specialized for prediction-that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.}
      \field{issn}{1573-0565}
      \field{journaltitle}{Machine Learning}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{1}
      \field{title}{Learning to Predict by the Methods of Temporal Differences}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{3}
      \field{year}{1988}
      \field{urldateera}{ce}
      \field{pages}{9\bibrangedash 44}
      \range{pages}{36}
      \verb{doi}
      \verb 10.1007/BF00115009
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/SIJVVH67/Sutton - 1988 - Learning to predict by the methods of temporal differences.pdf
      \endverb
      \keyw{Artificial Intelligence,connectionism,credit assignment,evaluation functions,Incremental learning,prediction}
    \endentry
    \entry{sutton2018reinforcement}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{fullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{bibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorbibnamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authornamehash}{eb920e5277d3d5fd0903f3cd41e11871}
      \strng{authorfullhash}{eb920e5277d3d5fd0903f3cd41e11871}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{A Bradford Book}
      \field{title}{Reinforcement learning: An introduction}
      \field{year}{2018}
    \endentry
    \entry{suttonPolicyGradientMethods1999}{inbook}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=09a4af5c985fc9a46727803f19cd8272}{%
           family={McAllester},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74d941c38e5affcd359ed5814815805f}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Satinder},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ad31daafb6eb6186dd51ffeae5196ec0}{%
           family={Mansour},
           familyi={M\bibinitperiod},
           given={Yishay},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{3}{}{%
        {{hash=b355381619d6a313804fe1e82c3c5d5e}{%
           family={Solla},
           familyi={S\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=d0fa2183d141c3c709a512cab4fee1b2}{%
           family={Leen},
           familyi={L\bibinitperiod},
           given={T.},
           giveni={T\bibinitperiod}}}%
        {{hash=45d0bd8fb04f1a74dbec720c7ccf750e}{%
           family={MÃ¼ller},
           familyi={M\bibinitperiod},
           given={K.},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{176c86aa36fab51e81d033c2d8ea8cbe}
      \strng{fullhash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{bibnamehash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{authorbibnamehash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{authornamehash}{176c86aa36fab51e81d033c2d8ea8cbe}
      \strng{authorfullhash}{6b36fd87902dbca910efbc0f913a7749}
      \strng{editorbibnamehash}{fa42941c20b5f08a036d8fc84cd1cdf0}
      \strng{editornamehash}{c8beec784e7d915fa390896f6b5e9dfa}
      \strng{editorfullhash}{fa42941c20b5f08a036d8fc84cd1cdf0}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Advances in {{Neural Information Processing Systems}}}
      \field{title}{Policy {{Gradient Methods}} for {{Reinforcement Learning}} with {{Function Approximation}}}
      \field{volume}{12}
      \field{year}{1999}
    \endentry
    \entry{tassaDeepMindControlSuite2018}{misc}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=58112cb88a80c1bc045b6eaab26a8695}{%
           family={Tassa},
           familyi={T\bibinitperiod},
           given={Yuval},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=237b733d6914e7eb0f991903046d13a3}{%
           family={Doron},
           familyi={D\bibinitperiod},
           given={Yotam},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3eb7f8dffab1558054d5f9ec78d2fac2}{%
           family={Muldal},
           familyi={M\bibinitperiod},
           given={Alistair},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3b79ca47f08451987877fd8682e971e5}{%
           family={Erez},
           familyi={E\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ea8af3b8f68d4c40172af64bc26a53c6}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yazhe},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2065f849a50a25340022b8ea9c67cdf8}{%
           family={Casas},
           familyi={C\bibinitperiod},
           given={Diego\bibnamedelimb de\bibnamedelima Las},
           giveni={D\bibinitperiod\bibinitdelim d\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c23f8012677b40de82f339368c393522}{%
           family={Budden},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=528d31a6b5c1231e01391e2597dd5491}{%
           family={Abdolmaleki},
           familyi={A\bibinitperiod},
           given={Abbas},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ac49e241f88460f90f9f1ab5f88db248}{%
           family={Merel},
           familyi={M\bibinitperiod},
           given={Josh},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74cc29ccd6d85aa2fba6fdb64104d432}{%
           family={Lefrancq},
           familyi={L\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b5137dee7101e4a7d1b4962348fb537a}
      \strng{fullhash}{2f52eb92fdec83e02a26d2211ea3a512}
      \strng{bibnamehash}{2f52eb92fdec83e02a26d2211ea3a512}
      \strng{authorbibnamehash}{2f52eb92fdec83e02a26d2211ea3a512}
      \strng{authornamehash}{b5137dee7101e4a7d1b4962348fb537a}
      \strng{authorfullhash}{2f52eb92fdec83e02a26d2211ea3a512}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The DeepMind Control Suite is a set of continuous control tasks with a standardised structure and interpretable rewards, intended to serve as performance benchmarks for reinforcement learning agents. The tasks are written in Python and powered by the MuJoCo physics engine, making them easy to use and modify. We include benchmarks for several learning algorithms. The Control Suite is publicly available at https://www.github.com/deepmind/dm\_control . A video summary of all tasks is available at http://youtu.be/rAai4QzcYbs .}
      \field{eprinttype}{arXiv}
      \field{month}{1}
      \field{number}{arXiv:1801.00690}
      \field{title}{{{DeepMind Control Suite}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1801.00690
      \endverb
      \verb{eprint}
      \verb 1801.00690
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/WCCR5876/Tassa et al. - 2018 - DeepMind Control Suite.pdf;/home/james/Zotero/storage/7WQI6APV/1801.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence}
    \endentry
    \entry{tobinDomainRandomizationTransferring2017}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=e6a2e03971ee3e138dbe64b3a4c5a95a}{%
           family={Tobin},
           familyi={T\bibinitperiod},
           given={Josh},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=71105dfe9b3b73a20fb9a3156d389fad}{%
           family={Fong},
           familyi={F\bibinitperiod},
           given={Rachel},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=143fa59d90387ae4a6aa650dcf1c7ceb}{%
           family={Ray},
           familyi={R\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5167ef9d0b77bf68557730648baac9b7}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e9fec85bbce1b087a6ebefe26e73f7bf}{%
           family={Zaremba},
           familyi={Z\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{2c42dddd45e1ea280a64e08c9a87d720}
      \strng{fullhash}{59127397f3045b880071f52e5e66fdf5}
      \strng{bibnamehash}{59127397f3045b880071f52e5e66fdf5}
      \strng{authorbibnamehash}{59127397f3045b880071f52e5e66fdf5}
      \strng{authornamehash}{2c42dddd45e1ea280a64e08c9a87d720}
      \strng{authorfullhash}{59127397f3045b880071f52e5e66fdf5}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Bridging the 'reality gap' that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to \$1.5\$cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated RGB images (without pre-training on real images) to the real world for the purpose of robotic control.}
      \field{eprinttype}{arXiv}
      \field{month}{3}
      \field{number}{arXiv:1703.06907}
      \field{title}{Domain {{Randomization}} for {{Transferring Deep Neural Networks}} from {{Simulation}} to the {{Real World}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1703.06907
      \endverb
      \verb{eprint}
      \verb 1703.06907
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/ZRMJ52LT/Tobin et al. - 2017 - Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World.pdf;/home/james/Zotero/storage/6LWYXQFS/1703.html
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{oordNeuralDiscreteRepresentation2018}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=705a5ed355c190be3a39e0a5134d2ae5}{%
           family={Oord},
           familyi={O\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod},
           givenun=0,
           prefix={van\bibnamedelima den},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=494b568c5dc85ba8f3f409635f9c5f25}{%
           family={Vinyals},
           familyi={V\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{d5a17822de636ff8de45307e236e0824}
      \strng{fullhash}{1f8f233c911e6ffbd85ce894897a4da5}
      \strng{bibnamehash}{1f8f233c911e6ffbd85ce894897a4da5}
      \strng{authorbibnamehash}{1f8f233c911e6ffbd85ce894897a4da5}
      \strng{authornamehash}{d5a17822de636ff8de45307e236e0824}
      \strng{authorfullhash}{1f8f233c911e6ffbd85ce894897a4da5}
      \field{sortinit}{v}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{number}{arXiv:1711.00937}
      \field{title}{Neural {{Discrete Representation Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1711.00937
      \endverb
      \verb{eprint}
      \verb 1711.00937
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Oord et al_2018_Neural Discrete Representation Learning.pdf;/home/james/Zotero/storage/JSPM23UP/1711.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{vanhasseltWhenUseParametric2019}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=e75f0b2e9c29c175e6320c1e96cdf5c8}{%
           family={{van Hasselt}},
           familyi={v\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e99abbc8dd53e5feeb2a428724ce1d2f}{%
           family={Aslanides},
           familyi={A\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{36a61a17516a81e9bf666a75302c9d59}
      \strng{fullhash}{6998db2d1facb5377c74726679d38cd6}
      \strng{bibnamehash}{6998db2d1facb5377c74726679d38cd6}
      \strng{authorbibnamehash}{6998db2d1facb5377c74726679d38cd6}
      \strng{authornamehash}{36a61a17516a81e9bf666a75302c9d59}
      \strng{authorfullhash}{6998db2d1facb5377c74726679d38cd6}
      \field{extraname}{1}
      \field{sortinit}{v}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We examine the question of when and how parametric models are most useful in reinforcement learning. In particular, we look at commonalities and differences between parametric models and experience replay. Replay-based learning algorithms share important traits with model-based approaches, including the ability to plan: to use more computation without additional data to improve predictions and behaviour. We discuss when to expect benefits from either approach, and interpret prior work in this context. We hypothesise that, under suitable conditions, replay-based algorithms should be competitive to or better than model-based algorithms if the model is used only to generate fictional transitions from observed states for an update rule that is otherwise model-free. We validated this hypothesis on Atari 2600 video games. The replay-based algorithm attained state-of-the-art data efficiency, improving over prior results with parametric models.}
      \field{eprintclass}{cs, stat}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{number}{arXiv:1906.05243}
      \field{title}{When to Use Parametric Models in Reinforcement Learning?}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1906.05243
      \endverb
      \verb{eprint}
      \verb 1906.05243
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/van Hasselt et al_2019_When to use parametric models in reinforcement learning.pdf;/home/james/Zotero/storage/LT5GCZ6M/1906.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{hasseltDeepReinforcementLearning2015}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=f5a8983bab24d2cd5670100e485fc883}{%
           family={Hasselt},
           familyi={H\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0,
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=4131bd14e5ca890278ecd351e356dc34}{%
           family={Guez},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a665efce46f880c07855c38cd56bd189}
      \strng{fullhash}{2bcc40866d8b979d51a84d2f43f45202}
      \strng{bibnamehash}{2bcc40866d8b979d51a84d2f43f45202}
      \strng{authorbibnamehash}{2bcc40866d8b979d51a84d2f43f45202}
      \strng{authornamehash}{a665efce46f880c07855c38cd56bd189}
      \strng{authorfullhash}{2bcc40866d8b979d51a84d2f43f45202}
      \field{extraname}{2}
      \field{sortinit}{v}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1509.06461}
      \field{title}{Deep {{Reinforcement Learning}} with {{Double Q-learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1509.06461
      \endverb
      \verb{eprint}
      \verb 1509.06461
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/KN8LT52B/Hasselt et al. - 2015 - Deep Reinforcement Learning with Double Q-learning.pdf;/home/james/Zotero/storage/CERMKB9X/1509.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{vaswaniAttentionAllYou2017}{misc}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N.},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2bc899b1160163417da7bf510f15d33}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Lukasz},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{bibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authorbibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:1706.03762}
      \field{title}{Attention {{Is All You Need}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1706.03762
      \endverb
      \verb{eprint}
      \verb 1706.03762
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Vaswani et al_2017_Attention Is All You Need.pdf;/home/james/Zotero/storage/MIYXNHJH/1706.html
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning,Transformers}
    \endentry
    \entry{inproceedings}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=da21e966c02c3cfd33d74369c7435c1a}{%
           family={Vincent},
           familyi={V\bibinitperiod},
           given={Pascal},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=42a970b0a0f1ed24b23064370cc9392f}{%
           family={Larochelle},
           familyi={L\bibinitperiod},
           given={Hugo},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=419350ebbeb4eba5351469f378dee007}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ba1a9455f15a2898752cabc022e1887}{%
           family={Manzagol},
           familyi={M\bibinitperiod},
           given={Pierre-Antoine},
           giveni={P\bibinithyphendelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{17d6344b63d3d08616d701213bf1af6a}
      \strng{fullhash}{178ee493b3884ed5cf4aad60949d7564}
      \strng{bibnamehash}{178ee493b3884ed5cf4aad60949d7564}
      \strng{authorbibnamehash}{178ee493b3884ed5cf4aad60949d7564}
      \strng{authornamehash}{17d6344b63d3d08616d701213bf1af6a}
      \strng{authorfullhash}{178ee493b3884ed5cf4aad60949d7564}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{1}
      \field{series}{Proceedings of the 25th {{International Conference}} on {{Machine Learning}}}
      \field{title}{Extracting and Composing Robust Features with Denoising Autoencoders}
      \field{year}{2008}
      \field{pages}{1096\bibrangedash 1103}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1145/1390156.1390294
      \endverb
    \endentry
    \entry{vinyalsGrandmasterLevelStarCraft2019}{article}{}
      \name{author}{42}{}{%
        {{un=0,uniquepart=base,hash=494b568c5dc85ba8f3f409635f9c5f25}{%
           family={Vinyals},
           familyi={V\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=92efe2a8e13a9b7a3fb647951ee2391c}{%
           family={Babuschkin},
           familyi={B\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5dc7de68ac7f0299a995822f38a3e705}{%
           family={Czarnecki},
           familyi={C\bibinitperiod},
           given={Wojciech\bibnamedelima M.},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b3fbcff36ec4b37aed7c56f67c21038b}{%
           family={Mathieu},
           familyi={M\bibinitperiod},
           given={MichaÃ«l},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=76a7579d94d000dca5e0071fb3b69382}{%
           family={Dudzik},
           familyi={D\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a79e6bb4ca772c9b3b38f4e9f45b83c}{%
           family={Chung},
           familyi={C\bibinitperiod},
           given={Junyoung},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=17ad757032d822b4a43e828ae592c91e}{%
           family={Choi},
           familyi={C\bibinitperiod},
           given={David\bibnamedelima H.},
           giveni={D\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2820daeb58d4d5a594fbdaf6db68f850}{%
           family={Powell},
           familyi={P\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2687d58e59afed22249974d723704f56}{%
           family={Ewalds},
           familyi={E\bibinitperiod},
           given={Timo},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1c5b83cefd7033a528994276b9c00e87}{%
           family={Georgiev},
           familyi={G\bibinitperiod},
           given={Petko},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d6a1e759373b43eefda2aab3aec6b728}{%
           family={Oh},
           familyi={O\bibinitperiod},
           given={Junhyuk},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c1a26cb7f963abdf071da408366e83a1}{%
           family={Horgan},
           familyi={H\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be1b190734e6a891e14bf8c4adc4d1c3}{%
           family={Kroiss},
           familyi={K\bibinitperiod},
           given={Manuel},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=970650e9394fccd4144d4b829505d2b3}{%
           family={Danihelka},
           familyi={D\bibinitperiod},
           given={Ivo},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba4b200ce1412a2570cb113366cc9559}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Aja},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50d24de916599d306c5cb1a77156e4b9}{%
           family={Sifre},
           familyi={S\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3d7a83ed6eb983ca17cec804631dc22e}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e4fa217e56ca1781ab11713ab27cf2b4}{%
           family={Agapiou},
           familyi={A\bibinitperiod},
           given={John\bibnamedelima P.},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7dc1446dea7ff50b2b02fb83780cc9c6}{%
           family={Jaderberg},
           familyi={J\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=06f6f348a3bb818c79944f71cf518f3f}{%
           family={Vezhnevets},
           familyi={V\bibinitperiod},
           given={Alexander\bibnamedelima S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f64056fe9107fedd28b447d31bfc157b}{%
           family={Leblond},
           familyi={L\bibinitperiod},
           given={RÃ©mi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b1bdbd9e1dcbed6591878a57d5058c54}{%
           family={Pohlen},
           familyi={P\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=39809e64cffbcbfd42bd81da5153546a}{%
           family={Dalibard},
           familyi={D\bibinitperiod},
           given={Valentin},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c23f8012677b40de82f339368c393522}{%
           family={Budden},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=22eaafdd6c3038933341b729e199e0ce}{%
           family={Sulsky},
           familyi={S\bibinitperiod},
           given={Yury},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=88dca93fff01bbe55329c40c0891257d}{%
           family={Molloy},
           familyi={M\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f565c54b0935cdca35d3d90b831013cf}{%
           family={Paine},
           familyi={P\bibinitperiod},
           given={Tom\bibnamedelima L.},
           giveni={T\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2adc0c92c308f233c731321d55efe58f}{%
           family={Gulcehre},
           familyi={G\bibinitperiod},
           given={Caglar},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=05bc8d503a2c310ef0976ace7f9d2734}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ziyu},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a726408819b6f955652c3ffaaedef966}{%
           family={Pfaff},
           familyi={P\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=954bef435a12336c9decd19360a640f5}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yuhuai},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=50349f5d4ef065e417356ee70e0f7069}{%
           family={Ring},
           familyi={R\bibinitperiod},
           given={Roman},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=14889c0769f78922934df82a671f0cf3}{%
           family={Yogatama},
           familyi={Y\bibinitperiod},
           given={Dani},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=616c76aced80eaed20688f6ab93db271}{%
           family={WÃ¼nsch},
           familyi={W\bibinitperiod},
           given={Dario},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5f3f9f74e6c498a754b9a8a7b7a53311}{%
           family={McKinney},
           familyi={M\bibinitperiod},
           given={Katrina},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e4c8c37e34209dd0f61d34723d9061fe}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3a6fdf4df9a25f1d2d506ad9e86e1f6c}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b160026950ebb1e2286dfb40c15482f5}{%
           family={Hassabis},
           familyi={H\bibinitperiod},
           given={Demis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b7585cb31b9235c4a758d152b7f7e828}{%
           family={Apps},
           familyi={A\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Nature Publishing Group}%
      }
      \strng{namehash}{832d19b6ecbaa1d465342fe676ffb29a}
      \strng{fullhash}{e20baf229e73fd131dd91cbcd821c571}
      \strng{bibnamehash}{783c2b117f393260e8cc5d9facb5ba78}
      \strng{authorbibnamehash}{783c2b117f393260e8cc5d9facb5ba78}
      \strng{authornamehash}{832d19b6ecbaa1d465342fe676ffb29a}
      \strng{authorfullhash}{e20baf229e73fd131dd91cbcd821c571}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.}
      \field{issn}{1476-4687}
      \field{journaltitle}{Nature}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{7782}
      \field{title}{Grandmaster Level in {{StarCraft II}} Using Multi-Agent Reinforcement Learning}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{volume}{575}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{350\bibrangedash 354}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1038/s41586-019-1724-z
      \endverb
      \keyw{Computer science,Statistics}
    \endentry
    \entry{wangDuelingNetworkArchitectures2016}{misc}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=05bc8d503a2c310ef0976ace7f9d2734}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ziyu},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a56e72b23778a835bdade7d0511e43a3}{%
           family={Schaul},
           familyi={S\bibinitperiod},
           given={Tom},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1640e78f1e643c3d6f8e8c5b4b50896c}{%
           family={Hessel},
           familyi={H\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f5a8983bab24d2cd5670100e485fc883}{%
           family={Hasselt},
           familyi={H\bibinitperiod},
           given={Hado},
           giveni={H\bibinitperiod},
           givenun=0,
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=3075d0e02c0833f6e5fe1addb880898f}{%
           family={Lanctot},
           familyi={L\bibinitperiod},
           given={Marc},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cf269f9a5106a41ad53847a68a27db1c}{%
           family={Freitas},
           familyi={F\bibinitperiod},
           given={Nando},
           giveni={N\bibinitperiod},
           givenun=0,
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ce0f3d71b18ee7367558a7b6d6e6973e}
      \strng{fullhash}{df01a276e95745be4e3db8438093d454}
      \strng{bibnamehash}{df01a276e95745be4e3db8438093d454}
      \strng{authorbibnamehash}{df01a276e95745be4e3db8438093d454}
      \strng{authornamehash}{ce0f3d71b18ee7367558a7b6d6e6973e}
      \strng{authorfullhash}{df01a276e95745be4e3db8438093d454}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{number}{arXiv:1511.06581}
      \field{title}{Dueling {{Network Architectures}} for {{Deep Reinforcement Learning}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1511.06581
      \endverb
      \verb{eprint}
      \verb 1511.06581
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/B4T6P73C/Wang et al. - 2016 - Dueling Network Architectures for Deep Reinforcement Learning.pdf;/home/james/Zotero/storage/BS84858L/1511.html
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{wengEnvPoolHighlyParallel2022}{misc}{}
      \name{author}{12}{}{%
        {{un=0,uniquepart=base,hash=1d0662e5050b9cf02a15642557cd6293}{%
           family={Weng},
           familyi={W\bibinitperiod},
           given={Jiayi},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d2827b813d1d73df44360201e3296bea}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a485c9f2edbeda28fc6122a6d8ef9913}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Shengyi},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fa97927921a403cfe822973e31081dca}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=600fffd871568e2c04c8fc864359604a}{%
           family={Makoviichuk},
           familyi={M\bibinitperiod},
           given={Denys},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b2920c1e5c13f9f9448bc7ad484b44ed}{%
           family={Makoviychuk},
           familyi={M\bibinitperiod},
           given={Viktor},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d55e742fcb815ec7994f7201aef69793}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Zichen},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=57634a2e7d71f42baa66bf30827f40d4}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Yufan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=735d49a4934b3cf6dc24f676533207be}{%
           family={Luo},
           familyi={L\bibinitperiod},
           given={Ting},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e166a7e4574441f9b8d74c0e13a2cce4}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Yukun},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=faada09468b43ab0d3997004258e0520}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Zhongwen},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a7a92b64300d6c39c3ae492b9ded385}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Shuicheng},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{c645e86784b912941351d8cfcbe832fe}
      \strng{fullhash}{d73c7d873857e2362be84dad0d762e16}
      \strng{bibnamehash}{d73c7d873857e2362be84dad0d762e16}
      \strng{authorbibnamehash}{d73c7d873857e2362be84dad0d762e16}
      \strng{authornamehash}{c645e86784b912941351d8cfcbe832fe}
      \strng{authorfullhash}{d73c7d873857e2362be84dad0d762e16}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{There has been significant progress in developing reinforcement learning (RL) training systems. Past works such as IMPALA, Apex, Seed RL, Sample Factory, and others, aim to improve the system's overall throughput. In this paper, we aim to address a common bottleneck in the RL training system, i.e., parallel environment execution, which is often the slowest part of the whole system but receives little attention. With a curated design for paralleling RL environments, we have improved the RL environment simulation speed across different hardware setups, ranging from a laptop and a modest workstation, to a high-end machine such as NVIDIA DGX-A100. On a high-end machine, EnvPool achieves one million frames per second for the environment execution on Atari environments and three million frames per second on MuJoCo environments. When running EnvPool on a laptop, the speed is 2.8x that of the Python subprocess. Moreover, great compatibility with existing RL training libraries has been demonstrated in the open-sourced community, including CleanRL, rl\_games, DeepMind Acme, etc. Finally, EnvPool allows researchers to iterate their ideas at a much faster pace and has great potential to become the de facto RL environment execution engine. Example runs show that it only takes five minutes to train agents to play Atari Pong and MuJoCo Ant on a laptop. EnvPool is open-sourced at https://github.com/sail-sg/envpool.}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:2206.10558}
      \field{shorttitle}{{{EnvPool}}}
      \field{title}{{{EnvPool}}: {{A Highly Parallel Reinforcement Learning Environment Execution Engine}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2206.10558
      \endverb
      \verb{eprint}
      \verb 2206.10558
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/HH87KM5I/Weng et al. - 2022 - EnvPool A Highly Parallel Reinforcement Learning Environment Execution Engine.pdf;/home/james/Zotero/storage/4G6HQWQR/2206.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning,Computer Science - Performance,Computer Science - Robotics}
    \endentry
    \entry{yampolskiy2018artificial}{book}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=85237c83ab50955dc88666e2ba00959e}{%
           family={Yampolskiy},
           familyi={Y\bibinitperiod},
           given={R.V.},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {CRC Press/Taylor \& Francis Group}%
      }
      \strng{namehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{fullhash}{85237c83ab50955dc88666e2ba00959e}
      \strng{bibnamehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{authorbibnamehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{authornamehash}{85237c83ab50955dc88666e2ba00959e}
      \strng{authorfullhash}{85237c83ab50955dc88666e2ba00959e}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-0-8153-6982-0}
      \field{series}{Chapman \& {{Hall}}/{{CRC}} Artificial Intelligence and Robotics Series}
      \field{title}{Artificial Intelligence Safety and Security}
      \field{year}{2018}
    \endentry
    \entry{yaratsMasteringVisualContinuous2021}{misc}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=c1a92bfddfd960be33e0dbc1cd54ddef}{%
           family={Yarats},
           familyi={Y\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6784304d1cc890b2cb6c6c7f2f3fd76}{%
           family={Fergus},
           familyi={F\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0edda5e676d227fa203a6350888089e}{%
           family={Lazaric},
           familyi={L\bibinitperiod},
           given={Alessandro},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d4b78f1220fe5cab8395d811fc9c5b2}{%
           family={Pinto},
           familyi={P\bibinitperiod},
           given={Lerrel},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{1416ba9258e17e11da9204cd03a00a44}
      \strng{fullhash}{4db5ff40301013a0f7660d400685bdd9}
      \strng{bibnamehash}{4db5ff40301013a0f7660d400685bdd9}
      \strng{authorbibnamehash}{4db5ff40301013a0f7660d400685bdd9}
      \strng{authornamehash}{1416ba9258e17e11da9204cd03a00a44}
      \strng{authorfullhash}{4db5ff40301013a0f7660d400685bdd9}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for visual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic approach that uses data augmentation to learn directly from pixels. We introduce several improvements that yield state-of-the-art results on the DeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid locomotion tasks directly from pixel observations, previously unattained by model-free RL. DrQ-v2 is conceptually simple, easy to implement, and provides significantly better computational footprint compared to prior work, with the majority of tasks taking just 8 hours to train on a single GPU. Finally, we publicly release DrQ-v2's implementation to provide RL practitioners with a strong and computationally efficient baseline.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{number}{arXiv:2107.09645}
      \field{shorttitle}{Mastering {{Visual Continuous Control}}}
      \field{title}{Mastering {{Visual Continuous Control}}: {{Improved Data-Augmented Reinforcement Learning}}}
      \field{urlday}{6}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2107.09645
      \endverb
      \verb{eprint}
      \verb 2107.09645
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/WUJBSACI/Yarats et al. - 2021 - Mastering Visual Continuous Control Improved Data.pdf;/home/james/Zotero/storage/WXJX786X/2107.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{yeMasteringAtariGames2021}{misc}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=119346c0749953c9169a3e08144eb042}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Weirui},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f441c03dee89a6c9491367e808d1bdc2}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Shaohuai},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9b11af4841b4b3e436a27b0f140f45e3}{%
           family={Kurutach},
           familyi={K\bibinitperiod},
           given={Thanard},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e28d4ee199593959d8c29980a64f1974}{%
           family={Abbeel},
           familyi={A\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9c1ecb1f7c47cf02e9e994296746328c}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Yang},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{bceae5bd124d719847dd2c8c56b20904}
      \strng{fullhash}{3c47a809330452b7725bd5bb7935c771}
      \strng{bibnamehash}{3c47a809330452b7725bd5bb7935c771}
      \strng{authorbibnamehash}{3c47a809330452b7725bd5bb7935c771}
      \strng{authornamehash}{bceae5bd124d719847dd2c8c56b20904}
      \strng{authorfullhash}{3c47a809330452b7725bd5bb7935c771}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3\% mean human performance and 109.0\% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{number}{arXiv:2111.00210}
      \field{title}{Mastering {{Atari Games}} with {{Limited Data}}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2111.00210
      \endverb
      \verb{eprint}
      \verb 2111.00210
      \endverb
      \verb{file}
      \verb /home/james/Documents/zotero/Ye et al_2021_Mastering Atari Games with Limited Data.pdf;/home/james/Zotero/storage/G2MEEKN4/2111.html
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics}
    \endentry
    \entry{zhangColorfulImageColorization2016}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=0c65190dcbd461dee172354f7938ae43}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cae9f806bc99a5f19fadea538fc2db04}{%
           family={Isola},
           familyi={I\bibinitperiod},
           given={Phillip},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5a663b27298722834a8cf09bb93d8c94}{%
           family={Efros},
           familyi={E\bibinitperiod},
           given={Alexei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a186c318a8836d77467280ce6646a302}
      \strng{fullhash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \strng{bibnamehash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \strng{authorbibnamehash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \strng{authornamehash}{a186c318a8836d77467280ce6646a302}
      \strng{authorfullhash}{dd48d99eeae43e62ba64f38fa60a07d5}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a "colorization Turing test," asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32\% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{number}{arXiv:1603.08511}
      \field{title}{Colorful {{Image Colorization}}}
      \field{urlday}{24}
      \field{urlmonth}{11}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1603.08511
      \endverb
      \verb{eprint}
      \verb 1603.08511
      \endverb
      \verb{file}
      \verb /home/james/Zotero/storage/UAKXPHDC/Zhang et al. - 2016 - Colorful Image Colorization.pdf;/home/james/Zotero/storage/7WRG6FX3/1603.html
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
  \enddatalist
\endrefsection
\endinput

